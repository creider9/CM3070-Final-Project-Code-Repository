{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc360176",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Short-Term Rental Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78357219",
   "metadata": {},
   "source": [
    "## Part 1: Loading Data into Python Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d791542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In starting out with the product developement, the first step will be getting the data into a dataframe.\n",
    "# This will allow me to pre-process the data with Pandas built in functions [1].\n",
    "# In order to do this, pandas must be added to the notebook. \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9fca626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, I will read in the CSV into a pandas dataframe\n",
    "file = \"Hotel_Reviews.csv\"\n",
    "original_data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b58d641a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>8/3/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Russia</td>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>397</td>\n",
       "      <td>1403</td>\n",
       "      <td>Only the park outside of the hotel was beauti...</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>0 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>8/3/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1403</td>\n",
       "      <td>No real complaints the hotel was great great ...</td>\n",
       "      <td>105</td>\n",
       "      <td>7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>0 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/31/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>42</td>\n",
       "      <td>1403</td>\n",
       "      <td>Location was good and staff were ok It is cut...</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>[' Leisure trip ', ' Family with young childre...</td>\n",
       "      <td>3 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Hotel_Address  \\\n",
       "0   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "1   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "2   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "\n",
       "   Additional_Number_of_Scoring Review_Date  Average_Score   Hotel_Name  \\\n",
       "0                           194    8/3/2017            7.7  Hotel Arena   \n",
       "1                           194    8/3/2017            7.7  Hotel Arena   \n",
       "2                           194   7/31/2017            7.7  Hotel Arena   \n",
       "\n",
       "  Reviewer_Nationality                                    Negative_Review  \\\n",
       "0              Russia    I am so angry that i made this post available...   \n",
       "1             Ireland                                         No Negative   \n",
       "2           Australia    Rooms are nice but for elderly a bit difficul...   \n",
       "\n",
       "   Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  \\\n",
       "0                                397                     1403   \n",
       "1                                  0                     1403   \n",
       "2                                 42                     1403   \n",
       "\n",
       "                                     Positive_Review  \\\n",
       "0   Only the park outside of the hotel was beauti...   \n",
       "1   No real complaints the hotel was great great ...   \n",
       "2   Location was good and staff were ok It is cut...   \n",
       "\n",
       "   Review_Total_Positive_Word_Counts  \\\n",
       "0                                 11   \n",
       "1                                105   \n",
       "2                                 21   \n",
       "\n",
       "   Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  \\\n",
       "0                                           7             2.9   \n",
       "1                                           7             7.5   \n",
       "2                                           9             7.1   \n",
       "\n",
       "                                                Tags days_since_review  \\\n",
       "0  [' Leisure trip ', ' Couple ', ' Duplex Double...            0 days   \n",
       "1  [' Leisure trip ', ' Couple ', ' Duplex Double...            0 days   \n",
       "2  [' Leisure trip ', ' Family with young childre...            3 days   \n",
       "\n",
       "         lat       lng  \n",
       "0  52.360576  4.915968  \n",
       "1  52.360576  4.915968  \n",
       "2  52.360576  4.915968  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show some of the data to start to understand it better. \n",
    "original_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ba3d33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Negative  No real complaints the hotel was ...</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Total_Review  Reviewer_Score\n",
       "0   I am so angry that i made this post available...             2.9\n",
       "1  No Negative  No real complaints the hotel was ...             7.5\n",
       "2   Rooms are nice but for elderly a bit difficul...             7.1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for sentiment analysis, we will want to combine the data into a new dataframe that will be used for pre-processing.\n",
    "# the fields that are relevant are the positive review, negative review, and the reviewer score\n",
    "# reviewer score can be used for labelling our sentiment as per the review \n",
    "\n",
    "original_data[\"Total_Review\"] = original_data[\"Negative_Review\"] + \" \" + original_data[\"Positive_Review\"]\n",
    "\n",
    "columns = [\"Total_Review\", \"Reviewer_Score\"]\n",
    "\n",
    "review_data = original_data[columns]\n",
    "\n",
    "review_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6614ace5",
   "metadata": {},
   "source": [
    "## Part 3: Optimizing the Pre-Processing into one Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3087941c",
   "metadata": {},
   "source": [
    "This section will be used for developing final preprocessing pipelines that can be used in my ML development. There will be two because one will be with using POS tagging and the other will be without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20a752e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/coreyreid/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/coreyreid/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/coreyreid/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/coreyreid/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/coreyreid/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "#import the relevant libraries and download the relevant nltk dependancies [3]\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#download the needed nltk toolkits\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# optimized all-encompassing function for preprocessing that can easily be manipulated for tests\n",
    "def preprocess_pos(review):\n",
    "    \n",
    "    #preprocess remove special characters and ensure lowercase \n",
    "    def preprocess_remove_special(review):\n",
    "        review_handled = re.sub(r'[^a-zA-Z\\s]', '', review)\n",
    "        review_lower = review_handled.lower()\n",
    "        return review_lower\n",
    "\n",
    "    #tokenize the words\n",
    "    def preprocess_tokenize(review):\n",
    "        bag_of_words = word_tokenize(review)\n",
    "        return bag_of_words\n",
    "\n",
    "    #remove the stopwords\n",
    "    def preprocess_stopwords(review):\n",
    "        words = stopwords.words('english')\n",
    "        set_stop_words = set(words)\n",
    "        removed_stopwords_words = []\n",
    "        for word in review:\n",
    "            if word not in set_stop_words:\n",
    "                removed_stopwords_words.append(word)\n",
    "        return removed_stopwords_words\n",
    "\n",
    "    #lemmatize\n",
    "    def preprocess_lemmatize(review):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized_review = [lemmatizer.lemmatize(word) for word in review ]\n",
    "        return lemmatized_review\n",
    "\n",
    "    #POS Tagging\n",
    "    def preprocess_tagger(review):\n",
    "        tagged_review = nltk.pos_tag(review)\n",
    "        return tagged_review\n",
    "\n",
    "\n",
    "    #execute the individual part functions within this bigger function\n",
    "    review_data_copy = review_data.copy()\n",
    "    review_data_copy['Total_Review_handled'] = review_data_copy[\"Total_Review\"].apply(preprocess_remove_special)\n",
    "    review_data_copy['Total_Review_handled'] = review_data_copy['Total_Review_handled'].apply(preprocess_tokenize)\n",
    "    review_data_copy['Total_Review_handled'] = review_data_copy['Total_Review_handled'].apply(preprocess_stopwords)\n",
    "    review_data_copy['Total_Review_handled'] = review_data_copy['Total_Review_handled'].apply(preprocess_lemmatize)\n",
    "    review_data_copy['POS_Tag'] = review_data_copy['Total_Review_handled'].apply(preprocess_tagger)\n",
    "\n",
    "    #create the final data\n",
    "    review_data_final = review_data_copy[['POS_Tag', 'Reviewer_Score']]\n",
    "    \n",
    "    #return the data\n",
    "    return review_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b86cd07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, I will create a similar function without POS Tagging and we will compare two techniques\n",
    "# with and without POS Tagging\n",
    "\n",
    "def preprocess_no_pos(review):\n",
    "    \n",
    "    # remove special characters and ensure it is lowercase\n",
    "    def preprocess_remove_special(review):\n",
    "        review_handled = re.sub(r'[^a-zA-Z\\s]', '', review)\n",
    "        review_lower = review_handled.lower()\n",
    "        return review_lower\n",
    "\n",
    "    #tokenize\n",
    "    def preprocess_tokenize(review):\n",
    "        bag_of_words = word_tokenize(review)\n",
    "        return bag_of_words\n",
    "\n",
    "    #remove stopwords\n",
    "    def preprocess_stopwords(review):\n",
    "        words = stopwords.words('english')\n",
    "        set_stop_words = set(words)\n",
    "        removed_stopwords_words = []\n",
    "        for word in review:\n",
    "            if word not in set_stop_words:\n",
    "                removed_stopwords_words.append(word)\n",
    "        return removed_stopwords_words\n",
    "\n",
    "    #lemmatize\n",
    "    def preprocess_lemmatize(review):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized_review = [lemmatizer.lemmatize(word) for word in review ]\n",
    "        return lemmatized_review\n",
    "\n",
    "    #execute functions within the bigger function\n",
    "    review_data_copy = review_data.copy()\n",
    "    review_data_copy['Total_Review_handled'] = review_data_copy[\"Total_Review\"].apply(preprocess_remove_special)\n",
    "    review_data_copy['Total_Review_handled'] = review_data_copy['Total_Review_handled'].apply(preprocess_tokenize)\n",
    "    review_data_copy['Total_Review_handled'] = review_data_copy['Total_Review_handled'].apply(preprocess_stopwords)\n",
    "    review_data_copy['Total_Review_handled'] = review_data_copy['Total_Review_handled'].apply(preprocess_lemmatize)\n",
    "\n",
    "    #finalize data\n",
    "    review_data_final = review_data_copy[['Total_Review_handled', 'Reviewer_Score']]\n",
    "\n",
    "    #return the preprocessed data\n",
    "    return review_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9870ba09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS_Tag</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(angry, JJ), (made, VBD), (post, NN), (availa...</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(negative, JJ), (real, JJ), (complaint, NN), ...</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(room, NN), (nice, RB), (elderly, JJ), (bit, ...</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(room, NN), (dirty, NN), (afraid, JJ), (walk,...</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(booked, VBN), (company, NN), (line, NN), (sh...</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>[(trolly, RB), (staff, NN), (help, NN), (take,...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>[(hotel, NN), (look, NN), (like, IN), (surely,...</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>[(ac, JJ), (useless, JJ), (hot, JJ), (week, NN...</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515736</th>\n",
       "      <td>[(negative, JJ), (room, NN), (enormous, JJ), (...</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>[(rd, NN), (floor, NN), (work, NN), (free, JJ)...</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515738 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  POS_Tag  Reviewer_Score\n",
       "0       [(angry, JJ), (made, VBD), (post, NN), (availa...             2.9\n",
       "1       [(negative, JJ), (real, JJ), (complaint, NN), ...             7.5\n",
       "2       [(room, NN), (nice, RB), (elderly, JJ), (bit, ...             7.1\n",
       "3       [(room, NN), (dirty, NN), (afraid, JJ), (walk,...             3.8\n",
       "4       [(booked, VBN), (company, NN), (line, NN), (sh...             6.7\n",
       "...                                                   ...             ...\n",
       "515733  [(trolly, RB), (staff, NN), (help, NN), (take,...             7.0\n",
       "515734  [(hotel, NN), (look, NN), (like, IN), (surely,...             5.8\n",
       "515735  [(ac, JJ), (useless, JJ), (hot, JJ), (week, NN...             2.5\n",
       "515736  [(negative, JJ), (room, NN), (enormous, JJ), (...             8.8\n",
       "515737  [(rd, NN), (floor, NN), (work, NN), (free, JJ)...             8.3\n",
       "\n",
       "[515738 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #next I will process the data with POS Tagging to compare to the previous section\n",
    "# #these should be the same as it is just an optimized function\n",
    "preprocessed_reviews_pos_tagging = preprocess_pos(review_data)\n",
    "preprocessed_reviews_pos_tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5a6d329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Review_handled</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[angry, made, post, available, via, possible, ...</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[negative, real, complaint, hotel, great, grea...</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[room, nice, elderly, bit, difficult, room, tw...</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[room, dirty, afraid, walk, barefoot, floor, l...</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[booked, company, line, showed, picture, room,...</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>[trolly, staff, help, take, luggage, room, loc...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>[hotel, look, like, surely, breakfast, ok, got...</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>[ac, useless, hot, week, vienna, gave, hot, ai...</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515736</th>\n",
       "      <td>[negative, room, enormous, really, comfortable...</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>[rd, floor, work, free, wife, staff, kind]</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515738 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Total_Review_handled  Reviewer_Score\n",
       "0       [angry, made, post, available, via, possible, ...             2.9\n",
       "1       [negative, real, complaint, hotel, great, grea...             7.5\n",
       "2       [room, nice, elderly, bit, difficult, room, tw...             7.1\n",
       "3       [room, dirty, afraid, walk, barefoot, floor, l...             3.8\n",
       "4       [booked, company, line, showed, picture, room,...             6.7\n",
       "...                                                   ...             ...\n",
       "515733  [trolly, staff, help, take, luggage, room, loc...             7.0\n",
       "515734  [hotel, look, like, surely, breakfast, ok, got...             5.8\n",
       "515735  [ac, useless, hot, week, vienna, gave, hot, ai...             2.5\n",
       "515736  [negative, room, enormous, really, comfortable...             8.8\n",
       "515737         [rd, floor, work, free, wife, staff, kind]             8.3\n",
       "\n",
       "[515738 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#last, I will process the review data without POS Tagging, the processing will end at lemmatizing. \n",
    "preprocessed_reviews_no_pos_tagging = preprocess_no_pos(review_data)\n",
    "preprocessed_reviews_no_pos_tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e281d302",
   "metadata": {},
   "source": [
    "These two dataframes will be the two types of preprocessing methods I will consider in each of the models. This will show the difference between using POS tags and not using them. Additionally, we will now have two cases for exploring the impact on machine learning outcomes. \n",
    "\n",
    "The dataframes both are showing the data as expected so we can now proceed to implementing different machine learning models. We will then compare the results and determine which machine learning model is best for sentiment analysis of the Short-Term Rental review data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6925112",
   "metadata": {},
   "source": [
    "## Part 4: Classifying the Review Score Data for Machine Learning Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5acb74cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS_Tag</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(angry, JJ), (made, VBD), (post, NN), (availa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(negative, JJ), (real, JJ), (complaint, NN), ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(room, NN), (nice, RB), (elderly, JJ), (bit, ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(room, NN), (dirty, NN), (afraid, JJ), (walk,...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(booked, VBN), (company, NN), (line, NN), (sh...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>[(trolly, RB), (staff, NN), (help, NN), (take,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>[(hotel, NN), (look, NN), (like, IN), (surely,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>[(ac, JJ), (useless, JJ), (hot, JJ), (week, NN...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515736</th>\n",
       "      <td>[(negative, JJ), (room, NN), (enormous, JJ), (...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>[(rd, NN), (floor, NN), (work, NN), (free, JJ)...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515738 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  POS_Tag Reviewer_Score\n",
       "0       [(angry, JJ), (made, VBD), (post, NN), (availa...       negative\n",
       "1       [(negative, JJ), (real, JJ), (complaint, NN), ...       positive\n",
       "2       [(room, NN), (nice, RB), (elderly, JJ), (bit, ...       positive\n",
       "3       [(room, NN), (dirty, NN), (afraid, JJ), (walk,...       negative\n",
       "4       [(booked, VBN), (company, NN), (line, NN), (sh...       positive\n",
       "...                                                   ...            ...\n",
       "515733  [(trolly, RB), (staff, NN), (help, NN), (take,...       positive\n",
       "515734  [(hotel, NN), (look, NN), (like, IN), (surely,...       positive\n",
       "515735  [(ac, JJ), (useless, JJ), (hot, JJ), (week, NN...       negative\n",
       "515736  [(negative, JJ), (room, NN), (enormous, JJ), (...       positive\n",
       "515737  [(rd, NN), (floor, NN), (work, NN), (free, JJ)...       positive\n",
       "\n",
       "[515738 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first I will define the thresholds - our labels will be positive, negative, and neutral \n",
    "# I decided to use a small window for neutral, between 4.5 and 5.5 - this will ensure most the review classifications\n",
    "# are sensative - it can be updated later if desired by changing the following threshold values\n",
    "\n",
    "positive_threshold = 5.5\n",
    "negative_threshold = 4.5\n",
    "\n",
    "# next, I will classify by building a classification function\n",
    "\n",
    "def classify_scores(score_value):\n",
    "    if score_value >= positive_threshold:\n",
    "        return 'positive'\n",
    "    elif score_value <= negative_threshold:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "    \n",
    "preprocessed_reviews_pos_tagging_final = preprocessed_reviews_pos_tagging.copy()\n",
    "    \n",
    "preprocessed_reviews_pos_tagging_final['Reviewer_Score'] = preprocessed_reviews_pos_tagging_final['Reviewer_Score'].apply(classify_scores)\n",
    "\n",
    "preprocessed_reviews_pos_tagging_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4e8b4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Review_handled</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[angry, made, post, available, via, possible, ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[negative, real, complaint, hotel, great, grea...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[room, nice, elderly, bit, difficult, room, tw...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[room, dirty, afraid, walk, barefoot, floor, l...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[booked, company, line, showed, picture, room,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>[trolly, staff, help, take, luggage, room, loc...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>[hotel, look, like, surely, breakfast, ok, got...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>[ac, useless, hot, week, vienna, gave, hot, ai...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515736</th>\n",
       "      <td>[negative, room, enormous, really, comfortable...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>[rd, floor, work, free, wife, staff, kind]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515738 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Total_Review_handled Reviewer_Score\n",
       "0       [angry, made, post, available, via, possible, ...       negative\n",
       "1       [negative, real, complaint, hotel, great, grea...       positive\n",
       "2       [room, nice, elderly, bit, difficult, room, tw...       positive\n",
       "3       [room, dirty, afraid, walk, barefoot, floor, l...       negative\n",
       "4       [booked, company, line, showed, picture, room,...       positive\n",
       "...                                                   ...            ...\n",
       "515733  [trolly, staff, help, take, luggage, room, loc...       positive\n",
       "515734  [hotel, look, like, surely, breakfast, ok, got...       positive\n",
       "515735  [ac, useless, hot, week, vienna, gave, hot, ai...       negative\n",
       "515736  [negative, room, enormous, really, comfortable...       positive\n",
       "515737         [rd, floor, work, free, wife, staff, kind]       positive\n",
       "\n",
       "[515738 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will also do the same for the no POS tagging scenario\n",
    "\n",
    "preprocessed_reviews_no_pos_tagging_final = preprocessed_reviews_no_pos_tagging.copy()\n",
    "    \n",
    "preprocessed_reviews_no_pos_tagging_final['Reviewer_Score'] = preprocessed_reviews_no_pos_tagging_final['Reviewer_Score'].apply(classify_scores)\n",
    "\n",
    "preprocessed_reviews_no_pos_tagging_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6e2262b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive    475509\n",
      "neutral      24188\n",
      "negative     16041\n",
      "Name: Reviewer_Score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# determine the counts of each category\n",
    "review_counts = preprocessed_reviews_no_pos_tagging_final['Reviewer_Score'].value_counts()\n",
    "print(review_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462acba7",
   "metadata": {},
   "source": [
    "The data has now been preprocessed and categorized. As can be seen, the dataset is very unbalanced as most of the data is positive reviews at this threshold. This may be problematic in some of our machine learning models that we will be exploring. There are techniques for unbalanced datasets, so we may need to employ some of those to get better classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c0826f",
   "metadata": {},
   "source": [
    "## Part 7: Exploring Recurrent Neural Networks (RNN) Outcomes for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ef849",
   "metadata": {},
   "source": [
    "### Part 7.1: Libraries and Installations\n",
    "\n",
    "In this section we will expand to more complex deep learning models to try and get a better performing machine learning model for our sentiment analysis tool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ad15f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the dataframes are still in order\n",
    "# preprocessed_reviews_pos_tagging_final\n",
    "# preprocessed_reviews_no_pos_tagging_final\n",
    "reviews_pos_tagging_RNN = preprocessed_reviews_pos_tagging_final.copy()\n",
    "reviews_no_pos_tagging_RNN = preprocessed_reviews_no_pos_tagging_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74b3716f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.13.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.24.2)\n",
      "Requirement already satisfied: setuptools in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (67.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: keras in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (2.13.1)\n"
     ]
    }
   ],
   "source": [
    "# for this type of model I will use TensorFlow and Keras \n",
    "#install the deep learning framework Tensor Flow and library Keras [14][15]\n",
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a0ae4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to use a Recurrent Neural Network (RNN), we need to do a bit more processing on the data to format it the way it is needed for input\n",
    "# This includes, seperating the words and the POS tags, adding padding to get the length consistent, and\n",
    "# creating embeddings for the data, then splitting into test and train datasets for the model. \n",
    "#first I will import all the libraries needed for this model - I will use different tokenizers than previously\n",
    "#to show capabilities with different technologies\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Bidirectional, LSTM, GRU, Dense, SimpleRNN, Dropout #[16][17]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c4b5f",
   "metadata": {},
   "source": [
    "### Part 7.2: Prepare Data for RNN usage\n",
    "\n",
    "First, we will prepare the POS tagged data to be used in further development tasks below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad59f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with an RNN the scores can not be text - they need to be numbers - will encode these now\n",
    "class LabelEncoderSentiment:\n",
    "    def __init__(self):\n",
    "        self.classes_ = ['negative', 'neutral', 'positive']\n",
    "\n",
    "    def fit_transform(self, labels):\n",
    "        return np.array([self.classes_.index(label) for label in labels])\n",
    "    \n",
    "    def inverse_transform_sentiment(label_encorder, encoded_labels):\n",
    "        classes_ = ['negative', 'neutral', 'positive']\n",
    "        return [classes_[label] for label in encoded_labels]\n",
    "\n",
    "#with an RNN the scores can not be text - they need to be numbers - will encode these now\n",
    "label_encoder_RNN = LabelEncoderSentiment()\n",
    "encoded_scores_RNN = label_encoder_RNN.fit_transform(reviews_pos_tagging_RNN[\"Reviewer_Score\"])\n",
    "\n",
    "# get the text and POS data\n",
    "review_RNN = reviews_pos_tagging_RNN[\"POS_Tag\"]\n",
    "\n",
    "# prepare the text and POS data for RNN usage\n",
    "tokenizer_RNN = Tokenizer()\n",
    "tokenizer_RNN.fit_on_texts([\" \".join([rev for rev, _ in seq]) for seq in review_RNN])\n",
    "sequences_RNN = tokenizer_RNN.texts_to_sequences([\" \".join([rev for rev, _ in seq]) for seq in review_RNN])\n",
    "review_prepped_RNN = pad_sequences(sequences_RNN, maxlen=10)\n",
    "\n",
    "# prepare the test and train datasets\n",
    "X_train_RNN, X_test_RNN, y_train_RNN, y_test_RNN = train_test_split(review_prepped_RNN, encoded_scores_RNN, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353a52f6",
   "metadata": {},
   "source": [
    "Next, we will prepare the baseline data for the no POS tag scenario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5db0b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with an RNN the scores can not be text - they need to be numbers - will encode these now\n",
    "class LabelEncoderSentiment_noPOS:\n",
    "    def __init__(self):\n",
    "        self.classes_ = ['negative', 'neutral', 'positive']\n",
    "\n",
    "    def fit_transform_noPOS(self, labels):\n",
    "        return np.array([self.classes_.index(label) for label in labels])\n",
    "    \n",
    "    def inverse_transform_sentiment_noPOS(label_encorder, encoded_labels):\n",
    "        classes_ = ['negative', 'neutral', 'positive']\n",
    "        return [classes_[label] for label in encoded_labels]\n",
    "\n",
    "label_encoder_RNN_noPOS = LabelEncoderSentiment_noPOS()\n",
    "encoded_scores_RNN_noPOS = label_encoder_RNN_noPOS.fit_transform_noPOS(reviews_no_pos_tagging_RNN[\"Reviewer_Score\"])\n",
    "\n",
    "# get the text and POS data\n",
    "review_RNN_noPOS = reviews_no_pos_tagging_RNN[\"Total_Review_handled\"]\n",
    "\n",
    "# prepare the text and POS data for RNN usage\n",
    "tokenizer_RNN_noPOS = Tokenizer()\n",
    "tokenizer_RNN_noPOS.fit_on_texts([\" \".join(seq) for seq in review_RNN_noPOS])\n",
    "sequences_RNN_noPOS = tokenizer_RNN_noPOS.texts_to_sequences([\" \".join(seq) for seq in review_RNN_noPOS])\n",
    "review_prepped_RNN_noPOS = pad_sequences(sequences_RNN_noPOS, maxlen=10)\n",
    "\n",
    "# prepare the test and train datasets\n",
    "X_train_RNN_noPOS, X_test_RNN_noPOS, y_train_RNN_noPOS, y_test_RNN_noPOS = train_test_split(review_prepped_RNN_noPOS, encoded_scores_RNN_noPOS, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fe4ac5",
   "metadata": {},
   "source": [
    "### Part 7.3: Build the Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de4b2c",
   "metadata": {},
   "source": [
    "POS Tagged Data and Simple Model for Baseline evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1873a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5158/5158 [==============================] - 78s 15ms/step - loss: 0.2468 - accuracy: 0.9258 - weighted_accuracy: 0.9258 - val_loss: 0.2369 - val_accuracy: 0.9255 - val_weighted_accuracy: 0.9255\n",
      "Epoch 2/10\n",
      "5158/5158 [==============================] - 80s 16ms/step - loss: 0.2147 - accuracy: 0.9301 - weighted_accuracy: 0.9301 - val_loss: 0.2452 - val_accuracy: 0.9251 - val_weighted_accuracy: 0.9251\n",
      "Epoch 3/10\n",
      "5158/5158 [==============================] - 80s 16ms/step - loss: 0.1848 - accuracy: 0.9390 - weighted_accuracy: 0.9390 - val_loss: 0.2564 - val_accuracy: 0.9201 - val_weighted_accuracy: 0.9201\n",
      "Epoch 4/10\n",
      "5158/5158 [==============================] - 80s 16ms/step - loss: 0.1579 - accuracy: 0.9479 - weighted_accuracy: 0.9479 - val_loss: 0.2759 - val_accuracy: 0.9189 - val_weighted_accuracy: 0.9189\n",
      "Epoch 5/10\n",
      "5158/5158 [==============================] - 80s 16ms/step - loss: 0.1364 - accuracy: 0.9554 - weighted_accuracy: 0.9554 - val_loss: 0.3047 - val_accuracy: 0.9130 - val_weighted_accuracy: 0.9130\n",
      "Epoch 6/10\n",
      "5158/5158 [==============================] - 80s 16ms/step - loss: 0.1188 - accuracy: 0.9616 - weighted_accuracy: 0.9616 - val_loss: 0.3289 - val_accuracy: 0.9150 - val_weighted_accuracy: 0.9150\n",
      "Epoch 7/10\n",
      "5158/5158 [==============================] - 80s 16ms/step - loss: 0.1052 - accuracy: 0.9662 - weighted_accuracy: 0.9662 - val_loss: 0.3450 - val_accuracy: 0.9130 - val_weighted_accuracy: 0.9130\n",
      "Epoch 8/10\n",
      "5158/5158 [==============================] - 80s 16ms/step - loss: 0.0947 - accuracy: 0.9696 - weighted_accuracy: 0.9696 - val_loss: 0.3616 - val_accuracy: 0.9084 - val_weighted_accuracy: 0.9084\n",
      "Epoch 9/10\n",
      "5158/5158 [==============================] - 81s 16ms/step - loss: 0.0861 - accuracy: 0.9724 - weighted_accuracy: 0.9724 - val_loss: 0.4014 - val_accuracy: 0.9032 - val_weighted_accuracy: 0.9032\n",
      "Epoch 10/10\n",
      "5158/5158 [==============================] - 80s 16ms/step - loss: 0.0796 - accuracy: 0.9748 - weighted_accuracy: 0.9748 - val_loss: 0.4062 - val_accuracy: 0.9074 - val_weighted_accuracy: 0.9074\n",
      "3224/3224 [==============================] - 1s 389us/step\n"
     ]
    }
   ],
   "source": [
    "# # first, I will create a baseline model for the RNN test scenario with POS tags included.\n",
    "# # it will just be a simple model to begin with\n",
    "# model_simpleRNN = Sequential()\n",
    "# model_simpleRNN.add(Embedding(input_dim=len(tokenizer_RNN.word_index) + 1, output_dim=128, input_length=10))\n",
    "# model_simpleRNN.add(SimpleRNN(units=50))\n",
    "# model_simpleRNN.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "# #compile the model\n",
    "# model_simpleRNN.compile(\n",
    "#     loss='sparse_categorical_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy'],    \n",
    "#     weighted_metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# #fit the model\n",
    "# model_simpleRNN.fit(X_train_RNN, y_train_RNN, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# pred_simpleRNN = model_simpleRNN.predict(X_test_RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12b449c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.27      0.31      3198\n",
      "           1       0.22      0.14      0.17      4981\n",
      "           2       0.94      0.97      0.96     94969\n",
      "\n",
      "    accuracy                           0.91    103148\n",
      "   macro avg       0.51      0.46      0.48    103148\n",
      "weighted avg       0.89      0.91      0.90    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  865   545  1788]\n",
      " [  482   685  3814]\n",
      " [  994  1899 92076]]\n",
      "Accuracy: 0.907686043355179\n"
     ]
    }
   ],
   "source": [
    "# #classification metrics didnt work out as we are getting probabilities of each classification from the model\n",
    "# #to fix this, we will convert it to the predicted outcome using numpy [19]\n",
    "# pred_simpleRNN_converted = np.argmax(pred_simpleRNN, axis=1)\n",
    "\n",
    "# #evaluate results from the RNN\n",
    "# baseline_simpleRNN_report_POS = classification_report(y_test_RNN, pred_simpleRNN_converted)\n",
    "# baseline_simpleRNN_confusion_matrix_POS = confusion_matrix(y_test_RNN, pred_simpleRNN_converted)\n",
    "# baseline_simpleRNN_accuracy_POS = accuracy_score(y_test_RNN, pred_simpleRNN_converted)\n",
    "\n",
    "# #print the results\n",
    "# print(\"Classification Report:\\n\", baseline_simpleRNN_report_POS)\n",
    "# print(\"Confusion Matrix:\\n\", baseline_simpleRNN_confusion_matrix_POS)\n",
    "# print(\"Accuracy:\", baseline_simpleRNN_accuracy_POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b812398",
   "metadata": {},
   "source": [
    "No POS Tags and Model Developed for the baseline in this scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4df066cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5158/5158 [==============================] - 80s 15ms/step - loss: 0.2488 - accuracy: 0.9254 - weighted_accuracy: 0.9254 - val_loss: 0.2408 - val_accuracy: 0.9239 - val_weighted_accuracy: 0.9239\n",
      "Epoch 2/10\n",
      "5158/5158 [==============================] - 80s 16ms/step - loss: 0.2137 - accuracy: 0.9307 - weighted_accuracy: 0.9307 - val_loss: 0.2430 - val_accuracy: 0.9237 - val_weighted_accuracy: 0.9237\n",
      "Epoch 3/10\n",
      "5158/5158 [==============================] - 81s 16ms/step - loss: 0.1819 - accuracy: 0.9400 - weighted_accuracy: 0.9400 - val_loss: 0.2572 - val_accuracy: 0.9218 - val_weighted_accuracy: 0.9218\n",
      "Epoch 4/10\n",
      "5158/5158 [==============================] - 81s 16ms/step - loss: 0.1540 - accuracy: 0.9497 - weighted_accuracy: 0.9497 - val_loss: 0.2822 - val_accuracy: 0.9141 - val_weighted_accuracy: 0.9141\n",
      "Epoch 5/10\n",
      "5158/5158 [==============================] - 81s 16ms/step - loss: 0.1320 - accuracy: 0.9569 - weighted_accuracy: 0.9569 - val_loss: 0.3025 - val_accuracy: 0.9120 - val_weighted_accuracy: 0.9120\n",
      "Epoch 6/10\n",
      "5158/5158 [==============================] - 81s 16ms/step - loss: 0.1155 - accuracy: 0.9625 - weighted_accuracy: 0.9625 - val_loss: 0.3239 - val_accuracy: 0.9064 - val_weighted_accuracy: 0.9064\n",
      "Epoch 7/10\n",
      "5158/5158 [==============================] - 81s 16ms/step - loss: 0.1026 - accuracy: 0.9668 - weighted_accuracy: 0.9668 - val_loss: 0.3477 - val_accuracy: 0.9032 - val_weighted_accuracy: 0.9032\n",
      "Epoch 8/10\n",
      "5158/5158 [==============================] - 81s 16ms/step - loss: 0.0923 - accuracy: 0.9706 - weighted_accuracy: 0.9706 - val_loss: 0.3760 - val_accuracy: 0.9023 - val_weighted_accuracy: 0.9023\n",
      "Epoch 9/10\n",
      "5158/5158 [==============================] - 81s 16ms/step - loss: 0.0851 - accuracy: 0.9728 - weighted_accuracy: 0.9728 - val_loss: 0.3909 - val_accuracy: 0.8971 - val_weighted_accuracy: 0.8971\n",
      "Epoch 10/10\n",
      "5158/5158 [==============================] - 81s 16ms/step - loss: 0.0788 - accuracy: 0.9746 - weighted_accuracy: 0.9746 - val_loss: 0.3985 - val_accuracy: 0.9073 - val_weighted_accuracy: 0.9073\n",
      "3224/3224 [==============================] - 1s 392us/step\n"
     ]
    }
   ],
   "source": [
    "# # next, I will create a baseline model for the RNN test scenario with no POS tags included.\n",
    "# # it will just be a simple model to begin with\n",
    "# model_simpleRNN_noPOS = Sequential()\n",
    "# model_simpleRNN_noPOS.add(Embedding(input_dim=len(tokenizer_RNN_noPOS.word_index) + 1, output_dim=128, input_length=10))\n",
    "# model_simpleRNN_noPOS.add(SimpleRNN(units=50))\n",
    "# model_simpleRNN_noPOS.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "# #compile the model\n",
    "# model_simpleRNN_noPOS.compile(\n",
    "#     loss='sparse_categorical_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy'],    \n",
    "#     weighted_metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# #fit the model\n",
    "# model_simpleRNN_noPOS.fit(X_train_RNN_noPOS, y_train_RNN_noPOS, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# pred_simpleRNN_noPOS = model_simpleRNN_noPOS.predict(X_test_RNN_noPOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "263f908a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.26      0.30      3198\n",
      "           1       0.20      0.11      0.14      4981\n",
      "           2       0.94      0.97      0.96     94969\n",
      "\n",
      "    accuracy                           0.91    103148\n",
      "   macro avg       0.50      0.45      0.46    103148\n",
      "weighted avg       0.89      0.91      0.90    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  832   442  1924]\n",
      " [  477   530  3974]\n",
      " [ 1039  1704 92226]]\n",
      "Accuracy: 0.9073176406716562\n"
     ]
    }
   ],
   "source": [
    "# #classification metrics didnt work out as we are getting probabilities of each classification from the model\n",
    "# #to fix this, we will convert it to the predicted outcome using numpy [19]\n",
    "# pred_simpleRNN_noPOS_converted = np.argmax(pred_simpleRNN_noPOS, axis=1)\n",
    "\n",
    "# #evaluate results from the RNN\n",
    "# baseline_simpleRNN_noPOS_report_POS = classification_report(y_test_RNN_noPOS, pred_simpleRNN_noPOS_converted)\n",
    "# baseline_simpleRNN_noPOS_confusion_matrix_POS = confusion_matrix(y_test_RNN_noPOS, pred_simpleRNN_noPOS_converted)\n",
    "# baseline_simpleRNN_noPOS_accuracy_POS = accuracy_score(y_test_RNN_noPOS, pred_simpleRNN_noPOS_converted)\n",
    "\n",
    "# #print the results\n",
    "# print(\"Classification Report:\\n\", baseline_simpleRNN_noPOS_report_POS)\n",
    "# print(\"Confusion Matrix:\\n\", baseline_simpleRNN_noPOS_confusion_matrix_POS)\n",
    "# print(\"Accuracy:\", baseline_simpleRNN_noPOS_accuracy_POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a6ab65",
   "metadata": {},
   "source": [
    "This concludes the baseline model approximations and we can see that in both cases, the results seem to be overfitting the data. This can be seen because it is only getting reasonable accuracy, precision, and recall values for the positive case. This is likely due to the imbalanced dataset that we are working with. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b191db",
   "metadata": {},
   "source": [
    "### 7.4: Testing Imbalanced Data Fixes to Determine Best Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc39c8a",
   "metadata": {},
   "source": [
    "#### 7.4.1: Using SMOTE to resample the data and try and improve the imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9024e7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "# in order to try and improve the deep learning prediction model, I am going to implement \n",
    "# synthetic minority over-sampling technique (SMOTE) to try and produce more minority class data. \n",
    "#SMOTE generates samples fo rus to help balance the dataset. \n",
    "\n",
    "#first I will load my libraries in\n",
    "!pip install -U imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3353362",
   "metadata": {},
   "source": [
    "Starting with the POS Tagged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1a6536b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14271/14271 [==============================] - 223s 16ms/step - loss: 0.6367 - accuracy: 0.7334 - weighted_accuracy: 0.7334 - val_loss: 1.4128 - val_accuracy: 0.0103 - val_weighted_accuracy: 0.0103\n",
      "Epoch 2/10\n",
      "14271/14271 [==============================] - 227s 16ms/step - loss: 0.5328 - accuracy: 0.7764 - weighted_accuracy: 0.7764 - val_loss: 1.3718 - val_accuracy: 0.0329 - val_weighted_accuracy: 0.0329\n",
      "Epoch 3/10\n",
      "14271/14271 [==============================] - 228s 16ms/step - loss: 0.4959 - accuracy: 0.7890 - weighted_accuracy: 0.7890 - val_loss: 1.3003 - val_accuracy: 0.0686 - val_weighted_accuracy: 0.0686\n",
      "Epoch 4/10\n",
      "14271/14271 [==============================] - 230s 16ms/step - loss: 0.4699 - accuracy: 0.7987 - weighted_accuracy: 0.7987 - val_loss: 1.4344 - val_accuracy: 0.0484 - val_weighted_accuracy: 0.0484\n",
      "Epoch 5/10\n",
      "14271/14271 [==============================] - 228s 16ms/step - loss: 0.4503 - accuracy: 0.8064 - weighted_accuracy: 0.8064 - val_loss: 1.4498 - val_accuracy: 0.0751 - val_weighted_accuracy: 0.0751\n",
      "Epoch 6/10\n",
      "14271/14271 [==============================] - 228s 16ms/step - loss: 0.4347 - accuracy: 0.8126 - weighted_accuracy: 0.8126 - val_loss: 1.4875 - val_accuracy: 0.0930 - val_weighted_accuracy: 0.0930\n",
      "Epoch 7/10\n",
      "14271/14271 [==============================] - 226s 16ms/step - loss: 0.4220 - accuracy: 0.8180 - weighted_accuracy: 0.8180 - val_loss: 1.5534 - val_accuracy: 0.1091 - val_weighted_accuracy: 0.1091\n",
      "Epoch 8/10\n",
      "14271/14271 [==============================] - 229s 16ms/step - loss: 0.4118 - accuracy: 0.8232 - weighted_accuracy: 0.8232 - val_loss: 1.3630 - val_accuracy: 0.1646 - val_weighted_accuracy: 0.1646\n",
      "Epoch 9/10\n",
      "14271/14271 [==============================] - 229s 16ms/step - loss: 0.4032 - accuracy: 0.8267 - weighted_accuracy: 0.8267 - val_loss: 1.4740 - val_accuracy: 0.1583 - val_weighted_accuracy: 0.1583\n",
      "Epoch 10/10\n",
      "14271/14271 [==============================] - 229s 16ms/step - loss: 0.3960 - accuracy: 0.8305 - weighted_accuracy: 0.8305 - val_loss: 1.4957 - val_accuracy: 0.1524 - val_weighted_accuracy: 0.1524\n",
      "3224/3224 [==============================] - 1s 414us/step\n"
     ]
    }
   ],
   "source": [
    "# #I will oversample the data as the minority class is not being recognized well\n",
    "# # this was shown by training the model without any additional fine tuning and just the baseline preprocessing. \n",
    "# smote_RNN = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "# X_train_RNN_resampled, y_train_RNN_resampled = smote_RNN.fit_resample(X_train_RNN, y_train_RNN)\n",
    "\n",
    "# model_simpleRNN_smote = Sequential()\n",
    "# model_simpleRNN_smote.add(Embedding(input_dim=len(tokenizer_RNN.word_index) + 1, output_dim=128, input_length=10))\n",
    "# model_simpleRNN_smote.add(SimpleRNN(units=50))\n",
    "# model_simpleRNN_smote.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "# #compile the model\n",
    "# model_simpleRNN_smote.compile(\n",
    "#     loss='sparse_categorical_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy'],    \n",
    "#     weighted_metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# #fit the model\n",
    "# model_simpleRNN_smote.fit(X_train_RNN_resampled, y_train_RNN_resampled, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# pred_simpleRNN_smote = model_simpleRNN_smote.predict(X_test_RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3336692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.42      0.23      3198\n",
      "           1       0.14      0.10      0.12      4981\n",
      "           2       0.95      0.90      0.92     94969\n",
      "\n",
      "    accuracy                           0.85    103148\n",
      "   macro avg       0.41      0.48      0.42    103148\n",
      "weighted avg       0.88      0.85      0.86    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1349   347  1502]\n",
      " [ 1093   509  3379]\n",
      " [ 6317  2794 85858]]\n",
      "Accuracy: 0.8503897312599372\n"
     ]
    }
   ],
   "source": [
    "# pred_simpleRNN_converted_resampled = np.argmax(pred_simpleRNN_smote, axis=1)\n",
    "\n",
    "# #evaluate results from the RNN\n",
    "# baseline_simpleRNN_report_POS = classification_report(y_test_RNN, pred_simpleRNN_converted_resampled)\n",
    "# baseline_simpleRNN_confusion_matrix_POS = confusion_matrix(y_test_RNN, pred_simpleRNN_converted_resampled)\n",
    "# baseline_simpleRNN_accuracy_POS = accuracy_score(y_test_RNN, pred_simpleRNN_converted_resampled)\n",
    "\n",
    "# #print the results\n",
    "# print(\"Classification Report:\\n\", baseline_simpleRNN_report_POS)\n",
    "# print(\"Confusion Matrix:\\n\", baseline_simpleRNN_confusion_matrix_POS)\n",
    "# print(\"Accuracy:\", baseline_simpleRNN_accuracy_POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e7aa31",
   "metadata": {},
   "source": [
    "Next, I will perform the same but for the no POS tagging case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e93aaa93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14271/14271 [==============================] - 227s 16ms/step - loss: 0.6395 - accuracy: 0.7323 - weighted_accuracy: 0.7323 - val_loss: 1.3930 - val_accuracy: 0.0159 - val_weighted_accuracy: 0.0159\n",
      "Epoch 2/10\n",
      "14271/14271 [==============================] - 228s 16ms/step - loss: 0.5317 - accuracy: 0.7771 - weighted_accuracy: 0.7771 - val_loss: 1.3863 - val_accuracy: 0.0284 - val_weighted_accuracy: 0.0284\n",
      "Epoch 3/10\n",
      "14271/14271 [==============================] - 241s 17ms/step - loss: 0.4944 - accuracy: 0.7899 - weighted_accuracy: 0.7899 - val_loss: 1.3857 - val_accuracy: 0.0417 - val_weighted_accuracy: 0.0417\n",
      "Epoch 4/10\n",
      "14271/14271 [==============================] - 242s 17ms/step - loss: 0.4689 - accuracy: 0.7990 - weighted_accuracy: 0.7990 - val_loss: 1.3570 - val_accuracy: 0.0954 - val_weighted_accuracy: 0.0954\n",
      "Epoch 5/10\n",
      "14271/14271 [==============================] - 241s 17ms/step - loss: 0.4497 - accuracy: 0.8062 - weighted_accuracy: 0.8062 - val_loss: 1.4197 - val_accuracy: 0.1001 - val_weighted_accuracy: 0.1001\n",
      "Epoch 6/10\n",
      "14271/14271 [==============================] - 244s 17ms/step - loss: 0.4349 - accuracy: 0.8128 - weighted_accuracy: 0.8128 - val_loss: 1.3048 - val_accuracy: 0.1478 - val_weighted_accuracy: 0.1478\n",
      "Epoch 7/10\n",
      "14271/14271 [==============================] - 233s 16ms/step - loss: 0.4228 - accuracy: 0.8180 - weighted_accuracy: 0.8180 - val_loss: 1.5098 - val_accuracy: 0.0989 - val_weighted_accuracy: 0.0989\n",
      "Epoch 8/10\n",
      "14271/14271 [==============================] - 230s 16ms/step - loss: 0.4122 - accuracy: 0.8227 - weighted_accuracy: 0.8227 - val_loss: 1.4445 - val_accuracy: 0.1458 - val_weighted_accuracy: 0.1458\n",
      "Epoch 9/10\n",
      "14271/14271 [==============================] - 230s 16ms/step - loss: 0.4040 - accuracy: 0.8264 - weighted_accuracy: 0.8264 - val_loss: 1.4884 - val_accuracy: 0.1489 - val_weighted_accuracy: 0.1489\n",
      "Epoch 10/10\n",
      "14271/14271 [==============================] - 244s 17ms/step - loss: 0.3966 - accuracy: 0.8303 - weighted_accuracy: 0.8303 - val_loss: 1.5229 - val_accuracy: 0.1483 - val_weighted_accuracy: 0.1483\n",
      "3224/3224 [==============================] - 1s 410us/step\n"
     ]
    }
   ],
   "source": [
    "# #I will oversample the data as the minority class is not being recognized well\n",
    "# # this was shown by training the model without any additional fine tuning and just the baseline preprocessing. \n",
    "\n",
    "# smote_RNN_noPOS = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "# X_train_RNN_noPOS_resampled, y_train_RNN_noPOS_resampled = smote_RNN_noPOS.fit_resample(X_train_RNN_noPOS, y_train_RNN_noPOS)\n",
    "\n",
    "# model_simpleRNN_smote_noPOS = Sequential()\n",
    "# model_simpleRNN_smote_noPOS.add(Embedding(input_dim=len(tokenizer_RNN_noPOS.word_index) + 1, output_dim=128, input_length=10))\n",
    "# model_simpleRNN_smote_noPOS.add(SimpleRNN(units=50))\n",
    "# model_simpleRNN_smote_noPOS.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "\n",
    "# #compile the model\n",
    "# model_simpleRNN_smote_noPOS.compile(\n",
    "#     loss='sparse_categorical_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy'],    \n",
    "#     weighted_metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# #fit the model\n",
    "# model_simpleRNN_smote_noPOS.fit(X_train_RNN_noPOS_resampled, y_train_RNN_noPOS_resampled, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# pred_simpleRNN_smote_noPOS = model_simpleRNN_smote_noPOS.predict(X_test_RNN_noPOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59fbd157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.45      0.23      3198\n",
      "           1       0.15      0.14      0.14      4981\n",
      "           2       0.95      0.89      0.92     94969\n",
      "\n",
      "    accuracy                           0.84    103148\n",
      "   macro avg       0.42      0.49      0.43    103148\n",
      "weighted avg       0.89      0.84      0.86    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1434   437  1327]\n",
      " [ 1174   675  3132]\n",
      " [ 6701  3302 84966]]\n",
      "Accuracy: 0.8441753596773568\n"
     ]
    }
   ],
   "source": [
    "# pred_simpleRNN_noPOS_converted_resampled = np.argmax(pred_simpleRNN_smote_noPOS, axis=1)\n",
    "\n",
    "# #evaluate results from the RNN\n",
    "# baseline_simpleRNN_report_noPOS = classification_report(y_test_RNN_noPOS, pred_simpleRNN_noPOS_converted_resampled)\n",
    "# baseline_simpleRNN_confusion_matrix_noPOS = confusion_matrix(y_test_RNN_noPOS, pred_simpleRNN_noPOS_converted_resampled)\n",
    "# baseline_simpleRNN_accuracy_noPOS = accuracy_score(y_test_RNN_noPOS, pred_simpleRNN_noPOS_converted_resampled)\n",
    "\n",
    "# #print the results\n",
    "# print(\"Classification Report:\\n\", baseline_simpleRNN_report_noPOS)\n",
    "# print(\"Confusion Matrix:\\n\", baseline_simpleRNN_confusion_matrix_noPOS)\n",
    "# print(\"Accuracy:\", baseline_simpleRNN_accuracy_noPOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e2a527",
   "metadata": {},
   "source": [
    "In this case, the noPOS still is performing better, but the data still seems very overfit (this was confirmed by testing on the review types below as well). The data seems to now be overfit to the negative class though, so SMOTE has introduced some noise. Moving forward, while iterating through different techniques, I will only use the noPOS scenario, since throughout the report so far it has shown that the difference is very small, and the noPOS usually performs better. This will allow me to iterate through new methods more efficiently. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f8a35",
   "metadata": {},
   "source": [
    "#### 7.4.2: Adding L2 Normalization to the SMOTE resampled data to try and lower the potential for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9409dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7771a92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14271/14271 [==============================] - 244s 17ms/step - loss: 0.6392 - accuracy: 0.7350 - weighted_accuracy: 0.7350 - val_loss: 1.4643 - val_accuracy: 0.0118 - val_weighted_accuracy: 0.0118\n",
      "Epoch 2/10\n",
      "14271/14271 [==============================] - 241s 17ms/step - loss: 0.5381 - accuracy: 0.7765 - weighted_accuracy: 0.7765 - val_loss: 1.4285 - val_accuracy: 0.0134 - val_weighted_accuracy: 0.0134\n",
      "Epoch 3/10\n",
      "14271/14271 [==============================] - 245s 17ms/step - loss: 0.5028 - accuracy: 0.7887 - weighted_accuracy: 0.7887 - val_loss: 1.4156 - val_accuracy: 0.0113 - val_weighted_accuracy: 0.0113\n",
      "Epoch 4/10\n",
      "14271/14271 [==============================] - 244s 17ms/step - loss: 0.4793 - accuracy: 0.7963 - weighted_accuracy: 0.7963 - val_loss: 1.3780 - val_accuracy: 0.0689 - val_weighted_accuracy: 0.0689\n",
      "Epoch 5/10\n",
      "14271/14271 [==============================] - 248s 17ms/step - loss: 0.4611 - accuracy: 0.8030 - weighted_accuracy: 0.8030 - val_loss: 1.4821 - val_accuracy: 0.0436 - val_weighted_accuracy: 0.0436\n",
      "Epoch 6/10\n",
      "14271/14271 [==============================] - 250s 17ms/step - loss: 0.4468 - accuracy: 0.8083 - weighted_accuracy: 0.8083 - val_loss: 1.4980 - val_accuracy: 0.0530 - val_weighted_accuracy: 0.0530\n",
      "Epoch 7/10\n",
      "14271/14271 [==============================] - 248s 17ms/step - loss: 0.4348 - accuracy: 0.8130 - weighted_accuracy: 0.8130 - val_loss: 1.4934 - val_accuracy: 0.0466 - val_weighted_accuracy: 0.0466\n",
      "Epoch 8/10\n",
      "14271/14271 [==============================] - 249s 17ms/step - loss: 0.4245 - accuracy: 0.8171 - weighted_accuracy: 0.8171 - val_loss: 1.3844 - val_accuracy: 0.1057 - val_weighted_accuracy: 0.1057\n",
      "Epoch 9/10\n",
      "14271/14271 [==============================] - 248s 17ms/step - loss: 0.4166 - accuracy: 0.8205 - weighted_accuracy: 0.8205 - val_loss: 1.4315 - val_accuracy: 0.1221 - val_weighted_accuracy: 0.1221\n",
      "Epoch 10/10\n",
      "14271/14271 [==============================] - 236s 17ms/step - loss: 0.4093 - accuracy: 0.8238 - weighted_accuracy: 0.8238 - val_loss: 1.6171 - val_accuracy: 0.1071 - val_weighted_accuracy: 0.1071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x310e72e50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_simpleRNN_Normalized = Sequential()\n",
    "# model_simpleRNN_Normalized.add(Embedding(input_dim=len(tokenizer_RNN_noPOS.word_index) + 1, output_dim=128, input_length=10))\n",
    "# model_simpleRNN_Normalized.add(SimpleRNN(units=50))\n",
    "# model_simpleRNN_Normalized.add(Dense(64, activation='relu', kernel_regularizer=l2(0.0001), input_dim=(10,1)))\n",
    "# model_simpleRNN_Normalized.add(Dense(32, activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "# model_simpleRNN_Normalized.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# model_simpleRNN_Normalized.compile(\n",
    "#     loss='sparse_categorical_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy'],    \n",
    "#     weighted_metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# model_simpleRNN_Normalized.fit(X_train_RNN_noPOS_resampled, y_train_RNN_noPOS_resampled, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1106c4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3224/3224 [==============================] - 1s 411us/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.45      0.24      3198\n",
      "           1       0.16      0.08      0.11      4981\n",
      "           2       0.95      0.91      0.93     94969\n",
      "\n",
      "    accuracy                           0.86    103148\n",
      "   macro avg       0.42      0.48      0.43    103148\n",
      "weighted avg       0.88      0.86      0.87    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1434   268  1496]\n",
      " [ 1167   408  3406]\n",
      " [ 6184  1945 86840]]\n",
      "Accuracy: 0.8597549152673828\n"
     ]
    }
   ],
   "source": [
    "# # test predictions and get evaluation metrics\n",
    "# pred_simpleRNN_noPOS_normalized = model_simpleRNN_Normalized.predict(X_test_RNN_noPOS)\n",
    "\n",
    "# #convert back\n",
    "# pred_simpleRNN_noPOS_converted_normalized = np.argmax(pred_simpleRNN_noPOS_normalized, axis=1)\n",
    "\n",
    "# #evaluate results from the RNN\n",
    "# normalized_simpleRNN_report_noPOS = classification_report(y_test_RNN_noPOS, pred_simpleRNN_noPOS_converted_normalized)\n",
    "# normalized_simpleRNN_confusion_matrix_noPOS = confusion_matrix(y_test_RNN_noPOS, pred_simpleRNN_noPOS_converted_normalized)\n",
    "# normalized_simpleRNN_accuracy_noPOS = accuracy_score(y_test_RNN_noPOS, pred_simpleRNN_noPOS_converted_normalized)\n",
    "\n",
    "# #print the results\n",
    "# print(\"Classification Report:\\n\", normalized_simpleRNN_report_noPOS)\n",
    "# print(\"Confusion Matrix:\\n\", normalized_simpleRNN_confusion_matrix_noPOS)\n",
    "# print(\"Accuracy:\", normalized_simpleRNN_accuracy_noPOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0da92a",
   "metadata": {},
   "source": [
    "#### Part 7.4.3: Undersampling the majority class and using L2 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ace1d289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import RandomUnderSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad508221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "562/562 [==============================] - 9s 16ms/step - loss: 1.0122 - accuracy: 0.5929 - weighted_accuracy: 0.5929 - val_loss: 1.4901 - val_accuracy: 0.4402 - val_weighted_accuracy: 0.4402\n",
      "Epoch 2/10\n",
      "562/562 [==============================] - 9s 16ms/step - loss: 0.7480 - accuracy: 0.6722 - weighted_accuracy: 0.6722 - val_loss: 1.6932 - val_accuracy: 0.3386 - val_weighted_accuracy: 0.3386\n",
      "Epoch 3/10\n",
      "562/562 [==============================] - 9s 16ms/step - loss: 0.6158 - accuracy: 0.7540 - weighted_accuracy: 0.7540 - val_loss: 1.5607 - val_accuracy: 0.4400 - val_weighted_accuracy: 0.4400\n",
      "Epoch 4/10\n",
      "562/562 [==============================] - 9s 16ms/step - loss: 0.4736 - accuracy: 0.8271 - weighted_accuracy: 0.8271 - val_loss: 1.7571 - val_accuracy: 0.4343 - val_weighted_accuracy: 0.4343\n",
      "Epoch 5/10\n",
      "562/562 [==============================] - 9s 16ms/step - loss: 0.3744 - accuracy: 0.8682 - weighted_accuracy: 0.8682 - val_loss: 2.2881 - val_accuracy: 0.3540 - val_weighted_accuracy: 0.3540\n",
      "Epoch 6/10\n",
      "562/562 [==============================] - 9s 16ms/step - loss: 0.3054 - accuracy: 0.8964 - weighted_accuracy: 0.8964 - val_loss: 2.2559 - val_accuracy: 0.4209 - val_weighted_accuracy: 0.4209\n",
      "Epoch 7/10\n",
      "562/562 [==============================] - 9s 16ms/step - loss: 0.2564 - accuracy: 0.9158 - weighted_accuracy: 0.9158 - val_loss: 2.1930 - val_accuracy: 0.4273 - val_weighted_accuracy: 0.4273\n",
      "Epoch 8/10\n",
      "562/562 [==============================] - 9s 16ms/step - loss: 0.2203 - accuracy: 0.9294 - weighted_accuracy: 0.9294 - val_loss: 2.5911 - val_accuracy: 0.3873 - val_weighted_accuracy: 0.3873\n",
      "Epoch 9/10\n",
      "562/562 [==============================] - 9s 16ms/step - loss: 0.1924 - accuracy: 0.9401 - weighted_accuracy: 0.9401 - val_loss: 2.6977 - val_accuracy: 0.3742 - val_weighted_accuracy: 0.3742\n",
      "Epoch 10/10\n",
      "562/562 [==============================] - 9s 16ms/step - loss: 0.1721 - accuracy: 0.9476 - weighted_accuracy: 0.9476 - val_loss: 2.6769 - val_accuracy: 0.4188 - val_weighted_accuracy: 0.4188\n",
      "3224/3224 [==============================] - 1s 424us/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.46      0.15      3198\n",
      "           1       0.07      0.61      0.12      4981\n",
      "           2       0.99      0.42      0.59     94969\n",
      "\n",
      "    accuracy                           0.43    103148\n",
      "   macro avg       0.38      0.50      0.28    103148\n",
      "weighted avg       0.91      0.43      0.55    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1482  1578   138]\n",
      " [ 1504  3047   430]\n",
      " [14203 41132 39634]]\n",
      "Accuracy: 0.4281517819056114\n"
     ]
    }
   ],
   "source": [
    "# under_sampler = RandomUnderSampler(sampling_strategy='majority', random_state=42)\n",
    "# X_train_undersampled, y_train_undersampled = under_sampler.fit_resample(X_train_RNN_noPOS, y_train_RNN_noPOS)\n",
    "\n",
    "# model_simpleRNN_normalized_undersampled = Sequential()\n",
    "# model_simpleRNN_normalized_undersampled.add(Embedding(input_dim=len(tokenizer_RNN_noPOS.word_index) + 1, output_dim=128, input_length=10))\n",
    "# model_simpleRNN_normalized_undersampled.add(SimpleRNN(units=50))\n",
    "# model_simpleRNN_normalized_undersampled.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01), input_dim=(10,1)))\n",
    "# model_simpleRNN_normalized_undersampled.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "# model_simpleRNN_normalized_undersampled.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# model_simpleRNN_normalized_undersampled.compile(\n",
    "#     loss='sparse_categorical_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy'],    \n",
    "#     weighted_metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# model_simpleRNN_normalized_undersampled.fit(X_train_undersampled, y_train_undersampled, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# # test predictions and get evaluation metrics\n",
    "# pred_simpleRNN_noPOS_undersampled = model_simpleRNN_normalized_undersampled.predict(X_test_RNN_noPOS)\n",
    "\n",
    "# #convert back\n",
    "# pred_simpleRNN_noPOS_converted_undersampled = np.argmax(pred_simpleRNN_noPOS_undersampled, axis=1)\n",
    "\n",
    "# #evaluate results from the RNN\n",
    "# undersampled_normalized_simpleRNN_report_noPOS = classification_report(y_test_RNN_noPOS, pred_simpleRNN_noPOS_converted_undersampled)\n",
    "# undersampled_normalized_simpleRNN_confusion_matrix_noPOS = confusion_matrix(y_test_RNN_noPOS, pred_simpleRNN_noPOS_converted_undersampled)\n",
    "# undersampled_normalized_simpleRNN_accuracy_noPOS = accuracy_score(y_test_RNN_noPOS, pred_simpleRNN_noPOS_converted_undersampled)\n",
    "\n",
    "# #print the results\n",
    "# print(\"Classification Report:\\n\", undersampled_normalized_simpleRNN_report_noPOS)\n",
    "# print(\"Confusion Matrix:\\n\", undersampled_normalized_simpleRNN_confusion_matrix_noPOS)\n",
    "# print(\"Accuracy:\", undersampled_normalized_simpleRNN_accuracy_noPOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42467492",
   "metadata": {},
   "source": [
    "#### 7.4.4: No over or under sampling, just L2 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97be52cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5158/5158 [==============================] - 80s 15ms/step - loss: 0.2804 - accuracy: 0.9219 - weighted_accuracy: 0.9219 - val_loss: 0.2528 - val_accuracy: 0.9219 - val_weighted_accuracy: 0.9219\n",
      "Epoch 2/10\n",
      "5158/5158 [==============================] - 82s 16ms/step - loss: 0.2305 - accuracy: 0.9276 - weighted_accuracy: 0.9276 - val_loss: 0.2450 - val_accuracy: 0.9244 - val_weighted_accuracy: 0.9244\n",
      "Epoch 3/10\n",
      "5158/5158 [==============================] - 81s 16ms/step - loss: 0.2118 - accuracy: 0.9308 - weighted_accuracy: 0.9308 - val_loss: 0.2513 - val_accuracy: 0.9252 - val_weighted_accuracy: 0.9252\n",
      "Epoch 4/10\n",
      "5158/5158 [==============================] - 81s 16ms/step - loss: 0.1953 - accuracy: 0.9338 - weighted_accuracy: 0.9338 - val_loss: 0.2565 - val_accuracy: 0.9223 - val_weighted_accuracy: 0.9223\n",
      "Epoch 5/10\n",
      "5158/5158 [==============================] - 81s 16ms/step - loss: 0.1810 - accuracy: 0.9378 - weighted_accuracy: 0.9378 - val_loss: 0.2638 - val_accuracy: 0.9172 - val_weighted_accuracy: 0.9172\n",
      "Epoch 6/10\n",
      "5158/5158 [==============================] - 81s 16ms/step - loss: 0.1689 - accuracy: 0.9417 - weighted_accuracy: 0.9417 - val_loss: 0.2655 - val_accuracy: 0.9184 - val_weighted_accuracy: 0.9184\n",
      "Epoch 7/10\n",
      "5158/5158 [==============================] - 81s 16ms/step - loss: 0.1577 - accuracy: 0.9458 - weighted_accuracy: 0.9458 - val_loss: 0.2947 - val_accuracy: 0.9176 - val_weighted_accuracy: 0.9176\n",
      "Epoch 8/10\n",
      "5158/5158 [==============================] - 82s 16ms/step - loss: 0.1483 - accuracy: 0.9495 - weighted_accuracy: 0.9495 - val_loss: 0.3058 - val_accuracy: 0.9001 - val_weighted_accuracy: 0.9001\n",
      "Epoch 9/10\n",
      "5158/5158 [==============================] - 82s 16ms/step - loss: 0.1409 - accuracy: 0.9527 - weighted_accuracy: 0.9527 - val_loss: 0.2956 - val_accuracy: 0.9146 - val_weighted_accuracy: 0.9146\n",
      "Epoch 10/10\n",
      "5158/5158 [==============================] - 82s 16ms/step - loss: 0.1337 - accuracy: 0.9556 - weighted_accuracy: 0.9556 - val_loss: 0.3279 - val_accuracy: 0.9094 - val_weighted_accuracy: 0.9094\n",
      "3224/3224 [==============================] - 1s 431us/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.27      0.34      3198\n",
      "           1       0.21      0.15      0.18      4981\n",
      "           2       0.94      0.97      0.96     94969\n",
      "\n",
      "    accuracy                           0.91    103148\n",
      "   macro avg       0.54      0.46      0.49    103148\n",
      "weighted avg       0.89      0.91      0.90    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  858   653  1687]\n",
      " [  409   751  3821]\n",
      " [  599  2159 92211]]\n",
      "Accuracy: 0.909566836002637\n"
     ]
    }
   ],
   "source": [
    "model_simpleRNN_normalized_only = Sequential()\n",
    "model_simpleRNN_normalized_only.add(Embedding(input_dim=len(tokenizer_RNN_noPOS.word_index) + 1, output_dim=128, input_length=10))\n",
    "model_simpleRNN_normalized_only.add(SimpleRNN(units=50))\n",
    "model_simpleRNN_normalized_only.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01), input_dim=(10,1)))\n",
    "model_simpleRNN_normalized_only.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model_simpleRNN_normalized_only.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model_simpleRNN_normalized_only.compile(\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'],    \n",
    "    weighted_metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_simpleRNN_normalized_only.fit(X_train_RNN_noPOS, y_train_RNN_noPOS, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# test predictions and get evaluation metrics\n",
    "pred_simpleRNN_noPOS_normalized_only = model_simpleRNN_normalized_only.predict(X_test_RNN_noPOS)\n",
    "\n",
    "#convert back\n",
    "pred_simpleRNN_noPOS_normalized_only = np.argmax(pred_simpleRNN_noPOS_normalized_only, axis=1)\n",
    "\n",
    "#evaluate results from the RNN\n",
    "only_normalized_simpleRNN_report_noPOS = classification_report(y_test_RNN_noPOS, pred_simpleRNN_noPOS_normalized_only)\n",
    "only_normalized_simpleRNN_confusion_matrix_noPOS = confusion_matrix(y_test_RNN_noPOS, pred_simpleRNN_noPOS_normalized_only)\n",
    "only_normalized_simpleRNN_accuracy_noPOS = accuracy_score(y_test_RNN_noPOS, pred_simpleRNN_noPOS_normalized_only)\n",
    "\n",
    "#print the results\n",
    "print(\"Classification Report:\\n\", only_normalized_simpleRNN_report_noPOS)\n",
    "print(\"Confusion Matrix:\\n\", only_normalized_simpleRNN_confusion_matrix_noPOS)\n",
    "print(\"Accuracy:\", only_normalized_simpleRNN_accuracy_noPOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a29f9d",
   "metadata": {},
   "source": [
    "#### 7.4.5: Multiclass SMOTE oversampling for both negative and neutral and LSTM Model with L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a26579e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class '0': 12843 occurrences\n",
      "Class '1': 19207 occurrences\n",
      "Class '2': 380540 occurrences\n",
      "Class '0': 190270 occurrences\n",
      "Class '1': 190270 occurrences\n",
      "Class '2': 380540 occurrences\n",
      "Epoch 1/10\n",
      "9514/9514 [==============================] - 155s 16ms/step - loss: 0.5139 - accuracy: 0.8093 - weighted_accuracy: 0.8093 - val_loss: 2.3256 - val_accuracy: 1.2482e-04 - val_weighted_accuracy: 1.2482e-04\n",
      "Epoch 2/10\n",
      "9514/9514 [==============================] - 155s 16ms/step - loss: 0.4020 - accuracy: 0.8627 - weighted_accuracy: 0.8627 - val_loss: 2.4474 - val_accuracy: 4.4016e-04 - val_weighted_accuracy: 4.4016e-04\n",
      "Epoch 3/10\n",
      "9514/9514 [==============================] - 157s 17ms/step - loss: 0.3663 - accuracy: 0.8773 - weighted_accuracy: 0.8773 - val_loss: 2.4229 - val_accuracy: 3.0877e-04 - val_weighted_accuracy: 3.0877e-04\n",
      "Epoch 4/10\n",
      "9514/9514 [==============================] - 160s 17ms/step - loss: 0.3458 - accuracy: 0.8849 - weighted_accuracy: 0.8849 - val_loss: 2.4240 - val_accuracy: 8.8690e-04 - val_weighted_accuracy: 8.8690e-04\n",
      "Epoch 5/10\n",
      "9514/9514 [==============================] - 159s 17ms/step - loss: 0.3310 - accuracy: 0.8902 - weighted_accuracy: 0.8902 - val_loss: 2.2522 - val_accuracy: 0.0018 - val_weighted_accuracy: 0.0018\n",
      "Epoch 6/10\n",
      "9514/9514 [==============================] - 159s 17ms/step - loss: 0.3191 - accuracy: 0.8944 - weighted_accuracy: 0.8944 - val_loss: 2.6151 - val_accuracy: 0.0037 - val_weighted_accuracy: 0.0037\n",
      "Epoch 7/10\n",
      "9514/9514 [==============================] - 159s 17ms/step - loss: 0.3099 - accuracy: 0.8975 - weighted_accuracy: 0.8975 - val_loss: 2.4703 - val_accuracy: 0.0040 - val_weighted_accuracy: 0.0040\n",
      "Epoch 8/10\n",
      "9514/9514 [==============================] - 158s 17ms/step - loss: 0.3013 - accuracy: 0.9005 - weighted_accuracy: 0.9005 - val_loss: 2.4859 - val_accuracy: 0.0083 - val_weighted_accuracy: 0.0083\n",
      "Epoch 9/10\n",
      "9514/9514 [==============================] - 157s 16ms/step - loss: 0.2939 - accuracy: 0.9034 - weighted_accuracy: 0.9034 - val_loss: 2.3487 - val_accuracy: 0.0092 - val_weighted_accuracy: 0.0092\n",
      "Epoch 10/10\n",
      "9514/9514 [==============================] - 156s 16ms/step - loss: 0.2874 - accuracy: 0.9056 - weighted_accuracy: 0.9056 - val_loss: 2.4937 - val_accuracy: 0.0160 - val_weighted_accuracy: 0.0160\n",
      "3224/3224 [==============================] - 3s 884us/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.36      0.22      3198\n",
      "           1       0.26      0.14      0.19      4981\n",
      "           2       0.95      0.93      0.94     94969\n",
      "\n",
      "    accuracy                           0.88    103148\n",
      "   macro avg       0.46      0.48      0.45    103148\n",
      "weighted avg       0.89      0.88      0.88    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1153   600  1445]\n",
      " [  908   722  3351]\n",
      " [ 5042  1465 88462]]\n",
      "Accuracy: 0.8757998216155427\n"
     ]
    }
   ],
   "source": [
    "# #get the totals for multiclass smote\n",
    "# unique_values, counts = np.unique(y_train_RNN_noPOS, return_counts=True)\n",
    "# #print the values to check \n",
    "# for label, count in zip(unique_values, counts):\n",
    "#     print(f\"Class '{label}': {count} occurrences\")\n",
    "\n",
    "# #update the sampling dict for the smote analysis\n",
    "# sampling_dict = {0:190270, 1:190270, 2:380540}\n",
    "# smote_multi_RNN_noPOS = SMOTE(sampling_strategy=sampling_dict, random_state=42)\n",
    "# X_train_RNN_noPOS_multi, y_train_RNN_noPOS_multi = smote_multi_RNN_noPOS.fit_resample(X_train_RNN_noPOS, y_train_RNN_noPOS)\n",
    "\n",
    "# unique_values_multi, counts_multi = np.unique(y_train_RNN_noPOS_multi, return_counts=True)\n",
    "\n",
    "# for label, count in zip(unique_values_multi, counts_multi):\n",
    "#     print(f\"Class '{label}': {count} occurrences\")\n",
    "\n",
    "# model_simpleRNN_smote_multi_noPOS = Sequential()\n",
    "# model_simpleRNN_smote_multi_noPOS.add(Embedding(input_dim=len(tokenizer_RNN_noPOS.word_index) + 1, output_dim=128, input_length=10))\n",
    "# model_simpleRNN_smote_multi_noPOS.add(LSTM(units=50, kernel_regularizer=l2(0.001)))\n",
    "# model_simpleRNN_smote_multi_noPOS.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "\n",
    "# #compile the model\n",
    "# model_simpleRNN_smote_multi_noPOS.compile(\n",
    "#     loss='sparse_categorical_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy'],    \n",
    "#     weighted_metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# #fit the model\n",
    "# model_simpleRNN_smote_multi_noPOS.fit(X_train_RNN_noPOS_multi, y_train_RNN_noPOS_multi, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# pred_simpleRNN_smote_multi_noPOS = model_simpleRNN_smote_multi_noPOS.predict(X_test_RNN_noPOS)\n",
    "\n",
    "# pred_simpleRNN_noPOS_multi_resampled = np.argmax(pred_simpleRNN_smote_multi_noPOS, axis=1)\n",
    "\n",
    "# #evaluate results from the RNN\n",
    "# multi_simpleRNN_report_noPOS = classification_report(y_test_RNN_noPOS, pred_simpleRNN_noPOS_multi_resampled)\n",
    "# multi_simpleRNN_confusion_matrix_noPOS = confusion_matrix(y_test_RNN_noPOS, pred_simpleRNN_noPOS_multi_resampled)\n",
    "# multi_simpleRNN_accuracy_noPOS = accuracy_score(y_test_RNN_noPOS, pred_simpleRNN_noPOS_multi_resampled)\n",
    "\n",
    "# #print the results\n",
    "# print(\"Classification Report:\\n\", multi_simpleRNN_report_noPOS)\n",
    "# print(\"Confusion Matrix:\\n\", multi_simpleRNN_confusion_matrix_noPOS)\n",
    "# print(\"Accuracy:\", multi_simpleRNN_accuracy_noPOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92798003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Sequence: customer badly bad experience breakfast great employee restaurant really nice\n",
      "Decoded Sequence: investigation pleased manner hotel handled situation good location quiet room\n",
      "Decoded Sequence:         everything location\n",
      "Decoded Sequence: coffee shop work price per night totally unacceptable good location\n",
      "Decoded Sequence: money tiny room air conditioning dated decor good central location\n",
      "Decoded Sequence: work report morning evening cash machine order location helpful staff\n",
      "Decoded Sequence: wifi attention request made booking fourth stay last restaurant nice\n",
      "Decoded Sequence: help always proposing candy kid free apple water always available\n",
      "Decoded Sequence: room resemble shown website rear garden view bedroom wad pleasant\n",
      "Decoded Sequence: would change mattress doubt exactly two day sleep awful breakfast\n",
      "Decoded Sequence: smoking neither room noisey sleep wink either night central location\n",
      "Decoded Sequence:         nothing nothing\n",
      "Decoded Sequence: neighbourhood night also breakfast recommended varied enough poor quality positive\n",
      "Decoded Sequence: bitten bed bug place tiny particularly clean staff apathetic location\n",
      "Decoded Sequence: ok frill business stopover london definitely recommended holiday stay london\n",
      "Decoded Sequence:    staff bed room breakfast really bad nothing\n",
      "Decoded Sequence: manager interested said help worst hotel experience six month nothing\n",
      "Decoded Sequence: poor choice far away center city minute walking metro station\n",
      "Decoded Sequence: hotel star opinion dirty dated grubby shame beautiful building much\n",
      "Decoded Sequence: little thing enterance gym towel gym internet etc close client\n",
      "Decoded Sequence: expensive breakfast weak water pressure shower toilet brush location wifi\n",
      "Decoded Sequence: regarding issue warned hotel located centrally london making easy travel\n",
      "Decoded Sequence: overlooking parking lot positive note carlos service charming maitre positive\n",
      "Decoded Sequence: night good size rat calmly scouting area outside window central\n",
      "Decoded Sequence:  convenient location bad service bad staff need renovation badly\n",
      "Decoded Sequence:    negative bedroom small feel like star hotel\n",
      "Decoded Sequence: magnificent view barcelona great food lovely staff definitely worthy star\n",
      "Decoded Sequence: definitely way public description give par poor travel lodge positive\n",
      "Decoded Sequence:     unfriendly staff reception surrounding bad positive\n",
      "Decoded Sequence: bad smell around ahotel service terrible like anything everything baddddd\n",
      "Decoded Sequence: stayed year ago great time different time would go back\n",
      "Decoded Sequence: hair well good value money false advertising expensive get positive\n",
      "Decoded Sequence:      made prepay whole stay positive\n",
      "Decoded Sequence: rare weekend away marred choosing stay grange bloom comfortable bed\n",
      "Decoded Sequence: line inquire reception issue ended ordering eating around room clean\n",
      "Decoded Sequence: short walk london eye london aquarium waterloo station house parliament\n",
      "Decoded Sequence:   food staff location room etc overall quite disappointing\n",
      "Decoded Sequence: mouse room staff even care fair say never staying location\n",
      "Decoded Sequence: restaurant friendly breakfast nice location bad underground station outside hotel\n",
      "Decoded Sequence: treat u bad first room located bad weather london nice\n",
      "Decoded Sequence: staff miserable expensive go different hotel food drink pm location\n",
      "Decoded Sequence: bad food bad service wifi le available price value positive\n",
      "Decoded Sequence:     room smell bad smell wood positive\n",
      "Decoded Sequence:    eating degree room nothing except la seine\n",
      "Decoded Sequence:      old toilet bed everything location\n",
      "Decoded Sequence: took u club lounge spoke u location hotel far station\n",
      "Decoded Sequence: poor rude service horrible food small room window aircon nothing\n",
      "Decoded Sequence: enough looking luxury contemporary style book standard double might dissapointed\n",
      "Decoded Sequence: like style dated good way coming back stylie kinda way\n",
      "Decoded Sequence: would never ever recommend hotel anyone fact stay well away\n",
      "Decoded Sequence: shocked naked woman picture wall strong theme whithout knowing positive\n",
      "Decoded Sequence: front gigantic repeater tower dissapointed nothing old property money spent\n",
      "Decoded Sequence:    room facility people fold bed acceptable positive\n",
      "Decoded Sequence: picture shown website price really expensive kind quality location center\n",
      "Decoded Sequence: working nice end extremely disappointed wished stayed way priced positive\n",
      "Decoded Sequence: receptionist last time look care friend room mobile stolen positive\n",
      "Decoded Sequence: saying atithi devo bhavo guest divine rare today world glimpse\n",
      "Decoded Sequence: cleaner service room properly rubbish cleared bed made properly nothing\n",
      "Decoded Sequence: staff poor construction right outside window hated every second hotel\n",
      "Decoded Sequence:        almost everything nothing\n",
      "Decoded Sequence: rate one night euro deceiving rate hotel star hotel nothing\n",
      "Decoded Sequence: rate even think come warn everyone read review disappointed nothing\n",
      "Decoded Sequence: nothing instructed report police even stolen property new room ok\n",
      "Decoded Sequence: broken shower tray star advertised surly uninterested staff recommended much\n",
      "Decoded Sequence:      whole hotel poor return positive\n",
      "Decoded Sequence:        location dirty nothing\n",
      "Decoded Sequence: towel bed suite warm small shower deffective nothing likeable hotel\n",
      "Decoded Sequence: one informed u building work done noisy dusty bar facility\n",
      "Decoded Sequence: burned towel warmer bathroom front desk first aid bad hotel\n",
      "Decoded Sequence: get actual room staff friendly think twice booking place positive\n",
      "Decoded Sequence:      room smell mold breakfast nice\n",
      "Decoded Sequence: room facility plus side emilio check exceptional xander check efficient\n",
      "Decoded Sequence: bed old room would never book hotel need renovation positive\n",
      "Decoded Sequence: went reception made several complaint worst stay ever hotel positive\n",
      "Decoded Sequence: wifi working staff know hotel bad near madeleine centre paris\n",
      "Decoded Sequence: door lift booked ground cross road go breakfast staff lovely\n",
      "Decoded Sequence: gone wrong carpet grubby room dirty bathroom horrible location good\n",
      "Decoded Sequence:         everything nothing\n",
      "Decoded Sequence: day husband extremely upset wanted talk manager right away location\n",
      "Decoded Sequence: fave mould think belong old church breakfast good value money\n",
      "Decoded Sequence: sort party going late night appalling experience round good breakfast\n",
      "Decoded Sequence: need updated comparing neighbor hotel square hotel highly recommended location\n",
      "Decoded Sequence: unacceptably inconsistent service staff explanation come back hotel ever positive\n",
      "Decoded Sequence: arrived hotel rued u especially girl called karen room type\n",
      "Decoded Sequence: small star hotel even deserve star lovely kindly italian receptionist\n",
      "Decoded Sequence: say go arriving minute go change hotel paying hour nothing\n",
      "Decoded Sequence: plaster chipping wall blind dirty bedside lamp broken location good\n",
      "Decoded Sequence: seen sister hotel offered ground floor room refuse good breakfast\n",
      "Decoded Sequence: advise give hotel miss stayed running london marathon location great\n",
      "Decoded Sequence: departure safe room reception declined offer staff helpful great reception\n",
      "Decoded Sequence: checking people complaining reception different thing always dirty noisy location\n",
      "Decoded Sequence: hotel maximum star room nice soap old towel bed breakfast\n",
      "Decoded Sequence: old small room really bad wifi range unusable good location\n",
      "Decoded Sequence: never experienced anything like location good spacious bar nice view\n",
      "Decoded Sequence: refrigerator staff nice poor location car poor air conditionner positive\n",
      "Decoded Sequence: rating hotel best find far better value elsewhere nice lobby\n",
      "Decoded Sequence: reception threaten cause scene moved appalling attitude guest problem positive\n",
      "Decoded Sequence: manager would call day propose discount next time happen positive\n",
      "Decoded Sequence: apologise lack one even bottle water room recommend stay location\n",
      "Decoded Sequence:        much mention view\n",
      "Decoded Sequence:     noisy night sound proof room nothing\n",
      "Decoded Sequence:   dirty poor staff service poor hotel two star\n",
      "Decoded Sequence: front super bad come hotel far away city center positive\n",
      "Decoded Sequence: amenity adquate overall standard hotel given u good impression positive\n",
      "Decoded Sequence: heard air conditioning plant room terrible left morning bad positive\n",
      "Decoded Sequence: everyday day barley slept whole night location good thing hotel\n",
      "Decoded Sequence: moment awful room view depressing time bright shinny light lobby\n",
      "Decoded Sequence: care taken overall leg work get basic breakfast requirement clean\n",
      "Decoded Sequence: two star never use breakfast good many variety food served\n",
      "Decoded Sequence: central paris mile away full youth pavement night felt unsafe\n",
      "Decoded Sequence:     room smelly staff friendly helpful positive\n",
      "Decoded Sequence: water many polite old reception jimmy bad polite location ok\n",
      "Decoded Sequence: liked enterence slate italian decor bar area gave upmarket image\n",
      "Decoded Sequence: closed privacy builder avoid hotel may night stay room staff\n",
      "Decoded Sequence: etc staff able spoil everything accommodate room would come back\n",
      "Decoded Sequence: charge stupid reason security policy eiffel tower view room wished\n",
      "Decoded Sequence: hotel give amount money paid expected better hotel cinema good\n",
      "Decoded Sequence: sad room uncomfy pillow bad smell sheet towel nothing special\n",
      "Decoded Sequence: toilet loud flushing stay half price may think staying positive\n",
      "Decoded Sequence: ceiling tile bed could almost fall someone head time positive\n",
      "Decoded Sequence:      facility poor running water location\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Sequence:      small noisy room near paddington\n",
      "Decoded Sequence:    negative never truly uncomfortable huge waste money\n",
      "Decoded Sequence: club hotel spa relaxing day sunday staff really helpful friendly\n",
      "Decoded Sequence: location paid gbp night would liked pay half best positive\n",
      "Decoded Sequence: brush tissue paper check guy wanted charge u friendly positive\n",
      "Decoded Sequence: arrival furthermore room extremely small even open trolley space positive\n",
      "Decoded Sequence: last moment competition provides free wifi lead market follow positive\n",
      "Decoded Sequence: previous stay city enjoyed much better comfort lower price positive\n",
      "Decoded Sequence: provided better service hotel staff location good worth money paid\n",
      "Decoded Sequence: room complained said nothink else available think worth money pool\n",
      "Decoded Sequence: area paris fridge really hard move inside tiny space nothing\n",
      "Decoded Sequence: cheap cheap hotel holiday inn would better cheaper staff loby\n",
      "Decoded Sequence: nothing friendly helpful staff located right next gare de lyon\n",
      "Decoded Sequence: also night fire alarm rang un middle night breakfast bad\n",
      "Decoded Sequence: location awful far away city centre staff unhospitable comfortable bed\n",
      "Decoded Sequence: early morning made noise wake every day room clean tidy\n",
      "Decoded Sequence: direct light room outside really tiny room location wifi breakfast\n",
      "Decoded Sequence: like body lotion shower jam one nice staff reception location\n",
      "Decoded Sequence: also one reply back question asked online departure staff helpful\n",
      "Decoded Sequence: ever depressing return uk breakfast good helpful staff bed comfy\n",
      "Decoded Sequence: dangerous four star hotel two star maximum would recommed positive\n",
      "Decoded Sequence: overpriced average barely slept come back hard find something like\n",
      "Decoded Sequence:   bed short complained helped ill informed staff positive\n",
      "Decoded Sequence: feel secure room moved complaining better first still mile reception\n",
      "Decoded Sequence: immediately otherwise forced bank contact bank collect amount thank positive\n",
      "Decoded Sequence: water seriously annoyed logged complaint best western get resolved positive\n",
      "Decoded Sequence: walk subway worth money worth four star hotel grade location\n",
      "Decoded Sequence: booking com kind proffesinal kind recepcionist muhamed one tall woman\n",
      "Decoded Sequence: still ready one bothered nothing like amenity like tesco close\n",
      "Decoded Sequence: minute better use bus service room clean need refurbishment positive\n",
      "Decoded Sequence: overall dirty carpet threadbare view room iterated room like positive\n",
      "Decoded Sequence: feel treatment due false advertising single room double room disgraceful\n",
      "Decoded Sequence: using language check never stay close eiffel tower actually much\n",
      "Decoded Sequence:       room small star nothing\n",
      "Decoded Sequence:      hot water half stay location\n",
      "Decoded Sequence: staying wanted check refused refund money paid credit card nothing\n",
      "Decoded Sequence:       breakfast bad bed conformable\n",
      "Decoded Sequence: u poker face always knew smile rest room big one\n",
      "Decoded Sequence: person night room really small location nice really close tube\n",
      "Decoded Sequence: room sounded like lung falling nose cooling draft broken window\n",
      "Decoded Sequence:      sheet clean room small positive\n",
      "Decoded Sequence: check inn room ready rate high room type poor location\n",
      "Decoded Sequence: walked two complained food wonder kept recommended struggling think really\n",
      "Decoded Sequence: shabby state electric heating room bathroom cold night good year\n",
      "Decoded Sequence: place thanks great central location tower bridge bank surrounding area\n",
      "Decoded Sequence: money place overrated used good day new management lack competence\n",
      "Decoded Sequence: day dirty breakfast coffee quite bad never ready shower good\n",
      "Decoded Sequence:     cleanliness amenity food service view location\n",
      "Decoded Sequence: basement room window open hotel laundry room wi fi service\n",
      "Decoded Sequence:        attitude bad attitude\n",
      "Decoded Sequence: wire shower room plumbing extremely noisey unable sleep morning positive\n",
      "Decoded Sequence:        every think positive\n",
      "Decoded Sequence: breakfast room dirty front door broken day breakfast choice good\n",
      "Decoded Sequence: birthday free upgrade julie kindly sent cake husband th birthday\n",
      "Decoded Sequence: disruption reception lounge area definitely star worth price charged location\n",
      "Decoded Sequence: executive dirty disgusted bathroom curtain room riped location location location\n",
      "Decoded Sequence:        unfriendly reception nothing\n",
      "Decoded Sequence: hair bed arrived small toilet crazily heavy door nothing particular\n",
      "Decoded Sequence: pool seating area spa pool proper access useful location needed\n",
      "Decoded Sequence:       staff rude abrupt location\n",
      "Decoded Sequence: hotel put pay euro unfair shame staff disappointed nothing special\n",
      "Decoded Sequence: small reduced stay night would never return substandard level positive\n",
      "Decoded Sequence: bedroom bathroom staff seems disinterested client need generally disappointing positive\n",
      "Decoded Sequence: location would advise hotel even tp think stay next time\n",
      "Decoded Sequence:    staff service resturant location value money like\n",
      "Decoded Sequence: hotel breakfast time one thing others another depending waiter positive\n",
      "Decoded Sequence: water service euro water leakage shower room relatively close center\n",
      "Decoded Sequence:    executive lounge tell u booked near wembley\n",
      "Decoded Sequence: room uncomfortable bed full cimex recommended never go back positive\n",
      "Decoded Sequence: apologize something morning disturbed situation therefore satisfied stay hotel positive\n",
      "Decoded Sequence:  reception encargada mal amable poco sttention al cliente positive\n",
      "Decoded Sequence: go narrow corridor breakfast disappointing little choice fresh bread positive\n",
      "Decoded Sequence:     expensive cold room bat hroom area\n",
      "Decoded Sequence: hotel lost money came sick b cause smell freezing room\n",
      "Decoded Sequence:    small tiny shoe box room small room\n",
      "Decoded Sequence:      negative good localization friendly staff\n",
      "Decoded Sequence: next morning answer decided walk sleeping worst hotel ever positive\n",
      "Decoded Sequence:    working street front window allow sleep nothing\n",
      "Decoded Sequence: lower floor sound good f hotel surroundings location proximity meeting\n",
      "Decoded Sequence: please look somewhere else downstairs lobby inviting allowed u relax\n",
      "Decoded Sequence: greasy potatis like would traveling business nothing like except location\n",
      "Decoded Sequence: request staff reception hostile kindly requesting remove hotel list nothing\n",
      "Decoded Sequence:         everything nothing\n",
      "Decoded Sequence: management must work get rid rat infestation location hotel nice\n",
      "Decoded Sequence: brought small radiator value money ved paid worth style room\n",
      "Decoded Sequence: provide u single bed added together hence uncomfortable sleep positive\n",
      "Decoded Sequence: ask anyone reconsider whether stay hostel think choice groningen positive\n",
      "Decoded Sequence: everything poor wall paper thin hotel smell musty never stay\n",
      "Decoded Sequence: public capark verrrry expensive beer average euro pint good breajfast\n",
      "Decoded Sequence: room looked better picture reality poor condition furniture bathroom positive\n",
      "Decoded Sequence:   restaurant availability reception staff seriously overpriced nothing particular\n",
      "Decoded Sequence: bedding scaffolding outside room sheer drop safety bar location fair\n",
      "Decoded Sequence: got hotel arena doesnt deliver four star promise bed nice\n",
      "Decoded Sequence: heat little bit middle night wake call ask heathing nothing\n",
      "Decoded Sequence: stop work lodged complaint writing thinking taking legal recourse positive\n",
      "Decoded Sequence: left like stuff messed ridiculous situation ever met nice location\n",
      "Decoded Sequence:    room dirty tired uncomfortable tiny location good\n",
      "Decoded Sequence: allowed bed freely move hotel memory foam pillow welcome plus\n",
      "Decoded Sequence: excellent position near boulevard saint germain quiet wonderful place stay\n",
      "Decoded Sequence: news paper international tv channel etcs almost nothing sorry say\n",
      "Decoded Sequence: fact maid stop knocking door even awake disturb sign door\n",
      "Decoded Sequence:    poor cummunication room smallest room ever stayed\n",
      "Decoded Sequence: euro per day would expected better service location nothing else\n",
      "Decoded Sequence:         staff bfast\n",
      "Decoded Sequence: pay breakfast parking thought included staff breakfast area extremely helpful\n",
      "Decoded Sequence: bathroom person door hole near lock din look stable location\n",
      "Decoded Sequence: really disappointed staff hotel star far star hotel location ok\n",
      "Decoded Sequence: min check time min ridiculous would nice shower worked tv\n",
      "Decoded Sequence: go hotel one thing dont try turn ac nothing like\n",
      "Decoded Sequence:      manager behavior breakfast dirt location\n",
      "Decoded Sequence: least got plenty warm water staff nice maded best could\n",
      "Decoded Sequence: mini bar free price pay room breakfast absolute joke much\n",
      "Decoded Sequence: door corridor stayed hundred hotel room top worst experience positive\n",
      "Decoded Sequence:       low quality room positive\n",
      "Decoded Sequence: thing actually liked waiter sport bar helpful food also nice\n",
      "Decoded Sequence: chargable green algae ground dirt whirlpool area worthy classification location\n",
      "Decoded Sequence: com site unhappy use booking com matter resolved full nothing\n",
      "Decoded Sequence:        cleanliness awful positive\n",
      "Decoded Sequence: clean also noise people walking floor outside room annoying positive\n",
      "Decoded Sequence: sleep though given price review would possible location liverpool street\n",
      "Decoded Sequence: five start hotel definitely worth four star bed view nice\n",
      "Decoded Sequence: acces via car elevator kinda cool coolest part stay actually\n",
      "Decoded Sequence: business travel staff experience value money per room stay nothing\n",
      "Decoded Sequence: would asked money back leave quickly morning close euston station\n",
      "Decoded Sequence: room room like sauna despite air conditioning set lowest none\n",
      "Decoded Sequence: lot negative thing talk thing going say going back positive\n",
      "Decoded Sequence: last resort place stay bathroom new clean plenty hot wster\n",
      "Decoded Sequence: pay swimming water cleanest parking safe clear indication spacious room\n",
      "Decoded Sequence: looking room look elsewhere unbelievable different package get price positive\n",
      "Decoded Sequence:        room cold positive\n",
      "Decoded Sequence: stuffed paper towel poor housekeeping close underground helpful staff reception\n",
      "Decoded Sequence:  surroundings rate high offered room clean definitely requires updating\n",
      "Decoded Sequence: rubbish location rubbish gym rubbish staff rubbish restaurant stay nothing\n",
      "Decoded Sequence:    old run nog luxury facility pretentie location\n",
      "Decoded Sequence: adult child never stayed room small charge absolutely disgraceful positive\n",
      "Decoded Sequence: kitchen email three staff told differently whenever ask worst ever\n",
      "Decoded Sequence: felt like happens often would definitely never recommend return positive\n",
      "Decoded Sequence: become like international chain guest experience paramount stay nh positive\n",
      "Decoded Sequence: still high overall stay nightmare would recommend hotel anybody positive\n",
      "Decoded Sequence:  wifi room lot ladybird room room door broken positive\n",
      "Decoded Sequence:         everything nothing\n",
      "Decoded Sequence:         clean positive\n",
      "Decoded Sequence: two night price time better know next time though positive\n",
      "Decoded Sequence:       ignoring need client positive\n",
      "Decoded Sequence: hour later cold even toasted would recommend anyone bed comfy\n",
      "Decoded Sequence:   baggage lost go find air conditioner working positive\n",
      "Decoded Sequence: got discount checkout think terrible hotel convenient access via tube\n",
      "Decoded Sequence:         cheating location\n",
      "Decoded Sequence: relaxing place sightseeing day supermarket next door min tram stop\n",
      "Decoded Sequence: work day night like sauna room noisy could sleep staff\n",
      "Decoded Sequence: paid would expect lot better worse premier inn bed comfortable\n",
      "Decoded Sequence: food come great quality food uk use location good u\n",
      "Decoded Sequence:       small bathroom causy atmosfeer\n",
      "Decoded Sequence:       small room good location\n",
      "Decoded Sequence: smelled sweat drinking water room seriously extremely need renovation positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Sequence:       sweage coming bathroom nothing\n",
      "Decoded Sequence:  dislike indifference staff attitude towards costumer demand like location\n",
      "Decoded Sequence: lead passenger resulting charged fee paying using debit card positive\n",
      "Decoded Sequence: morning stay room ok size location good working near aldgate\n",
      "Decoded Sequence:   clup room give bed room dirty room location\n",
      "Decoded Sequence: week booking com check property promote nothing really bad experience\n",
      "Decoded Sequence: staff never go back nice location every thing modern clean\n",
      "Decoded Sequence:      rude staff bathroom filthy positive\n",
      "Decoded Sequence: properly mattress horrible fridge bathroom seat broken miserable elevator positive\n",
      "Decoded Sequence:       lousy hotel lousy hotel\n",
      "Decoded Sequence: cheaper case much better experience absolutely staying neither friend positive\n",
      "Decoded Sequence: family room make sofa bed bedding supplied ask time positive\n",
      "Decoded Sequence: decent temp tap stiff breakfast good good choice location great\n",
      "Decoded Sequence: flip flop stand complained management rude said nothing comfortable bed\n",
      "Decoded Sequence:      every thing bad hotel nothing\n",
      "Decoded Sequence:   old stuffy room star accommodation expensive parking positive\n",
      "Decoded Sequence:      ac room small recommend nothing\n",
      "Decoded Sequence: asked include housekeeping booking com rate poor service close rai\n",
      "Decoded Sequence: room room tiny bed comfortable bathroom smelled somewhere stay guess\n",
      "Decoded Sequence: superior double room small window location fine close metro station\n",
      "Decoded Sequence: arrival front desk staff nice staff hotel bar rude location\n",
      "Decoded Sequence: unit poor considering deluxe room needed complete refurbishment good location\n",
      "Decoded Sequence: staff fact two room booked together one floor floor location\n",
      "Decoded Sequence:         stuff positive\n",
      "Decoded Sequence:      reception attitude friendly helpful positive\n",
      "Decoded Sequence: told come back hotel without key receptionist almost let positive\n",
      "Decoded Sequence: show customer horrendous wifi non existent overall unpleasant stay positive\n",
      "Decoded Sequence:    expensive room shower toilet great condition positive\n",
      "Decoded Sequence:         everything nothing\n",
      "Decoded Sequence: would strongly advised anyone even start thinking visiting hotel positive\n",
      "Decoded Sequence: room case room rented served rmey martin bar many hotel\n",
      "Decoded Sequence: offer help move luggage new room apology anyone problem nothing\n",
      "Decoded Sequence: load digging road work going outside hotel tired looking location\n",
      "Decoded Sequence: bit small bathroom side leaving room bad cost night positive\n",
      "Decoded Sequence: also called cuple time main desk one picked age positive\n",
      "Decoded Sequence:     revise number star star claim positive\n",
      "Decoded Sequence: give written website place hotel good noisy food restaurant good\n",
      "Decoded Sequence:    please take away name hilton friendly stuff\n",
      "Decoded Sequence:       bedroom smelling smoke positive\n",
      "Decoded Sequence: night trip park lane mew shameful good thing hotel location\n",
      "Decoded Sequence:       small room chair positive\n",
      "Decoded Sequence: decor completely opposite previous visit price pretty good wifi tv\n",
      "Decoded Sequence: whole experience learned never fooled photo read review book positive\n",
      "Decoded Sequence: inn staff worst staff come across moody judgemental breakfast ok\n",
      "Decoded Sequence: trained cleaning room every day first time happened life location\n",
      "Decoded Sequence: could lot serious good location next train station good decor\n",
      "Decoded Sequence: scooped moan included price service breakfast reminded u cheap clean\n",
      "Decoded Sequence: basic room like photo online across road main train station\n",
      "Decoded Sequence: disapointed wouod recommend anyone sold something completely different actually positive\n",
      "Decoded Sequence: horrible study table room lobby area wasnt nice staff friendly\n",
      "Decoded Sequence:       staff rude friendly positive\n",
      "Decoded Sequence: mobile stolen start staff body helped ask police even nothing\n",
      "Decoded Sequence: panel painted strong volatile paint sleep window wide open positive\n",
      "Decoded Sequence: still inconvenient u surrounding area hotel made feel unsafe positive\n",
      "Decoded Sequence:         everything nothing\n",
      "Decoded Sequence: rubbish room small dark uncomfortable staff unhelpful location strange positive\n",
      "Decoded Sequence: shower protection staff booked u unfriendly smile helpfulness bed comfortable\n",
      "Decoded Sequence: caught chill back window night allowed u drop bag early\n",
      "Decoded Sequence:         everything positive\n",
      "Decoded Sequence: room covered cigarette smoke imbedded bed recommended family child positive\n",
      "Decoded Sequence: child bad room overpriced hotel bad experience hilton hotel positive\n",
      "Decoded Sequence: booking also ignore whole stuation really disappointed worest experience ever\n",
      "Decoded Sequence: u unimpressed overall worth money shell stay location city centre\n",
      "Decoded Sequence: plight protect belonging leaving room good spread breakfast big room\n",
      "Decoded Sequence:   manager one rudest people ever come across nothing\n",
      "Decoded Sequence: never recommend staying best western attitude towards customer satisfaction positive\n",
      "Decoded Sequence:  careful deposit nonrefundable say day back account believe positive\n",
      "Decoded Sequence: blood net curtain poorly decorated shabby broken air con positive\n",
      "Decoded Sequence: plug complaint still continue offer room best accommodation property positive\n",
      "Decoded Sequence: service food disgusting highly advice future customer refrain ordering anything\n",
      "Decoded Sequence:        room steer nothing\n",
      "Decoded Sequence: interior hotel please avoid keep money rude staff nothing avoid\n",
      "Decoded Sequence: service disgusting bathroom mould filthy looking appliance stay away location\n",
      "Decoded Sequence: hotel offered explanation safety communication hotel apology good convenient location\n",
      "Decoded Sequence: included basicaly price booking com anyway expensive part city positive\n",
      "Decoded Sequence: poor breakfast overcrowded brekfast room never gbp worth rate positive\n",
      "Decoded Sequence: bone easly tell bed quite big enough space sleep thing\n",
      "Decoded Sequence: curtain husband foot clamber bed good one night stopping positive\n",
      "Decoded Sequence:      croudy rest afternoon night nothing\n",
      "Decoded Sequence: clean noisy time hotel old value money strange star hotel\n",
      "Decoded Sequence: basement floor stuffy difficult ventilate breakfast decent staff welcoming friendly\n",
      "Decoded Sequence: room dirty torn overall awful location underground good thing hotel\n",
      "Decoded Sequence: carpet falling apart location great lot money pay place location\n",
      "Decoded Sequence: business people even carry stuff long holiday nothing remember like\n",
      "Decoded Sequence: restaurant big cover start row enough however return mentioned inside\n",
      "Decoded Sequence: hotel spa low one party thing paying entire amsterdam clean\n",
      "Decoded Sequence: even access air coffee loud young pay night basin u\n",
      "Decoded Sequence:       wifi english hotel bar\n",
      "Decoded Sequence: taxi offered hotel house light cancelled worry front bed positive\n",
      "Decoded Sequence: front overall stay view booked around way stop extremely quite\n",
      "Decoded Sequence: room customer updated description definitely rooftop brush want drink would\n",
      "Decoded Sequence: pillow whole better hour u well reception city bed bed\n",
      "Decoded Sequence:         cleanliness positive\n",
      "Decoded Sequence: reach complained pm stay accommodating coctails reception surrounding customer location\n",
      "Decoded Sequence: reception helpful room delighted lobby night room food spacious nothing\n",
      "Decoded Sequence:     size stayed familiar restaurant review positive\n",
      "Decoded Sequence: one fabulous believe queue lovely fault beautiful corridor booked one\n",
      "Decoded Sequence: weekend light get lovely breakfast safe one every staff nothing\n",
      "Decoded Sequence:  option neighbourhood replaced outside sat communal wanted extra restaurant\n",
      "Decoded Sequence: outstanding unpleasant bathroom access would evening change like socket lovely\n",
      "Decoded Sequence: overall walk bit around annoying reach beautiful free metro stay\n",
      "Decoded Sequence:        breakfast noisy positive\n",
      "Decoded Sequence: hotel daily relaxation close long water area top easy service\n",
      "Decoded Sequence: fifth ask everyday advice footpath pleasant park felt street downstairs\n",
      "Decoded Sequence:  back door offered duomo place room lounge bit one\n",
      "Decoded Sequence: night window pay want major comfort room staying shoulder weak\n",
      "Decoded Sequence: facility place room soft ev expensive night pulled near including\n",
      "Decoded Sequence: clean stay single without room reception cost leave nothing bottle\n",
      "Decoded Sequence: bit thought reception minute hear cost extra relented money open\n",
      "Decoded Sequence:        good station arrival\n",
      "Decoded Sequence: lift deluxe corner dusting elevator la got amsterdam huge nothing\n",
      "Decoded Sequence: overall extremely oiled soap helpful convenient shower building modern positive\n",
      "Decoded Sequence: get could helpful towel garlic delicious jacuzzi apart center u\n",
      "Decoded Sequence: awful shower probably booking disturbing absolutely manageress building theme welcome\n",
      "Decoded Sequence: survival appointed mini didnt neighbour since tea noisy tasted tiny\n",
      "Decoded Sequence: shower think royal day several service facility loved small negative\n",
      "Decoded Sequence: suite restaurant good never check believe pathetically recommendation experience food\n",
      "Decoded Sequence: wonderful back transport way fantastic pay also car leave made\n",
      "Decoded Sequence: small would  nice room meat extremely near mattress u\n",
      "Decoded Sequence: never ready seems variety bad card home sagrada still nothing\n",
      "Decoded Sequence: penalty especially staying day underground walking distance money amazing location\n",
      "Decoded Sequence:      service rail air bed positive\n",
      "Decoded Sequence: heating location per otherwise sink reial clogged whole sized felt\n",
      "Decoded Sequence: phonecalls pinot better open etc changed position lock ask also\n",
      "Decoded Sequence: kept helpful paid street bit around within refund fixed bed\n",
      "Decoded Sequence:     welcoming facility could shower brightness within\n",
      "Decoded Sequence: window location good poor charged direct u lot brilliant park\n",
      "Decoded Sequence: bed city staff ready moved conditioning hotel clean side connecting\n",
      "Decoded Sequence: bed bed home snooting de walk every price recommended breakfast\n",
      "Decoded Sequence: already returning right spectacular mosquito efficiency photo hotel high bed\n",
      "Decoded Sequence: person heating  breakfast next cater possible integrity attentive extra\n",
      "Decoded Sequence: sorry sleep arrival coffee car drink clean hole breakfast location\n",
      "Decoded Sequence: asked facility noisy wifi wall coffee beautiful still sink latex\n",
      "Decoded Sequence: tea stay printing better belittling appreciated posed air never bed\n",
      "Decoded Sequence: old luggage location try cold car window accurate opposite nothing\n",
      "Decoded Sequence: uber rd wait jumping quiet bathroom issue friend nicely negative\n",
      "Decoded Sequence: need sleep would properly stand close v drink station positive\n",
      "Decoded Sequence: station bathroom excellent main wasnt new walking staff ask rail\n",
      "Decoded Sequence: decorated guest spa extremely complementary best initial building sight restaurant\n",
      "Decoded Sequence: working got afterwards noisy charming atmosphere noisy broken lively positive\n",
      "Decoded Sequence: basic south anything de monday eat italian situated recommend positive\n",
      "Decoded Sequence: front central looked helpful modem keep overall location small take\n",
      "Decoded Sequence: n nothing gym spot repaired modern cost option size great\n",
      "Decoded Sequence:    great helpful hotel professional line bathroom helpful\n",
      "Decoded Sequence: could price comfortable tired london subway street european perfect coffee\n",
      "Decoded Sequence: elsewehere near taste size king worn friendly pressure hugh ready\n",
      "Decoded Sequence: property really find also free conditioning course comfortable door could\n",
      "Decoded Sequence:     around nice great room inside positive\n",
      "Decoded Sequence: tube deposit help cleanliness open earlier making breakfast one shrek\n",
      "Decoded Sequence: advertised later train safe knowing booking minute exactly room positive\n",
      "Decoded Sequence: gap nice nearly near fridge unique kensington rude clothes stay\n",
      "Decoded Sequence: refuse pot lovely friendly st romantic lovely good extra hotel\n",
      "Decoded Sequence:       negative ground far positive\n",
      "Decoded Sequence: thames somewhere friendly water small enjoyed window furniture theatre night\n",
      "Decoded Sequence: updating coffee reasonable fit although cool metro went hotel fault\n",
      "Decoded Sequence: hotel   room room excellent one cafe trashcan asked\n",
      "Decoded Sequence: need would need spacious extremely tranquil needed lot choice service\n",
      "Decoded Sequence:        time copthorne clean\n",
      "Decoded Sequence:    location twice pay decorated comfortable could around\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Sequence: drop time could bread negative negative none open place amazing\n",
      "Decoded Sequence: immediately ok walkable access work door room enthusiastic even lyon\n",
      "Decoded Sequence: london upgraded garden bit area lot central phone socket nothing\n",
      "Decoded Sequence: privacy stay knocking enough pm central traveller spot comfortable nice\n",
      "Decoded Sequence: nightmare tube staff able many different nothing gave friend well\n",
      "Decoded Sequence: first open require detail small enough get location bed lovely\n",
      "Decoded Sequence: stayed tiny look angle brother market large walking location bit\n",
      "Decoded Sequence: nest unique credit see contacted ever floor enough could positive\n",
      "Decoded Sequence: cleaning parking choice pudding room work night lovely light breakfast\n",
      "Decoded Sequence: dark taking gratuitously need needed well late girl walk important\n",
      "Decoded Sequence: everything lunch charged many travelling service comfortable staff back may\n",
      "Decoded Sequence: bed served handy got could view perfect positive size clean\n",
      "Decoded Sequence: destination minute delicious day failure explained designed well excellent airport\n",
      "Decoded Sequence: still complimentary packed worth cleanliness booked bread value per station\n",
      "Decoded Sequence:     staff hotel go staff excellent bathroom\n",
      "Decoded Sequence:         everything nothing\n",
      "Decoded Sequence: bread small located fantastic internet realy moment money metro position\n",
      "Decoded Sequence: bit internet particularly quiet bit location every city suffer walking\n",
      "Decoded Sequence: efficient space negative near coffee new use smile room comfy\n",
      "Decoded Sequence:         everything nothing\n",
      "Decoded Sequence: staff adjacent preparing groom particular leaving bit outlet helful stay\n",
      "Decoded Sequence: room positive already business want money friday dry definitely finally\n",
      "Decoded Sequence: cleanliness reception  everything roof scrambled torn cozy onward bring\n",
      "Decoded Sequence: modest remembered office buffet yet distance recommended hotel hotel good\n",
      "Decoded Sequence: bit go old spin amazing tired better one beyond breakfast\n"
     ]
    }
   ],
   "source": [
    "# # seemingly the data is always overfitting the training for multiple models I have tried \n",
    "# # i need to explore if the data being created is any good from SMOTE\n",
    "\n",
    "# negative_indices = np.where(y_train_RNN_noPOS_multi == 0)[0]\n",
    "\n",
    "# for i in range(12483, 12943):\n",
    "#     index = negative_indices[i]\n",
    "#     reverse_word_index = {v: k for k, v in tokenizer_RNN_noPOS.word_index.items()}\n",
    "#     decoded_sequence = [reverse_word_index.get(token, '') for token in X_train_RNN_noPOS_multi[index]]\n",
    "#     print(\"Decoded Sequence:\", ' '.join(decoded_sequence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99d3da1",
   "metadata": {},
   "source": [
    "There isn't anything crazy unusual with these reviews, as compared to the processed reviews from the original data, so seemingly these are ok for negative reviews. I will need to look into different techniques to try and improve the model prediction. I will try adjusting class weights to penalize the majority class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5799f19",
   "metadata": {},
   "source": [
    "#### 7.4.6: Class weights adjusted and bidirectional LSTM tested with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28054100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4757/4757 [==============================] - 136s 28ms/step - loss: 0.4982 - accuracy: 0.8153 - weighted_accuracy: 0.7931 - val_loss: 3.0324 - val_accuracy: 4.3359e-04 - val_weighted_accuracy: 4.3359e-04\n",
      "Epoch 2/10\n",
      "4757/4757 [==============================] - 134s 28ms/step - loss: 0.3810 - accuracy: 0.8753 - weighted_accuracy: 0.8500 - val_loss: 3.2635 - val_accuracy: 0.0023 - val_weighted_accuracy: 0.0023\n",
      "Epoch 3/10\n",
      "4757/4757 [==============================] - 140s 29ms/step - loss: 0.3358 - accuracy: 0.8920 - weighted_accuracy: 0.8676 - val_loss: 3.0088 - val_accuracy: 0.0050 - val_weighted_accuracy: 0.0050\n",
      "Epoch 4/10\n",
      "4757/4757 [==============================] - 144s 30ms/step - loss: 0.2974 - accuracy: 0.9044 - weighted_accuracy: 0.8818 - val_loss: 3.0358 - val_accuracy: 0.0246 - val_weighted_accuracy: 0.0246\n",
      "Epoch 5/10\n",
      "4757/4757 [==============================] - 135s 28ms/step - loss: 0.2591 - accuracy: 0.9161 - weighted_accuracy: 0.8962 - val_loss: 3.6745 - val_accuracy: 0.0278 - val_weighted_accuracy: 0.0278\n",
      "Epoch 6/10\n",
      "4757/4757 [==============================] - 141s 30ms/step - loss: 0.2225 - accuracy: 0.9276 - weighted_accuracy: 0.9107 - val_loss: 3.6852 - val_accuracy: 0.0558 - val_weighted_accuracy: 0.0558\n",
      "Epoch 7/10\n",
      "4757/4757 [==============================] - 145s 31ms/step - loss: 0.1888 - accuracy: 0.9377 - weighted_accuracy: 0.9238 - val_loss: 4.6309 - val_accuracy: 0.0595 - val_weighted_accuracy: 0.0595\n",
      "Epoch 8/10\n",
      "4757/4757 [==============================] - 137s 29ms/step - loss: 0.1588 - accuracy: 0.9467 - weighted_accuracy: 0.9354 - val_loss: 5.1625 - val_accuracy: 0.0792 - val_weighted_accuracy: 0.0792\n",
      "Epoch 9/10\n",
      "4757/4757 [==============================] - 139s 29ms/step - loss: 0.1320 - accuracy: 0.9551 - weighted_accuracy: 0.9464 - val_loss: 6.3186 - val_accuracy: 0.0843 - val_weighted_accuracy: 0.0843\n",
      "Epoch 10/10\n",
      "4757/4757 [==============================] - 144s 30ms/step - loss: 0.1097 - accuracy: 0.9625 - weighted_accuracy: 0.9559 - val_loss: 7.1371 - val_accuracy: 0.1001 - val_weighted_accuracy: 0.1001\n",
      "3224/3224 [==============================] - 8s 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.41      0.25      3198\n",
      "           1       0.19      0.18      0.18      4981\n",
      "           2       0.95      0.91      0.93     94969\n",
      "\n",
      "    accuracy                           0.86    103148\n",
      "   macro avg       0.44      0.50      0.45    103148\n",
      "weighted avg       0.89      0.86      0.87    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1307   616  1275]\n",
      " [ 1055   883  3043]\n",
      " [ 5020  3237 86712]]\n",
      "Accuracy: 0.86188777290883\n"
     ]
    }
   ],
   "source": [
    "# #adjust the class weights\n",
    "# class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_RNN_noPOS), y=y_train_RNN_noPOS_multi)\n",
    "# class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "# sample_weights = np.array([class_weights_dict[y] for y in y_train_RNN_noPOS_multi])\n",
    "\n",
    "# #will try a bi-directional LSTM model \n",
    "# model_RNN_bidirect_class_smote = Sequential()\n",
    "# model_RNN_bidirect_class_smote.add(Embedding(input_dim=len(tokenizer_RNN_noPOS.word_index) + 1, output_dim=128, input_length=10))\n",
    "# model_RNN_bidirect_class_smote.add(Bidirectional(LSTM(128)))\n",
    "# model_RNN_bidirect_class_smote.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# # Compile the model with the updated class weights\n",
    "# model_RNN_bidirect_class_smote.compile(\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     optimizer='adam',\n",
    "#     metrics=['accuracy'],\n",
    "#     weighted_metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# #fit the model\n",
    "# model_RNN_bidirect_class_smote.fit(X_train_RNN_noPOS_multi, y_train_RNN_noPOS_multi, epochs=10, batch_size=128, validation_split=0.2, sample_weight=sample_weights)\n",
    "\n",
    "# pred_RNN_bidirect_class_smote = model_RNN_bidirect_class_smote.predict(X_test_RNN_noPOS)\n",
    "\n",
    "# pred_converted_RNN_bidirect_class_smote = np.argmax(pred_RNN_bidirect_class_smote, axis=1)\n",
    "\n",
    "# #evaluate results from the RNN\n",
    "# report_model_RNN_bidirect_class_smote = classification_report(y_test_RNN_noPOS, pred_converted_RNN_bidirect_class_smote)\n",
    "# confusion_matrix_model_RNN_bidirect_class_smote = confusion_matrix(y_test_RNN_noPOS, pred_converted_RNN_bidirect_class_smote)\n",
    "# accuracy_model_RNN_bidirect_class_smote = accuracy_score(y_test_RNN_noPOS, pred_converted_RNN_bidirect_class_smote)\n",
    "\n",
    "# #print the results\n",
    "# print(\"Classification Report:\\n\", report_model_RNN_bidirect_class_smote)\n",
    "# print(\"Confusion Matrix:\\n\", confusion_matrix_model_RNN_bidirect_class_smote)\n",
    "# print(\"Accuracy:\", accuracy_model_RNN_bidirect_class_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3b03d0",
   "metadata": {},
   "source": [
    "#### 7.4.7: Class weights only with LSTM and L2 Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a43580fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.8780 - accuracy: 0.7258 - weighted_accuracy: 0.5839 - val_loss: 0.8343 - val_accuracy: 0.7262 - val_weighted_accuracy: 0.6120\n",
      "Epoch 2/10\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.7674 - accuracy: 0.7534 - weighted_accuracy: 0.6483 - val_loss: 0.8231 - val_accuracy: 0.7570 - val_weighted_accuracy: 0.6123\n",
      "Epoch 3/10\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.7039 - accuracy: 0.7697 - weighted_accuracy: 0.6922 - val_loss: 0.8694 - val_accuracy: 0.7282 - val_weighted_accuracy: 0.6062\n",
      "Epoch 4/10\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.6390 - accuracy: 0.7866 - weighted_accuracy: 0.7342 - val_loss: 0.9227 - val_accuracy: 0.7675 - val_weighted_accuracy: 0.5998\n",
      "Epoch 5/10\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.5724 - accuracy: 0.8001 - weighted_accuracy: 0.7719 - val_loss: 0.9632 - val_accuracy: 0.7437 - val_weighted_accuracy: 0.5944\n",
      "Epoch 6/10\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.5102 - accuracy: 0.8127 - weighted_accuracy: 0.8036 - val_loss: 1.0666 - val_accuracy: 0.7863 - val_weighted_accuracy: 0.5837\n",
      "Epoch 7/10\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.4546 - accuracy: 0.8256 - weighted_accuracy: 0.8296 - val_loss: 1.0868 - val_accuracy: 0.7188 - val_weighted_accuracy: 0.5821\n",
      "Epoch 8/10\n",
      "5158/5158 [==============================] - 84s 16ms/step - loss: 0.4070 - accuracy: 0.8378 - weighted_accuracy: 0.8512 - val_loss: 1.2380 - val_accuracy: 0.7772 - val_weighted_accuracy: 0.5730\n",
      "Epoch 9/10\n",
      "5158/5158 [==============================] - 84s 16ms/step - loss: 0.3676 - accuracy: 0.8487 - weighted_accuracy: 0.8702 - val_loss: 1.3972 - val_accuracy: 0.7597 - val_weighted_accuracy: 0.5728\n",
      "Epoch 10/10\n",
      "5158/5158 [==============================] - 84s 16ms/step - loss: 0.3338 - accuracy: 0.8596 - weighted_accuracy: 0.8839 - val_loss: 1.4303 - val_accuracy: 0.7537 - val_weighted_accuracy: 0.5668\n",
      "3224/3224 [==============================] - 3s 928us/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.48      0.29      3198\n",
      "           1       0.12      0.48      0.19      4981\n",
      "           2       0.98      0.77      0.86     94969\n",
      "\n",
      "    accuracy                           0.75    103148\n",
      "   macro avg       0.43      0.58      0.45    103148\n",
      "weighted avg       0.91      0.75      0.81    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1529  1180   489]\n",
      " [ 1210  2415  1356]\n",
      " [ 4656 16829 73484]]\n",
      "Accuracy: 0.7506495520998953\n"
     ]
    }
   ],
   "source": [
    "# # next I will try a new model architecture with class weights adjusted and L2 norm \n",
    "# class_weights_lstm = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_RNN_noPOS), y=y_train_RNN_noPOS)\n",
    "# class_weights_dict = {i: weight for i, weight in enumerate(class_weights_lstm)}\n",
    "# sample_weights = np.array([class_weights_dict[y] for y in y_train_RNN_noPOS])\n",
    "\n",
    "# model_class_norm_lstm = Sequential()\n",
    "# model_class_norm_lstm.add(Embedding(input_dim=len(tokenizer_RNN_noPOS.word_index) + 1, output_dim=128, input_length=10))\n",
    "# model_class_norm_lstm.add(LSTM(units=50))\n",
    "# model_class_norm_lstm.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01), input_dim=(10,1)))\n",
    "# model_class_norm_lstm.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "# model_class_norm_lstm.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# model_class_norm_lstm.compile(\n",
    "#     loss='sparse_categorical_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy'],    \n",
    "#     weighted_metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# model_class_norm_lstm.fit(X_train_RNN_noPOS, y_train_RNN_noPOS, epochs=10, batch_size=64, validation_split=0.2, sample_weight=sample_weights)\n",
    "\n",
    "# # test predictions and get evaluation metrics\n",
    "# pred_noPOS_class_norm_lstm = model_class_norm_lstm.predict(X_test_RNN_noPOS)\n",
    "\n",
    "# #convert back\n",
    "# pred_noPOS_class_norm_lstm_converted = np.argmax(pred_noPOS_class_norm_lstm, axis=1)\n",
    "\n",
    "# #evaluate results from the RNN\n",
    "# class_norm_lstm_report_noPOS = classification_report(y_test_RNN_noPOS, pred_noPOS_class_norm_lstm_converted)\n",
    "# class_norm_lstm_confusion_matrix_noPOS = confusion_matrix(y_test_RNN_noPOS, pred_noPOS_class_norm_lstm_converted)\n",
    "# class_norm_lstm_accuracy_noPOS = accuracy_score(y_test_RNN_noPOS, pred_noPOS_class_norm_lstm_converted)\n",
    "\n",
    "# #print the results\n",
    "# print(\"Classification Report:\\n\", class_norm_lstm_report_noPOS)\n",
    "# print(\"Confusion Matrix:\\n\", class_norm_lstm_confusion_matrix_noPOS)\n",
    "# print(\"Accuracy:\", class_norm_lstm_accuracy_noPOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99444952",
   "metadata": {},
   "source": [
    "#### 7.4.8: Same as above, but with L2 normalization first, then LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08c93ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5158/5158 [==============================] - 83s 16ms/step - loss: 0.8989 - accuracy: 0.6972 - weighted_accuracy: 0.5672 - val_loss: 0.8685 - val_accuracy: 0.6545 - val_weighted_accuracy: 0.5816\n",
      "Epoch 2/10\n",
      "5158/5158 [==============================] - 82s 16ms/step - loss: 0.8167 - accuracy: 0.7222 - weighted_accuracy: 0.6123 - val_loss: 0.8542 - val_accuracy: 0.7322 - val_weighted_accuracy: 0.5914\n",
      "Epoch 3/10\n",
      "5158/5158 [==============================] - 82s 16ms/step - loss: 0.7926 - accuracy: 0.7250 - weighted_accuracy: 0.6284 - val_loss: 0.8712 - val_accuracy: 0.7196 - val_weighted_accuracy: 0.5833\n",
      "Epoch 4/10\n",
      "5158/5158 [==============================] - 82s 16ms/step - loss: 0.7769 - accuracy: 0.7260 - weighted_accuracy: 0.6414 - val_loss: 0.8826 - val_accuracy: 0.6351 - val_weighted_accuracy: 0.5805\n",
      "Epoch 5/10\n",
      "5158/5158 [==============================] - 82s 16ms/step - loss: 0.7663 - accuracy: 0.7260 - weighted_accuracy: 0.6490 - val_loss: 0.9020 - val_accuracy: 0.7398 - val_weighted_accuracy: 0.5797\n",
      "Epoch 6/10\n",
      "5158/5158 [==============================] - 82s 16ms/step - loss: 0.7564 - accuracy: 0.7293 - weighted_accuracy: 0.6545 - val_loss: 0.9344 - val_accuracy: 0.7435 - val_weighted_accuracy: 0.5834\n",
      "Epoch 7/10\n",
      "5158/5158 [==============================] - 82s 16ms/step - loss: 0.7481 - accuracy: 0.7315 - weighted_accuracy: 0.6591 - val_loss: 0.8859 - val_accuracy: 0.6267 - val_weighted_accuracy: 0.5774\n",
      "Epoch 8/10\n",
      "5158/5158 [==============================] - 83s 16ms/step - loss: 0.7404 - accuracy: 0.7340 - weighted_accuracy: 0.6647 - val_loss: 0.8989 - val_accuracy: 0.6983 - val_weighted_accuracy: 0.5798\n",
      "Epoch 9/10\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.7341 - accuracy: 0.7345 - weighted_accuracy: 0.6664 - val_loss: 0.9000 - val_accuracy: 0.6861 - val_weighted_accuracy: 0.5785\n",
      "Epoch 10/10\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.7282 - accuracy: 0.7382 - weighted_accuracy: 0.6692 - val_loss: 0.9157 - val_accuracy: 0.6937 - val_weighted_accuracy: 0.5768\n",
      "3224/3224 [==============================] - 3s 749us/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.44      0.31      3198\n",
      "           1       0.10      0.60      0.17      4981\n",
      "           2       0.98      0.70      0.82     94969\n",
      "\n",
      "    accuracy                           0.69    103148\n",
      "   macro avg       0.44      0.58      0.44    103148\n",
      "weighted avg       0.91      0.69      0.77    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1407  1468   323]\n",
      " [  929  2974  1078]\n",
      " [ 3428 24647 66894]]\n",
      "Accuracy: 0.6909974017916004\n"
     ]
    }
   ],
   "source": [
    "# # next I will try a new model architecture with class weights adjusted and L2 norm and LSTM\n",
    "# class_weights_lstm = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_RNN_noPOS), y=y_train_RNN_noPOS)\n",
    "# class_weights_dict = {i: weight for i, weight in enumerate(class_weights_lstm)}\n",
    "# sample_weights = np.array([class_weights_dict[y] for y in y_train_RNN_noPOS])\n",
    "\n",
    "# model_class_norm_lstm_2 = Sequential()\n",
    "# model_class_norm_lstm_2.add(Embedding(input_dim=len(tokenizer_RNN_noPOS.word_index) + 1, output_dim=128, input_length=10))\n",
    "# model_class_norm_lstm_2.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01), input_dim=(10,1)))\n",
    "# model_class_norm_lstm_2.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "# model_class_norm_lstm_2.add(LSTM(units=50))\n",
    "# model_class_norm_lstm_2.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# model_class_norm_lstm_2.compile(\n",
    "#     loss='sparse_categorical_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy'],    \n",
    "#     weighted_metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# model_class_norm_lstm_2.fit(X_train_RNN_noPOS, y_train_RNN_noPOS, epochs=10, batch_size=64, validation_split=0.2, sample_weight=sample_weights)\n",
    "\n",
    "# # test predictions and get evaluation metrics\n",
    "# pred_noPOS_class_norm_lstm_2 = model_class_norm_lstm_2.predict(X_test_RNN_noPOS)\n",
    "\n",
    "# #convert back\n",
    "# pred_noPOS_class_norm_lstm_converted_2 = np.argmax(pred_noPOS_class_norm_lstm_2, axis=1)\n",
    "\n",
    "# #evaluate results from the RNN\n",
    "# class_norm_lstm_report_noPOS_2 = classification_report(y_test_RNN_noPOS, pred_noPOS_class_norm_lstm_converted_2)\n",
    "# class_norm_lstm_confusion_matrix_noPOS_2 = confusion_matrix(y_test_RNN_noPOS, pred_noPOS_class_norm_lstm_converted_2)\n",
    "# class_norm_lstm_accuracy_noPOS_2 = accuracy_score(y_test_RNN_noPOS, pred_noPOS_class_norm_lstm_converted_2)\n",
    "\n",
    "# #print the results\n",
    "# print(\"Classification Report:\\n\", class_norm_lstm_report_noPOS_2)\n",
    "# print(\"Confusion Matrix:\\n\", class_norm_lstm_confusion_matrix_noPOS_2)\n",
    "# print(\"Accuracy:\", class_norm_lstm_accuracy_noPOS_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b4831",
   "metadata": {},
   "source": [
    "#### 7.4.9: Trying class weights with Bi-directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4e63ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5158/5158 [==============================] - 90s 17ms/step - loss: 0.8972 - accuracy: 0.7156 - weighted_accuracy: 0.5758 - val_loss: 0.8563 - val_accuracy: 0.6829 - val_weighted_accuracy: 0.5993\n",
      "Epoch 2/10\n",
      "5158/5158 [==============================] - 89s 17ms/step - loss: 0.7987 - accuracy: 0.7322 - weighted_accuracy: 0.6335 - val_loss: 0.8720 - val_accuracy: 0.7885 - val_weighted_accuracy: 0.5906\n",
      "Epoch 3/10\n",
      "5158/5158 [==============================] - 89s 17ms/step - loss: 0.7614 - accuracy: 0.7387 - weighted_accuracy: 0.6613 - val_loss: 0.9019 - val_accuracy: 0.7712 - val_weighted_accuracy: 0.5893\n",
      "Epoch 4/10\n",
      "5158/5158 [==============================] - 89s 17ms/step - loss: 0.7309 - accuracy: 0.7478 - weighted_accuracy: 0.6852 - val_loss: 0.8846 - val_accuracy: 0.6401 - val_weighted_accuracy: 0.5839\n",
      "Epoch 5/10\n",
      "5158/5158 [==============================] - 91s 18ms/step - loss: 0.7051 - accuracy: 0.7545 - weighted_accuracy: 0.7037 - val_loss: 0.9064 - val_accuracy: 0.7665 - val_weighted_accuracy: 0.5807\n",
      "Epoch 6/10\n",
      "5158/5158 [==============================] - 92s 18ms/step - loss: 0.6829 - accuracy: 0.7597 - weighted_accuracy: 0.7156 - val_loss: 0.9617 - val_accuracy: 0.7727 - val_weighted_accuracy: 0.5804\n",
      "Epoch 7/10\n",
      "5158/5158 [==============================] - 90s 17ms/step - loss: 0.6605 - accuracy: 0.7656 - weighted_accuracy: 0.7270 - val_loss: 0.9708 - val_accuracy: 0.6792 - val_weighted_accuracy: 0.5690\n",
      "Epoch 8/10\n",
      "5158/5158 [==============================] - 91s 18ms/step - loss: 0.6389 - accuracy: 0.7704 - weighted_accuracy: 0.7396 - val_loss: 0.9699 - val_accuracy: 0.7183 - val_weighted_accuracy: 0.5836\n",
      "Epoch 9/10\n",
      "5158/5158 [==============================] - 91s 18ms/step - loss: 0.6206 - accuracy: 0.7754 - weighted_accuracy: 0.7496 - val_loss: 0.9872 - val_accuracy: 0.6708 - val_weighted_accuracy: 0.5723\n",
      "Epoch 10/10\n",
      "5158/5158 [==============================] - 91s 18ms/step - loss: 0.6079 - accuracy: 0.7791 - weighted_accuracy: 0.7532 - val_loss: 1.0228 - val_accuracy: 0.7305 - val_weighted_accuracy: 0.5740\n",
      "3224/3224 [==============================] - 4s 1ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.53      0.28      3198\n",
      "           1       0.11      0.46      0.17      4981\n",
      "           2       0.98      0.75      0.85     94969\n",
      "\n",
      "    accuracy                           0.73    103148\n",
      "   macro avg       0.42      0.58      0.43    103148\n",
      "weighted avg       0.91      0.73      0.80    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1685  1095   418]\n",
      " [ 1437  2301  1243]\n",
      " [ 5808 17925 71236]]\n",
      "Accuracy: 0.7292628068406561\n"
     ]
    }
   ],
   "source": [
    "# # next I will try a new model architecture with class weights adjusted and L2 norm and Bi-Directional LSTM\n",
    "# class_weights_bi_lstm = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_RNN_noPOS), y=y_train_RNN_noPOS)\n",
    "# class_weights_dict = {i: weight for i, weight in enumerate(class_weights_bi_lstm)}\n",
    "# sample_weights = np.array([class_weights_dict[y] for y in y_train_RNN_noPOS])\n",
    "\n",
    "# model_class_norm_lstm_bi = Sequential()\n",
    "# model_class_norm_lstm_bi.add(Embedding(input_dim=len(tokenizer_RNN_noPOS.word_index) + 1, output_dim=128, input_length=10))\n",
    "# model_class_norm_lstm_bi.add(Bidirectional(LSTM(units=50, kernel_regularizer=l2(0.01))))\n",
    "# model_class_norm_lstm_bi.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# model_class_norm_lstm_bi.compile(\n",
    "#     loss='sparse_categorical_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy'],    \n",
    "#     weighted_metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# model_class_norm_lstm_bi.fit(X_train_RNN_noPOS, y_train_RNN_noPOS, epochs=10, batch_size=64, validation_split=0.2, sample_weight=sample_weights)\n",
    "\n",
    "# # test predictions and get evaluation metrics\n",
    "# pred_noPOS_class_norm_lstm_bi = model_class_norm_lstm_bi.predict(X_test_RNN_noPOS)\n",
    "\n",
    "# #convert back\n",
    "# pred_noPOS_class_norm_lstm_converted_bi = np.argmax(pred_noPOS_class_norm_lstm_bi, axis=1)\n",
    "\n",
    "# #evaluate results from the RNN\n",
    "# class_norm_lstm_report_noPOS_bi = classification_report(y_test_RNN_noPOS, pred_noPOS_class_norm_lstm_converted_bi)\n",
    "# class_norm_lstm_confusion_matrix_noPOS_bi = confusion_matrix(y_test_RNN_noPOS, pred_noPOS_class_norm_lstm_converted_bi)\n",
    "# class_norm_lstm_accuracy_noPOS_bi = accuracy_score(y_test_RNN_noPOS, pred_noPOS_class_norm_lstm_converted_bi)\n",
    "\n",
    "# #print the results\n",
    "# print(\"Classification Report:\\n\", class_norm_lstm_report_noPOS_bi)\n",
    "# print(\"Confusion Matrix:\\n\", class_norm_lstm_confusion_matrix_noPOS_bi)\n",
    "# print(\"Accuracy:\", class_norm_lstm_accuracy_noPOS_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78846d2d",
   "metadata": {},
   "source": [
    "#### 7.4.10: Trying with same as above but GRU instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "672e0301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5158/5158 [==============================] - 83s 16ms/step - loss: 0.8827 - accuracy: 0.7136 - weighted_accuracy: 0.5835 - val_loss: 0.8475 - val_accuracy: 0.7263 - val_weighted_accuracy: 0.6013\n",
      "Epoch 2/10\n",
      "5158/5158 [==============================] - 84s 16ms/step - loss: 0.7952 - accuracy: 0.7337 - weighted_accuracy: 0.6366 - val_loss: 0.8451 - val_accuracy: 0.7173 - val_weighted_accuracy: 0.6013\n",
      "Epoch 3/10\n",
      "5158/5158 [==============================] - 84s 16ms/step - loss: 0.7610 - accuracy: 0.7403 - weighted_accuracy: 0.6602 - val_loss: 0.8743 - val_accuracy: 0.6316 - val_weighted_accuracy: 0.5850\n",
      "Epoch 4/10\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.7335 - accuracy: 0.7475 - weighted_accuracy: 0.6788 - val_loss: 0.8945 - val_accuracy: 0.7447 - val_weighted_accuracy: 0.5909\n",
      "Epoch 5/10\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.7107 - accuracy: 0.7541 - weighted_accuracy: 0.6915 - val_loss: 0.8988 - val_accuracy: 0.7439 - val_weighted_accuracy: 0.5861\n",
      "Epoch 6/10\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.6900 - accuracy: 0.7607 - weighted_accuracy: 0.7073 - val_loss: 0.9892 - val_accuracy: 0.7488 - val_weighted_accuracy: 0.5701\n",
      "Epoch 7/10\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.6710 - accuracy: 0.7668 - weighted_accuracy: 0.7183 - val_loss: 0.9518 - val_accuracy: 0.7678 - val_weighted_accuracy: 0.5853\n",
      "Epoch 8/10\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.6520 - accuracy: 0.7740 - weighted_accuracy: 0.7287 - val_loss: 0.9890 - val_accuracy: 0.7592 - val_weighted_accuracy: 0.5852\n",
      "Epoch 9/10\n",
      "5158/5158 [==============================] - 89s 17ms/step - loss: 0.6341 - accuracy: 0.7779 - weighted_accuracy: 0.7361 - val_loss: 1.0479 - val_accuracy: 0.7113 - val_weighted_accuracy: 0.5755\n",
      "Epoch 10/10\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.6179 - accuracy: 0.7813 - weighted_accuracy: 0.7454 - val_loss: 1.0403 - val_accuracy: 0.6851 - val_weighted_accuracy: 0.5710\n",
      "3224/3224 [==============================] - 2s 667us/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.56      0.23      3198\n",
      "           1       0.10      0.46      0.17      4981\n",
      "           2       0.98      0.70      0.82     94969\n",
      "\n",
      "    accuracy                           0.68    103148\n",
      "   macro avg       0.41      0.57      0.40    103148\n",
      "weighted avg       0.91      0.68      0.77    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1784  1089   325]\n",
      " [ 1657  2313  1011]\n",
      " [ 9037 19593 66339]]\n",
      "Accuracy: 0.6828634583317176\n"
     ]
    }
   ],
   "source": [
    "# # next I will try a new model architecture with class weights adjusted and L2 norm and GRU\n",
    "# class_weights_gru = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_RNN_noPOS), y=y_train_RNN_noPOS)\n",
    "# class_weights_dict = {i: weight for i, weight in enumerate(class_weights_gru)}\n",
    "# sample_weights = np.array([class_weights_dict[y] for y in y_train_RNN_noPOS])\n",
    "\n",
    "# model_class_norm_gru = Sequential()\n",
    "# model_class_norm_gru.add(Embedding(input_dim=len(tokenizer_RNN_noPOS.word_index) + 1, output_dim=128, input_length=10))\n",
    "# model_class_norm_gru.add(GRU(units=50, kernel_regularizer=l2(0.01)))\n",
    "# model_class_norm_gru.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# model_class_norm_gru.compile(\n",
    "#     loss='sparse_categorical_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy'],    \n",
    "#     weighted_metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# model_class_norm_gru.fit(X_train_RNN_noPOS, y_train_RNN_noPOS, epochs=10, batch_size=64, validation_split=0.2, sample_weight=sample_weights)\n",
    "\n",
    "# # test predictions and get evaluation metrics\n",
    "# pred_noPOS_class_norm_gru = model_class_norm_gru.predict(X_test_RNN_noPOS)\n",
    "\n",
    "# #convert back\n",
    "# pred_noPOS_class_norm_converted_gru = np.argmax(pred_noPOS_class_norm_gru, axis=1)\n",
    "\n",
    "# #evaluate results from the RNN\n",
    "# class_norm_lstm_report_noPOS_gru = classification_report(y_test_RNN_noPOS, pred_noPOS_class_norm_converted_gru)\n",
    "# class_norm_lstm_confusion_matrix_noPOS_gru = confusion_matrix(y_test_RNN_noPOS, pred_noPOS_class_norm_converted_gru)\n",
    "# class_norm_lstm_accuracy_noPOS_gru = accuracy_score(y_test_RNN_noPOS, pred_noPOS_class_norm_converted_gru)\n",
    "\n",
    "# #print the results\n",
    "# print(\"Classification Report:\\n\", class_norm_lstm_report_noPOS_gru)\n",
    "# print(\"Confusion Matrix:\\n\", class_norm_lstm_confusion_matrix_noPOS_gru)\n",
    "# print(\"Accuracy:\", class_norm_lstm_accuracy_noPOS_gru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be0c5f1",
   "metadata": {},
   "source": [
    "#### 7.4.11: SimpleRNN with class weights balanced and L2 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75e810d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5158/5158 [==============================] - 80s 15ms/step - loss: 0.9035 - accuracy: 0.7206 - weighted_accuracy: 0.5741 - val_loss: 0.8568 - val_accuracy: 0.7485 - val_weighted_accuracy: 0.5987\n",
      "Epoch 2/10\n",
      "5158/5158 [==============================] - 81s 16ms/step - loss: 0.7866 - accuracy: 0.7380 - weighted_accuracy: 0.6433 - val_loss: 0.8660 - val_accuracy: 0.7551 - val_weighted_accuracy: 0.5946\n",
      "Epoch 3/10\n",
      "5158/5158 [==============================] - 83s 16ms/step - loss: 0.7037 - accuracy: 0.7594 - weighted_accuracy: 0.7017 - val_loss: 0.8966 - val_accuracy: 0.6541 - val_weighted_accuracy: 0.5846\n",
      "Epoch 4/10\n",
      "5158/5158 [==============================] - 82s 16ms/step - loss: 0.6205 - accuracy: 0.7743 - weighted_accuracy: 0.7522 - val_loss: 0.9541 - val_accuracy: 0.7804 - val_weighted_accuracy: 0.5808\n",
      "Epoch 5/10\n",
      "5158/5158 [==============================] - 81s 16ms/step - loss: 0.5472 - accuracy: 0.7894 - weighted_accuracy: 0.7902 - val_loss: 1.0117 - val_accuracy: 0.7044 - val_weighted_accuracy: 0.5753\n",
      "Epoch 6/10\n",
      "5158/5158 [==============================] - 81s 16ms/step - loss: 0.4895 - accuracy: 0.8042 - weighted_accuracy: 0.8165 - val_loss: 1.1207 - val_accuracy: 0.7320 - val_weighted_accuracy: 0.5643\n",
      "Epoch 7/10\n",
      "5158/5158 [==============================] - 80s 16ms/step - loss: 0.4425 - accuracy: 0.8178 - weighted_accuracy: 0.8379 - val_loss: 1.2327 - val_accuracy: 0.7220 - val_weighted_accuracy: 0.5652\n",
      "Epoch 8/10\n",
      "5158/5158 [==============================] - 82s 16ms/step - loss: 0.4092 - accuracy: 0.8262 - weighted_accuracy: 0.8517 - val_loss: 1.2277 - val_accuracy: 0.6945 - val_weighted_accuracy: 0.5641\n",
      "Epoch 9/10\n",
      "5158/5158 [==============================] - 81s 16ms/step - loss: 0.3794 - accuracy: 0.8344 - weighted_accuracy: 0.8646 - val_loss: 1.2550 - val_accuracy: 0.7143 - val_weighted_accuracy: 0.5589\n",
      "Epoch 10/10\n",
      "5158/5158 [==============================] - 87s 17ms/step - loss: 0.3564 - accuracy: 0.8423 - weighted_accuracy: 0.8740 - val_loss: 1.3259 - val_accuracy: 0.6787 - val_weighted_accuracy: 0.5528\n",
      "3224/3224 [==============================] - 2s 468us/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.45      0.22      3198\n",
      "           1       0.10      0.52      0.17      4981\n",
      "           2       0.98      0.69      0.81     94969\n",
      "\n",
      "    accuracy                           0.68    103148\n",
      "   macro avg       0.41      0.56      0.40    103148\n",
      "weighted avg       0.91      0.68      0.76    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1453  1374   371]\n",
      " [ 1346  2579  1056]\n",
      " [ 7187 21874 65908]]\n",
      "Accuracy: 0.6780548338310001\n"
     ]
    }
   ],
   "source": [
    "# #adjust class weights than train with SimpleRNN\n",
    "# class_weights_simple = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_RNN_noPOS), y=y_train_RNN_noPOS)\n",
    "# class_weights_dict = {i: weight for i, weight in enumerate(class_weights_simple)}\n",
    "# sample_weights = np.array([class_weights_dict[y] for y in y_train_RNN_noPOS])\n",
    "\n",
    "# model_simpleRNN_normalized_class = Sequential()\n",
    "# model_simpleRNN_normalized_class.add(Embedding(input_dim=len(tokenizer_RNN_noPOS.word_index) + 1, output_dim=128, input_length=10))\n",
    "# model_simpleRNN_normalized_class.add(SimpleRNN(units=50))\n",
    "# model_simpleRNN_normalized_class.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01), input_dim=(10,1)))\n",
    "# model_simpleRNN_normalized_class.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "# model_simpleRNN_normalized_class.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# model_simpleRNN_normalized_class.compile(\n",
    "#     loss='sparse_categorical_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy'],    \n",
    "#     weighted_metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# model_simpleRNN_normalized_class.fit(X_train_RNN_noPOS, y_train_RNN_noPOS, epochs=10, batch_size=64, validation_split=0.2, sample_weight=sample_weights)\n",
    "\n",
    "# # test predictions and get evaluation metrics\n",
    "# pred_simpleRNN_noPOS_normalized_class = model_simpleRNN_normalized_class.predict(X_test_RNN_noPOS)\n",
    "\n",
    "# #convert back\n",
    "# pred_simpleRNN_noPOS_normalized_class_convert = np.argmax(pred_simpleRNN_noPOS_normalized_class, axis=1)\n",
    "\n",
    "# #evaluate results from the RNN\n",
    "# only_normalized_simpleRNN_class_report_noPOS = classification_report(y_test_RNN_noPOS, pred_simpleRNN_noPOS_normalized_class_convert)\n",
    "# only_normalized_simpleRNN_confusion_matrix_class_noPOS = confusion_matrix(y_test_RNN_noPOS, pred_simpleRNN_noPOS_normalized_class_convert)\n",
    "# only_normalized_simpleRNN_accuracy_class_noPOS = accuracy_score(y_test_RNN_noPOS, pred_simpleRNN_noPOS_normalized_class_convert)\n",
    "\n",
    "# #print the results\n",
    "# print(\"Classification Report:\\n\", only_normalized_simpleRNN_class_report_noPOS)\n",
    "# print(\"Confusion Matrix:\\n\", only_normalized_simpleRNN_confusion_matrix_class_noPOS)\n",
    "# print(\"Accuracy:\", only_normalized_simpleRNN_accuracy_class_noPOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d30853",
   "metadata": {},
   "source": [
    "## Part 8: Updated Classification Data to only 2 classes - positive and negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5a04610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import TFIDF for testing using this data instead of current features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "703cf313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive    335646\n",
      "negative    180092\n",
      "Name: Reviewer_Score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# first I will define the thresholds - our labels will be positive, negative, and neutral \n",
    "# I decided to use a small window for neutral, between 4.5 and 5.5 - this will ensure most the review classifications\n",
    "# are sensative - it can be updated later if desired by changing the following threshold values\n",
    "\n",
    "positive_threshold = 8.0\n",
    "negative_threshold = 8.0\n",
    "\n",
    "# next, I will classify by building a classification function\n",
    "\n",
    "def classify_scores(score_value):\n",
    "    if score_value >= positive_threshold:\n",
    "        return 'positive'\n",
    "    elif score_value < negative_threshold:\n",
    "        return 'negative'\n",
    "    \n",
    "# I will also do the same for the no POS tagging scenario\n",
    "\n",
    "preprocessed_reviews_updated = preprocessed_reviews_no_pos_tagging.copy()\n",
    "    \n",
    "preprocessed_reviews_updated['Reviewer_Score'] = preprocessed_reviews_updated['Reviewer_Score'].apply(classify_scores)\n",
    "\n",
    "preprocessed_reviews_updated\n",
    "\n",
    "# determine the counts of each category\n",
    "review_counts_updated = preprocessed_reviews_updated['Reviewer_Score'].value_counts()\n",
    "print(review_counts_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2efacd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Total_Review_handled Reviewer_Score\n",
      "0       [angry, made, post, available, via, possible, ...       negative\n",
      "1       [negative, real, complaint, hotel, great, grea...       negative\n",
      "2       [room, nice, elderly, bit, difficult, room, tw...       negative\n",
      "3       [room, dirty, afraid, walk, barefoot, floor, l...       negative\n",
      "4       [booked, company, line, showed, picture, room,...       negative\n",
      "...                                                   ...            ...\n",
      "515733  [trolly, staff, help, take, luggage, room, loc...       negative\n",
      "515734  [hotel, look, like, surely, breakfast, ok, got...       negative\n",
      "515735  [ac, useless, hot, week, vienna, gave, hot, ai...       negative\n",
      "515736  [negative, room, enormous, really, comfortable...       positive\n",
      "515737         [rd, floor, work, free, wife, staff, kind]       positive\n",
      "\n",
      "[515738 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#with an RNN the scores can not be text - they need to be numbers - will encode these now\n",
    "class LabelEncoderSentiment_updated:\n",
    "    def __init__(self):\n",
    "        self.classes_ = ['negative', 'positive']\n",
    "\n",
    "    def fit_transform_updated(self, labels):\n",
    "        return np.array([self.classes_.index(label) for label in labels])\n",
    "    \n",
    "    def inverse_transform_sentiment_updated(encoded_labels):\n",
    "        classes_ = ['negative', 'positive']\n",
    "        return [classes_[label] for label in encoded_labels]\n",
    "\n",
    "label_encoder_RNN_updated = LabelEncoderSentiment_updated()\n",
    "encoded_scores_RNN_updated = label_encoder_RNN_updated.fit_transform_updated(preprocessed_reviews_updated[\"Reviewer_Score\"])\n",
    "\n",
    "# get the text and POS data\n",
    "review_RNN_updated = preprocessed_reviews_updated[\"Total_Review_handled\"]\n",
    "\n",
    "print(preprocessed_reviews_updated)\n",
    "\n",
    "# # Define TF-IDF vectorizer - this didn't work well so I won't use it. \n",
    "# tfidf_vectorizer = TfidfVectorizer(max_features=500)\n",
    "# preprocessed_reviews_tfidf = [\" \".join(seq) for seq in review_RNN_updated]\n",
    "# # Fit and transform the text data using TF-IDF\n",
    "# tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed_reviews_tfidf)\n",
    "# tfidf_array = tfidf_matrix.toarray()\n",
    "\n",
    "# prepare the text and POS data for RNN usage\n",
    "tokenizer_RNN_updated = Tokenizer()\n",
    "tokenizer_RNN_updated.fit_on_texts([\" \".join(seq) for seq in review_RNN_updated])\n",
    "sequences_RNN_updated = tokenizer_RNN_updated.texts_to_sequences([\" \".join(seq) for seq in review_RNN_updated])\n",
    "review_prepped_RNN_updated = pad_sequences(sequences_RNN_updated, maxlen=30)\n",
    "\n",
    "# prepare the test and train datasets\n",
    "X_train_RNN_updated, X_test_RNN_updated, y_train_RNN_updated, y_test_RNN_updated = train_test_split(review_prepped_RNN_updated, encoded_scores_RNN_updated, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a135d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test batch normalization and reducing the learning rate if no changes to val_loss\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "#update class weights\n",
    "class_weights_updated = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_RNN_updated), y=y_train_RNN_updated)\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights_updated)}\n",
    "sample_weights_updated = np.array([class_weights_dict[y] for y in y_train_RNN_updated])\n",
    "\n",
    "#define the reduce learning rate parameters. \n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  \n",
    "    factor=0.5,           \n",
    "    patience=3,           \n",
    "    min_lr=1e-5,          \n",
    "    verbose=1              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a1dd97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.6525 - accuracy: 0.6990 - weighted_accuracy: 0.6998 - val_loss: 0.5716 - val_accuracy: 0.7224 - val_weighted_accuracy: 0.7130 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.5133 - accuracy: 0.7483 - weighted_accuracy: 0.7518 - val_loss: 0.5202 - val_accuracy: 0.7567 - val_weighted_accuracy: 0.7494 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.4881 - accuracy: 0.7683 - weighted_accuracy: 0.7684 - val_loss: 0.5871 - val_accuracy: 0.7184 - val_weighted_accuracy: 0.7218 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.5125 - accuracy: 0.7477 - weighted_accuracy: 0.7541 - val_loss: 0.5149 - val_accuracy: 0.7610 - val_weighted_accuracy: 0.7570 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.4908 - accuracy: 0.7673 - weighted_accuracy: 0.7657 - val_loss: 0.5044 - val_accuracy: 0.7677 - val_weighted_accuracy: 0.7611 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.4662 - accuracy: 0.7784 - weighted_accuracy: 0.7811 - val_loss: 0.5524 - val_accuracy: 0.7773 - val_weighted_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.4478 - accuracy: 0.7878 - weighted_accuracy: 0.7910 - val_loss: 0.4825 - val_accuracy: 0.7600 - val_weighted_accuracy: 0.7706 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.4413 - accuracy: 0.7936 - weighted_accuracy: 0.7964 - val_loss: 0.5040 - val_accuracy: 0.7615 - val_weighted_accuracy: 0.7697 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.4349 - accuracy: 0.7970 - weighted_accuracy: 0.7998 - val_loss: 0.4846 - val_accuracy: 0.7640 - val_weighted_accuracy: 0.7683 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "5158/5158 [==============================] - ETA: 0s - loss: 0.4286 - accuracy: 0.8026 - weighted_accuracy: 0.8029\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.4286 - accuracy: 0.8026 - weighted_accuracy: 0.8029 - val_loss: 0.4905 - val_accuracy: 0.7527 - val_weighted_accuracy: 0.7675 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.4100 - accuracy: 0.8123 - weighted_accuracy: 0.8125 - val_loss: 0.4910 - val_accuracy: 0.7782 - val_weighted_accuracy: 0.7710 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3979 - accuracy: 0.8190 - weighted_accuracy: 0.8186 - val_loss: 0.4908 - val_accuracy: 0.7693 - val_weighted_accuracy: 0.7712 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "5158/5158 [==============================] - ETA: 0s - loss: 0.3904 - accuracy: 0.8239 - weighted_accuracy: 0.8234\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3904 - accuracy: 0.8239 - weighted_accuracy: 0.8234 - val_loss: 0.4983 - val_accuracy: 0.7685 - val_weighted_accuracy: 0.7698 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3755 - accuracy: 0.8320 - weighted_accuracy: 0.8316 - val_loss: 0.4934 - val_accuracy: 0.7748 - val_weighted_accuracy: 0.7692 - lr: 2.5000e-04\n",
      "Epoch 15/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3660 - accuracy: 0.8381 - weighted_accuracy: 0.8371 - val_loss: 0.5053 - val_accuracy: 0.7673 - val_weighted_accuracy: 0.7699 - lr: 2.5000e-04\n",
      "Epoch 16/100\n",
      "5155/5158 [============================>.] - ETA: 0s - loss: 0.3602 - accuracy: 0.8411 - weighted_accuracy: 0.8400\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3602 - accuracy: 0.8411 - weighted_accuracy: 0.8400 - val_loss: 0.5055 - val_accuracy: 0.7774 - val_weighted_accuracy: 0.7682 - lr: 2.5000e-04\n",
      "Epoch 17/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3497 - accuracy: 0.8476 - weighted_accuracy: 0.8465 - val_loss: 0.5249 - val_accuracy: 0.7670 - val_weighted_accuracy: 0.7696 - lr: 1.2500e-04\n",
      "Epoch 18/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3446 - accuracy: 0.8516 - weighted_accuracy: 0.8496 - val_loss: 0.5151 - val_accuracy: 0.7721 - val_weighted_accuracy: 0.7675 - lr: 1.2500e-04\n",
      "Epoch 19/100\n",
      "5156/5158 [============================>.] - ETA: 0s - loss: 0.3407 - accuracy: 0.8528 - weighted_accuracy: 0.8511\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3407 - accuracy: 0.8528 - weighted_accuracy: 0.8511 - val_loss: 0.5235 - val_accuracy: 0.7700 - val_weighted_accuracy: 0.7679 - lr: 1.2500e-04\n",
      "Epoch 20/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3350 - accuracy: 0.8561 - weighted_accuracy: 0.8543 - val_loss: 0.5247 - val_accuracy: 0.7721 - val_weighted_accuracy: 0.7666 - lr: 6.2500e-05\n",
      "Epoch 21/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3326 - accuracy: 0.8579 - weighted_accuracy: 0.8558 - val_loss: 0.5273 - val_accuracy: 0.7710 - val_weighted_accuracy: 0.7675 - lr: 6.2500e-05\n",
      "Epoch 22/100\n",
      "5155/5158 [============================>.] - ETA: 0s - loss: 0.3305 - accuracy: 0.8586 - weighted_accuracy: 0.8568\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3305 - accuracy: 0.8586 - weighted_accuracy: 0.8568 - val_loss: 0.5360 - val_accuracy: 0.7699 - val_weighted_accuracy: 0.7670 - lr: 6.2500e-05\n",
      "Epoch 23/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3274 - accuracy: 0.8606 - weighted_accuracy: 0.8586 - val_loss: 0.5384 - val_accuracy: 0.7700 - val_weighted_accuracy: 0.7665 - lr: 3.1250e-05\n",
      "Epoch 24/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3261 - accuracy: 0.8617 - weighted_accuracy: 0.8593 - val_loss: 0.5366 - val_accuracy: 0.7716 - val_weighted_accuracy: 0.7653 - lr: 3.1250e-05\n",
      "Epoch 25/100\n",
      "5155/5158 [============================>.] - ETA: 0s - loss: 0.3248 - accuracy: 0.8620 - weighted_accuracy: 0.8600\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3248 - accuracy: 0.8620 - weighted_accuracy: 0.8600 - val_loss: 0.5380 - val_accuracy: 0.7731 - val_weighted_accuracy: 0.7659 - lr: 3.1250e-05\n",
      "Epoch 26/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3233 - accuracy: 0.8628 - weighted_accuracy: 0.8609 - val_loss: 0.5332 - val_accuracy: 0.7734 - val_weighted_accuracy: 0.7661 - lr: 1.5625e-05\n",
      "Epoch 27/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3229 - accuracy: 0.8629 - weighted_accuracy: 0.8608 - val_loss: 0.5357 - val_accuracy: 0.7732 - val_weighted_accuracy: 0.7653 - lr: 1.5625e-05\n",
      "Epoch 28/100\n",
      "5157/5158 [============================>.] - ETA: 0s - loss: 0.3218 - accuracy: 0.8638 - weighted_accuracy: 0.8615\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3218 - accuracy: 0.8638 - weighted_accuracy: 0.8616 - val_loss: 0.5400 - val_accuracy: 0.7710 - val_weighted_accuracy: 0.7659 - lr: 1.5625e-05\n",
      "Epoch 29/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3213 - accuracy: 0.8638 - weighted_accuracy: 0.8618 - val_loss: 0.5424 - val_accuracy: 0.7724 - val_weighted_accuracy: 0.7654 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3210 - accuracy: 0.8636 - weighted_accuracy: 0.8618 - val_loss: 0.5394 - val_accuracy: 0.7699 - val_weighted_accuracy: 0.7657 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3205 - accuracy: 0.8645 - weighted_accuracy: 0.8624 - val_loss: 0.5423 - val_accuracy: 0.7722 - val_weighted_accuracy: 0.7653 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3202 - accuracy: 0.8646 - weighted_accuracy: 0.8622 - val_loss: 0.5423 - val_accuracy: 0.7719 - val_weighted_accuracy: 0.7655 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3194 - accuracy: 0.8652 - weighted_accuracy: 0.8631 - val_loss: 0.5421 - val_accuracy: 0.7708 - val_weighted_accuracy: 0.7658 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3195 - accuracy: 0.8652 - weighted_accuracy: 0.8630 - val_loss: 0.5433 - val_accuracy: 0.7726 - val_weighted_accuracy: 0.7655 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3195 - accuracy: 0.8651 - weighted_accuracy: 0.8628 - val_loss: 0.5434 - val_accuracy: 0.7715 - val_weighted_accuracy: 0.7654 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3191 - accuracy: 0.8653 - weighted_accuracy: 0.8632 - val_loss: 0.5416 - val_accuracy: 0.7725 - val_weighted_accuracy: 0.7651 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3188 - accuracy: 0.8655 - weighted_accuracy: 0.8629 - val_loss: 0.5456 - val_accuracy: 0.7709 - val_weighted_accuracy: 0.7651 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3187 - accuracy: 0.8655 - weighted_accuracy: 0.8633 - val_loss: 0.5431 - val_accuracy: 0.7718 - val_weighted_accuracy: 0.7650 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3184 - accuracy: 0.8654 - weighted_accuracy: 0.8631 - val_loss: 0.5466 - val_accuracy: 0.7728 - val_weighted_accuracy: 0.7652 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3175 - accuracy: 0.8661 - weighted_accuracy: 0.8640 - val_loss: 0.5441 - val_accuracy: 0.7725 - val_weighted_accuracy: 0.7649 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3172 - accuracy: 0.8663 - weighted_accuracy: 0.8641 - val_loss: 0.5443 - val_accuracy: 0.7710 - val_weighted_accuracy: 0.7650 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3173 - accuracy: 0.8661 - weighted_accuracy: 0.8640 - val_loss: 0.5518 - val_accuracy: 0.7721 - val_weighted_accuracy: 0.7646 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3170 - accuracy: 0.8659 - weighted_accuracy: 0.8639 - val_loss: 0.5458 - val_accuracy: 0.7708 - val_weighted_accuracy: 0.7648 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3169 - accuracy: 0.8660 - weighted_accuracy: 0.8640 - val_loss: 0.5434 - val_accuracy: 0.7713 - val_weighted_accuracy: 0.7648 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3167 - accuracy: 0.8665 - weighted_accuracy: 0.8643 - val_loss: 0.5448 - val_accuracy: 0.7709 - val_weighted_accuracy: 0.7649 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3162 - accuracy: 0.8670 - weighted_accuracy: 0.8646 - val_loss: 0.5464 - val_accuracy: 0.7711 - val_weighted_accuracy: 0.7644 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3161 - accuracy: 0.8665 - weighted_accuracy: 0.8643 - val_loss: 0.5508 - val_accuracy: 0.7698 - val_weighted_accuracy: 0.7649 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3159 - accuracy: 0.8668 - weighted_accuracy: 0.8646 - val_loss: 0.5469 - val_accuracy: 0.7709 - val_weighted_accuracy: 0.7644 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3151 - accuracy: 0.8672 - weighted_accuracy: 0.8649 - val_loss: 0.5476 - val_accuracy: 0.7715 - val_weighted_accuracy: 0.7642 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3149 - accuracy: 0.8675 - weighted_accuracy: 0.8652 - val_loss: 0.5494 - val_accuracy: 0.7692 - val_weighted_accuracy: 0.7650 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3147 - accuracy: 0.8671 - weighted_accuracy: 0.8652 - val_loss: 0.5477 - val_accuracy: 0.7727 - val_weighted_accuracy: 0.7638 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3146 - accuracy: 0.8674 - weighted_accuracy: 0.8653 - val_loss: 0.5501 - val_accuracy: 0.7712 - val_weighted_accuracy: 0.7647 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3145 - accuracy: 0.8675 - weighted_accuracy: 0.8654 - val_loss: 0.5479 - val_accuracy: 0.7717 - val_weighted_accuracy: 0.7640 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3139 - accuracy: 0.8680 - weighted_accuracy: 0.8656 - val_loss: 0.5459 - val_accuracy: 0.7716 - val_weighted_accuracy: 0.7634 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3139 - accuracy: 0.8682 - weighted_accuracy: 0.8660 - val_loss: 0.5487 - val_accuracy: 0.7700 - val_weighted_accuracy: 0.7639 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3135 - accuracy: 0.8675 - weighted_accuracy: 0.8656 - val_loss: 0.5492 - val_accuracy: 0.7702 - val_weighted_accuracy: 0.7640 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3129 - accuracy: 0.8683 - weighted_accuracy: 0.8663 - val_loss: 0.5493 - val_accuracy: 0.7699 - val_weighted_accuracy: 0.7643 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3129 - accuracy: 0.8681 - weighted_accuracy: 0.8662 - val_loss: 0.5527 - val_accuracy: 0.7731 - val_weighted_accuracy: 0.7644 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3128 - accuracy: 0.8686 - weighted_accuracy: 0.8665 - val_loss: 0.5510 - val_accuracy: 0.7698 - val_weighted_accuracy: 0.7646 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3125 - accuracy: 0.8687 - weighted_accuracy: 0.8664 - val_loss: 0.5501 - val_accuracy: 0.7716 - val_weighted_accuracy: 0.7640 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3124 - accuracy: 0.8686 - weighted_accuracy: 0.8665 - val_loss: 0.5502 - val_accuracy: 0.7702 - val_weighted_accuracy: 0.7641 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3118 - accuracy: 0.8689 - weighted_accuracy: 0.8672 - val_loss: 0.5566 - val_accuracy: 0.7712 - val_weighted_accuracy: 0.7637 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3118 - accuracy: 0.8690 - weighted_accuracy: 0.8668 - val_loss: 0.5523 - val_accuracy: 0.7706 - val_weighted_accuracy: 0.7635 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3114 - accuracy: 0.8692 - weighted_accuracy: 0.8672 - val_loss: 0.5514 - val_accuracy: 0.7702 - val_weighted_accuracy: 0.7635 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3110 - accuracy: 0.8691 - weighted_accuracy: 0.8670 - val_loss: 0.5493 - val_accuracy: 0.7713 - val_weighted_accuracy: 0.7638 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3110 - accuracy: 0.8692 - weighted_accuracy: 0.8674 - val_loss: 0.5551 - val_accuracy: 0.7706 - val_weighted_accuracy: 0.7642 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3109 - accuracy: 0.8696 - weighted_accuracy: 0.8676 - val_loss: 0.5540 - val_accuracy: 0.7708 - val_weighted_accuracy: 0.7641 - lr: 1.0000e-05\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3108 - accuracy: 0.8689 - weighted_accuracy: 0.8671 - val_loss: 0.5552 - val_accuracy: 0.7705 - val_weighted_accuracy: 0.7638 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3103 - accuracy: 0.8694 - weighted_accuracy: 0.8676 - val_loss: 0.5532 - val_accuracy: 0.7707 - val_weighted_accuracy: 0.7638 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3095 - accuracy: 0.8696 - weighted_accuracy: 0.8678 - val_loss: 0.5584 - val_accuracy: 0.7696 - val_weighted_accuracy: 0.7635 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3100 - accuracy: 0.8697 - weighted_accuracy: 0.8677 - val_loss: 0.5558 - val_accuracy: 0.7722 - val_weighted_accuracy: 0.7637 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3098 - accuracy: 0.8698 - weighted_accuracy: 0.8677 - val_loss: 0.5538 - val_accuracy: 0.7705 - val_weighted_accuracy: 0.7637 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3093 - accuracy: 0.8699 - weighted_accuracy: 0.8680 - val_loss: 0.5551 - val_accuracy: 0.7705 - val_weighted_accuracy: 0.7638 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3094 - accuracy: 0.8700 - weighted_accuracy: 0.8680 - val_loss: 0.5593 - val_accuracy: 0.7704 - val_weighted_accuracy: 0.7636 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3088 - accuracy: 0.8704 - weighted_accuracy: 0.8684 - val_loss: 0.5564 - val_accuracy: 0.7720 - val_weighted_accuracy: 0.7638 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3085 - accuracy: 0.8701 - weighted_accuracy: 0.8684 - val_loss: 0.5584 - val_accuracy: 0.7704 - val_weighted_accuracy: 0.7634 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3083 - accuracy: 0.8701 - weighted_accuracy: 0.8684 - val_loss: 0.5545 - val_accuracy: 0.7709 - val_weighted_accuracy: 0.7636 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3081 - accuracy: 0.8706 - weighted_accuracy: 0.8689 - val_loss: 0.5569 - val_accuracy: 0.7711 - val_weighted_accuracy: 0.7635 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3079 - accuracy: 0.8702 - weighted_accuracy: 0.8684 - val_loss: 0.5593 - val_accuracy: 0.7715 - val_weighted_accuracy: 0.7633 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3078 - accuracy: 0.8709 - weighted_accuracy: 0.8689 - val_loss: 0.5591 - val_accuracy: 0.7708 - val_weighted_accuracy: 0.7634 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3072 - accuracy: 0.8708 - weighted_accuracy: 0.8690 - val_loss: 0.5584 - val_accuracy: 0.7695 - val_weighted_accuracy: 0.7633 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3072 - accuracy: 0.8707 - weighted_accuracy: 0.8690 - val_loss: 0.5586 - val_accuracy: 0.7699 - val_weighted_accuracy: 0.7634 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3069 - accuracy: 0.8711 - weighted_accuracy: 0.8695 - val_loss: 0.5573 - val_accuracy: 0.7716 - val_weighted_accuracy: 0.7633 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3065 - accuracy: 0.8715 - weighted_accuracy: 0.8695 - val_loss: 0.5602 - val_accuracy: 0.7696 - val_weighted_accuracy: 0.7633 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3064 - accuracy: 0.8712 - weighted_accuracy: 0.8693 - val_loss: 0.5618 - val_accuracy: 0.7705 - val_weighted_accuracy: 0.7635 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3061 - accuracy: 0.8714 - weighted_accuracy: 0.8696 - val_loss: 0.5603 - val_accuracy: 0.7689 - val_weighted_accuracy: 0.7634 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3062 - accuracy: 0.8713 - weighted_accuracy: 0.8696 - val_loss: 0.5613 - val_accuracy: 0.7705 - val_weighted_accuracy: 0.7632 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3056 - accuracy: 0.8719 - weighted_accuracy: 0.8699 - val_loss: 0.5620 - val_accuracy: 0.7690 - val_weighted_accuracy: 0.7636 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3058 - accuracy: 0.8715 - weighted_accuracy: 0.8696 - val_loss: 0.5648 - val_accuracy: 0.7700 - val_weighted_accuracy: 0.7636 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3055 - accuracy: 0.8719 - weighted_accuracy: 0.8699 - val_loss: 0.5588 - val_accuracy: 0.7706 - val_weighted_accuracy: 0.7634 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3053 - accuracy: 0.8720 - weighted_accuracy: 0.8702 - val_loss: 0.5643 - val_accuracy: 0.7701 - val_weighted_accuracy: 0.7632 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3049 - accuracy: 0.8725 - weighted_accuracy: 0.8705 - val_loss: 0.5637 - val_accuracy: 0.7714 - val_weighted_accuracy: 0.7632 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3044 - accuracy: 0.8724 - weighted_accuracy: 0.8705 - val_loss: 0.5598 - val_accuracy: 0.7706 - val_weighted_accuracy: 0.7633 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3048 - accuracy: 0.8721 - weighted_accuracy: 0.8701 - val_loss: 0.5599 - val_accuracy: 0.7714 - val_weighted_accuracy: 0.7637 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3041 - accuracy: 0.8724 - weighted_accuracy: 0.8704 - val_loss: 0.5653 - val_accuracy: 0.7708 - val_weighted_accuracy: 0.7635 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "5158/5158 [==============================] - 85s 16ms/step - loss: 0.3045 - accuracy: 0.8724 - weighted_accuracy: 0.8704 - val_loss: 0.5615 - val_accuracy: 0.7700 - val_weighted_accuracy: 0.7636 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "5158/5158 [==============================] - 85s 17ms/step - loss: 0.3033 - accuracy: 0.8730 - weighted_accuracy: 0.8712 - val_loss: 0.5640 - val_accuracy: 0.7703 - val_weighted_accuracy: 0.7632 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3035 - accuracy: 0.8727 - weighted_accuracy: 0.8708 - val_loss: 0.5645 - val_accuracy: 0.7694 - val_weighted_accuracy: 0.7630 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3039 - accuracy: 0.8725 - weighted_accuracy: 0.8708 - val_loss: 0.5598 - val_accuracy: 0.7712 - val_weighted_accuracy: 0.7627 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "5158/5158 [==============================] - 86s 17ms/step - loss: 0.3031 - accuracy: 0.8730 - weighted_accuracy: 0.8712 - val_loss: 0.5631 - val_accuracy: 0.7696 - val_weighted_accuracy: 0.7629 - lr: 1.0000e-05\n",
      "3224/3224 [==============================] - 3s 896us/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69     36165\n",
      "           1       0.85      0.79      0.82     66983\n",
      "\n",
      "    accuracy                           0.77    103148\n",
      "   macro avg       0.75      0.76      0.76    103148\n",
      "weighted avg       0.78      0.77      0.77    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[26847  9318]\n",
      " [14327 52656]]\n",
      "Accuracy: 0.7707662775817272\n"
     ]
    }
   ],
   "source": [
    "#create the complex model\n",
    "model_simpleRNN_updated = Sequential()\n",
    "model_simpleRNN_updated.add(Embedding(input_dim=len(tokenizer_RNN_updated.word_index) + 1, output_dim=128, input_length=30))\n",
    "model_simpleRNN_updated.add(BatchNormalization())\n",
    "model_simpleRNN_updated.add(SimpleRNN(units=50))\n",
    "model_simpleRNN_updated.add(BatchNormalization())\n",
    "model_simpleRNN_updated.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model_simpleRNN_updated.add(BatchNormalization())\n",
    "model_simpleRNN_updated.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model_simpleRNN_updated.add(BatchNormalization())\n",
    "model_simpleRNN_updated.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model_simpleRNN_updated.compile(\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'],    \n",
    "    weighted_metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#train\n",
    "model_simpleRNN_updated.fit(X_train_RNN_updated, y_train_RNN_updated, epochs=100, batch_size=64, validation_split=0.2, sample_weight=sample_weights_updated, callbacks=[reduce_lr])\n",
    "\n",
    "# test predictions and get evaluation metrics\n",
    "pred_simpleRNN_updated = model_simpleRNN_updated.predict(X_test_RNN_updated)\n",
    "\n",
    "#convert back\n",
    "pred_simpleRNN_updated_convert = np.argmax(pred_simpleRNN_updated, axis=1)\n",
    "\n",
    "#evaluate results from the RNN\n",
    "updated_simpleRNN_class_report = classification_report(y_test_RNN_updated, pred_simpleRNN_updated_convert)\n",
    "updated_simpleRNN_confusion_matrix_class = confusion_matrix(y_test_RNN_updated, pred_simpleRNN_updated_convert)\n",
    "updated_simpleRNN_accuracy_class = accuracy_score(y_test_RNN_updated, pred_simpleRNN_updated_convert)\n",
    "\n",
    "#print the results\n",
    "print(\"Classification Report:\\n\", updated_simpleRNN_class_report)\n",
    "print(\"Confusion Matrix:\\n\", updated_simpleRNN_confusion_matrix_class)\n",
    "print(\"Accuracy:\", updated_simpleRNN_accuracy_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d23bdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5158/5158 [==============================] - 124s 24ms/step - loss: 0.6472 - accuracy: 0.7600 - weighted_accuracy: 0.7630 - val_loss: 0.4884 - val_accuracy: 0.7850 - val_weighted_accuracy: 0.7728 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.4646 - accuracy: 0.7858 - weighted_accuracy: 0.7872 - val_loss: 0.4734 - val_accuracy: 0.7688 - val_weighted_accuracy: 0.7800 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.4454 - accuracy: 0.7958 - weighted_accuracy: 0.7970 - val_loss: 0.4756 - val_accuracy: 0.7882 - val_weighted_accuracy: 0.7795 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "5158/5158 [==============================] - 121s 23ms/step - loss: 0.4313 - accuracy: 0.8037 - weighted_accuracy: 0.8047 - val_loss: 0.4728 - val_accuracy: 0.7763 - val_weighted_accuracy: 0.7819 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "5158/5158 [==============================] - 121s 24ms/step - loss: 0.4204 - accuracy: 0.8091 - weighted_accuracy: 0.8099 - val_loss: 0.4771 - val_accuracy: 0.7726 - val_weighted_accuracy: 0.7783 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.4122 - accuracy: 0.8135 - weighted_accuracy: 0.8140 - val_loss: 0.4874 - val_accuracy: 0.7740 - val_weighted_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "5158/5158 [==============================] - ETA: 0s - loss: 0.4045 - accuracy: 0.8169 - weighted_accuracy: 0.8174\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.4045 - accuracy: 0.8169 - weighted_accuracy: 0.8174 - val_loss: 0.4881 - val_accuracy: 0.7739 - val_weighted_accuracy: 0.7750 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3827 - accuracy: 0.8273 - weighted_accuracy: 0.8276 - val_loss: 0.4949 - val_accuracy: 0.7627 - val_weighted_accuracy: 0.7704 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3757 - accuracy: 0.8307 - weighted_accuracy: 0.8311 - val_loss: 0.5045 - val_accuracy: 0.7753 - val_weighted_accuracy: 0.7730 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "5157/5158 [============================>.] - ETA: 0s - loss: 0.3709 - accuracy: 0.8321 - weighted_accuracy: 0.8327\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3709 - accuracy: 0.8321 - weighted_accuracy: 0.8327 - val_loss: 0.5174 - val_accuracy: 0.7611 - val_weighted_accuracy: 0.7688 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3563 - accuracy: 0.8388 - weighted_accuracy: 0.8393 - val_loss: 0.5287 - val_accuracy: 0.7676 - val_weighted_accuracy: 0.7682 - lr: 2.5000e-04\n",
      "Epoch 12/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3526 - accuracy: 0.8407 - weighted_accuracy: 0.8413 - val_loss: 0.5480 - val_accuracy: 0.7707 - val_weighted_accuracy: 0.7661 - lr: 2.5000e-04\n",
      "Epoch 13/100\n",
      "5156/5158 [============================>.] - ETA: 0s - loss: 0.3492 - accuracy: 0.8423 - weighted_accuracy: 0.8428\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "5158/5158 [==============================] - 121s 24ms/step - loss: 0.3492 - accuracy: 0.8423 - weighted_accuracy: 0.8428 - val_loss: 0.5403 - val_accuracy: 0.7665 - val_weighted_accuracy: 0.7665 - lr: 2.5000e-04\n",
      "Epoch 14/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3394 - accuracy: 0.8460 - weighted_accuracy: 0.8461 - val_loss: 0.5620 - val_accuracy: 0.7677 - val_weighted_accuracy: 0.7654 - lr: 1.2500e-04\n",
      "Epoch 15/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3379 - accuracy: 0.8465 - weighted_accuracy: 0.8472 - val_loss: 0.5745 - val_accuracy: 0.7736 - val_weighted_accuracy: 0.7628 - lr: 1.2500e-04\n",
      "Epoch 16/100\n",
      "5157/5158 [============================>.] - ETA: 0s - loss: 0.3362 - accuracy: 0.8480 - weighted_accuracy: 0.8484\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3362 - accuracy: 0.8480 - weighted_accuracy: 0.8484 - val_loss: 0.5733 - val_accuracy: 0.7607 - val_weighted_accuracy: 0.7642 - lr: 1.2500e-04\n",
      "Epoch 17/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3304 - accuracy: 0.8503 - weighted_accuracy: 0.8507 - val_loss: 0.5825 - val_accuracy: 0.7621 - val_weighted_accuracy: 0.7636 - lr: 6.2500e-05\n",
      "Epoch 18/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3292 - accuracy: 0.8505 - weighted_accuracy: 0.8512 - val_loss: 0.5884 - val_accuracy: 0.7654 - val_weighted_accuracy: 0.7644 - lr: 6.2500e-05\n",
      "Epoch 19/100\n",
      "5157/5158 [============================>.] - ETA: 0s - loss: 0.3279 - accuracy: 0.8509 - weighted_accuracy: 0.8515\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3279 - accuracy: 0.8509 - weighted_accuracy: 0.8515 - val_loss: 0.5853 - val_accuracy: 0.7676 - val_weighted_accuracy: 0.7627 - lr: 6.2500e-05\n",
      "Epoch 20/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3249 - accuracy: 0.8520 - weighted_accuracy: 0.8524 - val_loss: 0.6001 - val_accuracy: 0.7662 - val_weighted_accuracy: 0.7622 - lr: 3.1250e-05\n",
      "Epoch 21/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3249 - accuracy: 0.8522 - weighted_accuracy: 0.8527 - val_loss: 0.6023 - val_accuracy: 0.7675 - val_weighted_accuracy: 0.7622 - lr: 3.1250e-05\n",
      "Epoch 22/100\n",
      "5156/5158 [============================>.] - ETA: 0s - loss: 0.3233 - accuracy: 0.8530 - weighted_accuracy: 0.8535\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3233 - accuracy: 0.8530 - weighted_accuracy: 0.8535 - val_loss: 0.5994 - val_accuracy: 0.7649 - val_weighted_accuracy: 0.7612 - lr: 3.1250e-05\n",
      "Epoch 23/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3225 - accuracy: 0.8530 - weighted_accuracy: 0.8536 - val_loss: 0.6116 - val_accuracy: 0.7664 - val_weighted_accuracy: 0.7615 - lr: 1.5625e-05\n",
      "Epoch 24/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3217 - accuracy: 0.8541 - weighted_accuracy: 0.8547 - val_loss: 0.6100 - val_accuracy: 0.7648 - val_weighted_accuracy: 0.7621 - lr: 1.5625e-05\n",
      "Epoch 25/100\n",
      "5158/5158 [==============================] - ETA: 0s - loss: 0.3216 - accuracy: 0.8540 - weighted_accuracy: 0.8544\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "5158/5158 [==============================] - 123s 24ms/step - loss: 0.3216 - accuracy: 0.8540 - weighted_accuracy: 0.8544 - val_loss: 0.6111 - val_accuracy: 0.7656 - val_weighted_accuracy: 0.7612 - lr: 1.5625e-05\n",
      "Epoch 26/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3207 - accuracy: 0.8538 - weighted_accuracy: 0.8547 - val_loss: 0.6118 - val_accuracy: 0.7665 - val_weighted_accuracy: 0.7611 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3207 - accuracy: 0.8543 - weighted_accuracy: 0.8548 - val_loss: 0.6115 - val_accuracy: 0.7654 - val_weighted_accuracy: 0.7615 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3201 - accuracy: 0.8542 - weighted_accuracy: 0.8549 - val_loss: 0.6147 - val_accuracy: 0.7656 - val_weighted_accuracy: 0.7613 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "5158/5158 [==============================] - 123s 24ms/step - loss: 0.3201 - accuracy: 0.8540 - weighted_accuracy: 0.8545 - val_loss: 0.6139 - val_accuracy: 0.7651 - val_weighted_accuracy: 0.7610 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "5158/5158 [==============================] - 123s 24ms/step - loss: 0.3196 - accuracy: 0.8548 - weighted_accuracy: 0.8555 - val_loss: 0.6151 - val_accuracy: 0.7659 - val_weighted_accuracy: 0.7606 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3198 - accuracy: 0.8549 - weighted_accuracy: 0.8557 - val_loss: 0.6142 - val_accuracy: 0.7668 - val_weighted_accuracy: 0.7612 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3197 - accuracy: 0.8545 - weighted_accuracy: 0.8550 - val_loss: 0.6180 - val_accuracy: 0.7640 - val_weighted_accuracy: 0.7609 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "5158/5158 [==============================] - 121s 24ms/step - loss: 0.3194 - accuracy: 0.8544 - weighted_accuracy: 0.8551 - val_loss: 0.6147 - val_accuracy: 0.7644 - val_weighted_accuracy: 0.7615 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3187 - accuracy: 0.8546 - weighted_accuracy: 0.8552 - val_loss: 0.6208 - val_accuracy: 0.7643 - val_weighted_accuracy: 0.7603 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3189 - accuracy: 0.8553 - weighted_accuracy: 0.8559 - val_loss: 0.6211 - val_accuracy: 0.7637 - val_weighted_accuracy: 0.7612 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3192 - accuracy: 0.8545 - weighted_accuracy: 0.8552 - val_loss: 0.6175 - val_accuracy: 0.7637 - val_weighted_accuracy: 0.7608 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "5158/5158 [==============================] - 121s 23ms/step - loss: 0.3186 - accuracy: 0.8546 - weighted_accuracy: 0.8550 - val_loss: 0.6268 - val_accuracy: 0.7664 - val_weighted_accuracy: 0.7604 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "5158/5158 [==============================] - 121s 24ms/step - loss: 0.3183 - accuracy: 0.8547 - weighted_accuracy: 0.8553 - val_loss: 0.6219 - val_accuracy: 0.7640 - val_weighted_accuracy: 0.7607 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3183 - accuracy: 0.8550 - weighted_accuracy: 0.8555 - val_loss: 0.6205 - val_accuracy: 0.7638 - val_weighted_accuracy: 0.7601 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3173 - accuracy: 0.8555 - weighted_accuracy: 0.8561 - val_loss: 0.6218 - val_accuracy: 0.7629 - val_weighted_accuracy: 0.7608 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3179 - accuracy: 0.8549 - weighted_accuracy: 0.8554 - val_loss: 0.6264 - val_accuracy: 0.7635 - val_weighted_accuracy: 0.7610 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3176 - accuracy: 0.8559 - weighted_accuracy: 0.8565 - val_loss: 0.6245 - val_accuracy: 0.7640 - val_weighted_accuracy: 0.7601 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3178 - accuracy: 0.8553 - weighted_accuracy: 0.8558 - val_loss: 0.6290 - val_accuracy: 0.7654 - val_weighted_accuracy: 0.7608 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3171 - accuracy: 0.8560 - weighted_accuracy: 0.8565 - val_loss: 0.6266 - val_accuracy: 0.7641 - val_weighted_accuracy: 0.7601 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3169 - accuracy: 0.8555 - weighted_accuracy: 0.8563 - val_loss: 0.6279 - val_accuracy: 0.7629 - val_weighted_accuracy: 0.7601 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3164 - accuracy: 0.8561 - weighted_accuracy: 0.8569 - val_loss: 0.6297 - val_accuracy: 0.7656 - val_weighted_accuracy: 0.7602 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "5158/5158 [==============================] - 124s 24ms/step - loss: 0.3163 - accuracy: 0.8559 - weighted_accuracy: 0.8566 - val_loss: 0.6327 - val_accuracy: 0.7659 - val_weighted_accuracy: 0.7599 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3162 - accuracy: 0.8559 - weighted_accuracy: 0.8566 - val_loss: 0.6308 - val_accuracy: 0.7635 - val_weighted_accuracy: 0.7596 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3159 - accuracy: 0.8556 - weighted_accuracy: 0.8562 - val_loss: 0.6260 - val_accuracy: 0.7635 - val_weighted_accuracy: 0.7599 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3156 - accuracy: 0.8556 - weighted_accuracy: 0.8563 - val_loss: 0.6325 - val_accuracy: 0.7645 - val_weighted_accuracy: 0.7598 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3157 - accuracy: 0.8561 - weighted_accuracy: 0.8568 - val_loss: 0.6312 - val_accuracy: 0.7646 - val_weighted_accuracy: 0.7603 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3158 - accuracy: 0.8564 - weighted_accuracy: 0.8569 - val_loss: 0.6321 - val_accuracy: 0.7638 - val_weighted_accuracy: 0.7594 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "5158/5158 [==============================] - 123s 24ms/step - loss: 0.3153 - accuracy: 0.8566 - weighted_accuracy: 0.8573 - val_loss: 0.6326 - val_accuracy: 0.7633 - val_weighted_accuracy: 0.7596 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "5158/5158 [==============================] - 123s 24ms/step - loss: 0.3148 - accuracy: 0.8570 - weighted_accuracy: 0.8576 - val_loss: 0.6326 - val_accuracy: 0.7634 - val_weighted_accuracy: 0.7599 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3151 - accuracy: 0.8564 - weighted_accuracy: 0.8569 - val_loss: 0.6334 - val_accuracy: 0.7632 - val_weighted_accuracy: 0.7593 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "5158/5158 [==============================] - 121s 24ms/step - loss: 0.3148 - accuracy: 0.8566 - weighted_accuracy: 0.8573 - val_loss: 0.6352 - val_accuracy: 0.7623 - val_weighted_accuracy: 0.7598 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3145 - accuracy: 0.8571 - weighted_accuracy: 0.8578 - val_loss: 0.6384 - val_accuracy: 0.7637 - val_weighted_accuracy: 0.7599 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3139 - accuracy: 0.8571 - weighted_accuracy: 0.8577 - val_loss: 0.6423 - val_accuracy: 0.7653 - val_weighted_accuracy: 0.7597 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3140 - accuracy: 0.8568 - weighted_accuracy: 0.8574 - val_loss: 0.6351 - val_accuracy: 0.7629 - val_weighted_accuracy: 0.7595 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3136 - accuracy: 0.8576 - weighted_accuracy: 0.8582 - val_loss: 0.6410 - val_accuracy: 0.7637 - val_weighted_accuracy: 0.7591 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3136 - accuracy: 0.8574 - weighted_accuracy: 0.8580 - val_loss: 0.6387 - val_accuracy: 0.7632 - val_weighted_accuracy: 0.7592 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3135 - accuracy: 0.8570 - weighted_accuracy: 0.8576 - val_loss: 0.6465 - val_accuracy: 0.7638 - val_weighted_accuracy: 0.7593 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "5158/5158 [==============================] - 121s 24ms/step - loss: 0.3136 - accuracy: 0.8576 - weighted_accuracy: 0.8584 - val_loss: 0.6440 - val_accuracy: 0.7637 - val_weighted_accuracy: 0.7595 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3131 - accuracy: 0.8577 - weighted_accuracy: 0.8584 - val_loss: 0.6446 - val_accuracy: 0.7645 - val_weighted_accuracy: 0.7593 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "5158/5158 [==============================] - 123s 24ms/step - loss: 0.3130 - accuracy: 0.8574 - weighted_accuracy: 0.8579 - val_loss: 0.6411 - val_accuracy: 0.7631 - val_weighted_accuracy: 0.7594 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3131 - accuracy: 0.8574 - weighted_accuracy: 0.8582 - val_loss: 0.6442 - val_accuracy: 0.7644 - val_weighted_accuracy: 0.7600 - lr: 1.0000e-05\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3125 - accuracy: 0.8581 - weighted_accuracy: 0.8586 - val_loss: 0.6463 - val_accuracy: 0.7633 - val_weighted_accuracy: 0.7591 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "5158/5158 [==============================] - 121s 24ms/step - loss: 0.3125 - accuracy: 0.8578 - weighted_accuracy: 0.8585 - val_loss: 0.6438 - val_accuracy: 0.7612 - val_weighted_accuracy: 0.7593 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "5158/5158 [==============================] - 121s 24ms/step - loss: 0.3119 - accuracy: 0.8579 - weighted_accuracy: 0.8587 - val_loss: 0.6452 - val_accuracy: 0.7637 - val_weighted_accuracy: 0.7598 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "5158/5158 [==============================] - 121s 24ms/step - loss: 0.3119 - accuracy: 0.8577 - weighted_accuracy: 0.8584 - val_loss: 0.6468 - val_accuracy: 0.7626 - val_weighted_accuracy: 0.7599 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3120 - accuracy: 0.8576 - weighted_accuracy: 0.8583 - val_loss: 0.6475 - val_accuracy: 0.7632 - val_weighted_accuracy: 0.7592 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3115 - accuracy: 0.8584 - weighted_accuracy: 0.8590 - val_loss: 0.6519 - val_accuracy: 0.7610 - val_weighted_accuracy: 0.7591 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3118 - accuracy: 0.8580 - weighted_accuracy: 0.8589 - val_loss: 0.6489 - val_accuracy: 0.7641 - val_weighted_accuracy: 0.7586 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3112 - accuracy: 0.8588 - weighted_accuracy: 0.8595 - val_loss: 0.6519 - val_accuracy: 0.7642 - val_weighted_accuracy: 0.7594 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3119 - accuracy: 0.8578 - weighted_accuracy: 0.8586 - val_loss: 0.6520 - val_accuracy: 0.7623 - val_weighted_accuracy: 0.7591 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3104 - accuracy: 0.8589 - weighted_accuracy: 0.8596 - val_loss: 0.6492 - val_accuracy: 0.7627 - val_weighted_accuracy: 0.7592 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3109 - accuracy: 0.8584 - weighted_accuracy: 0.8591 - val_loss: 0.6496 - val_accuracy: 0.7627 - val_weighted_accuracy: 0.7588 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3105 - accuracy: 0.8587 - weighted_accuracy: 0.8594 - val_loss: 0.6516 - val_accuracy: 0.7626 - val_weighted_accuracy: 0.7585 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3107 - accuracy: 0.8589 - weighted_accuracy: 0.8595 - val_loss: 0.6574 - val_accuracy: 0.7642 - val_weighted_accuracy: 0.7583 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3102 - accuracy: 0.8589 - weighted_accuracy: 0.8596 - val_loss: 0.6564 - val_accuracy: 0.7629 - val_weighted_accuracy: 0.7584 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3095 - accuracy: 0.8595 - weighted_accuracy: 0.8601 - val_loss: 0.6540 - val_accuracy: 0.7602 - val_weighted_accuracy: 0.7591 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3100 - accuracy: 0.8588 - weighted_accuracy: 0.8597 - val_loss: 0.6576 - val_accuracy: 0.7625 - val_weighted_accuracy: 0.7586 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3097 - accuracy: 0.8587 - weighted_accuracy: 0.8595 - val_loss: 0.6574 - val_accuracy: 0.7625 - val_weighted_accuracy: 0.7590 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3090 - accuracy: 0.8590 - weighted_accuracy: 0.8599 - val_loss: 0.6563 - val_accuracy: 0.7632 - val_weighted_accuracy: 0.7593 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3092 - accuracy: 0.8596 - weighted_accuracy: 0.8602 - val_loss: 0.6626 - val_accuracy: 0.7650 - val_weighted_accuracy: 0.7590 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3091 - accuracy: 0.8594 - weighted_accuracy: 0.8602 - val_loss: 0.6608 - val_accuracy: 0.7625 - val_weighted_accuracy: 0.7580 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3092 - accuracy: 0.8593 - weighted_accuracy: 0.8601 - val_loss: 0.6654 - val_accuracy: 0.7636 - val_weighted_accuracy: 0.7585 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3088 - accuracy: 0.8592 - weighted_accuracy: 0.8601 - val_loss: 0.6634 - val_accuracy: 0.7628 - val_weighted_accuracy: 0.7584 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3086 - accuracy: 0.8593 - weighted_accuracy: 0.8600 - val_loss: 0.6614 - val_accuracy: 0.7596 - val_weighted_accuracy: 0.7580 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3082 - accuracy: 0.8595 - weighted_accuracy: 0.8603 - val_loss: 0.6631 - val_accuracy: 0.7627 - val_weighted_accuracy: 0.7585 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3082 - accuracy: 0.8596 - weighted_accuracy: 0.8603 - val_loss: 0.6659 - val_accuracy: 0.7644 - val_weighted_accuracy: 0.7579 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3079 - accuracy: 0.8596 - weighted_accuracy: 0.8604 - val_loss: 0.6637 - val_accuracy: 0.7631 - val_weighted_accuracy: 0.7579 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3078 - accuracy: 0.8596 - weighted_accuracy: 0.8604 - val_loss: 0.6649 - val_accuracy: 0.7619 - val_weighted_accuracy: 0.7583 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3075 - accuracy: 0.8600 - weighted_accuracy: 0.8607 - val_loss: 0.6686 - val_accuracy: 0.7639 - val_weighted_accuracy: 0.7579 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3072 - accuracy: 0.8598 - weighted_accuracy: 0.8608 - val_loss: 0.6655 - val_accuracy: 0.7623 - val_weighted_accuracy: 0.7580 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3071 - accuracy: 0.8603 - weighted_accuracy: 0.8609 - val_loss: 0.6682 - val_accuracy: 0.7619 - val_weighted_accuracy: 0.7579 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3064 - accuracy: 0.8608 - weighted_accuracy: 0.8614 - val_loss: 0.6719 - val_accuracy: 0.7617 - val_weighted_accuracy: 0.7583 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3068 - accuracy: 0.8602 - weighted_accuracy: 0.8610 - val_loss: 0.6719 - val_accuracy: 0.7606 - val_weighted_accuracy: 0.7577 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3071 - accuracy: 0.8600 - weighted_accuracy: 0.8608 - val_loss: 0.6698 - val_accuracy: 0.7623 - val_weighted_accuracy: 0.7581 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "5158/5158 [==============================] - 122s 24ms/step - loss: 0.3063 - accuracy: 0.8603 - weighted_accuracy: 0.8612 - val_loss: 0.6723 - val_accuracy: 0.7632 - val_weighted_accuracy: 0.7575 - lr: 1.0000e-05\n",
      "3224/3224 [==============================] - 8s 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.69     36165\n",
      "           1       0.85      0.78      0.81     66983\n",
      "\n",
      "    accuracy                           0.76    103148\n",
      "   macro avg       0.74      0.76      0.75    103148\n",
      "weighted avg       0.77      0.76      0.77    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[26729  9436]\n",
      " [14988 51995]]\n",
      "Accuracy: 0.7632140225695118\n"
     ]
    }
   ],
   "source": [
    "#create the model\n",
    "model_lstm_updated = Sequential()\n",
    "model_lstm_updated.add(Embedding(input_dim=len(tokenizer_RNN_updated.word_index) + 1, output_dim=128, input_length=30))\n",
    "model_lstm_updated.add(BatchNormalization())\n",
    "model_lstm_updated.add(LSTM(units=50, kernel_regularizer=l2(0.1)))\n",
    "model_lstm_updated.add(BatchNormalization())\n",
    "model_lstm_updated.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model_lstm_updated.compile(\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'],    \n",
    "    weighted_metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#train\n",
    "model_lstm_updated.fit(X_train_RNN_updated, y_train_RNN_updated, epochs=100, batch_size=64, validation_split=0.2, sample_weight=sample_weights_updated, callbacks=[reduce_lr])\n",
    "\n",
    "# test predictions and get evaluation metrics\n",
    "pred_lstm_updated = model_lstm_updated.predict(X_test_RNN_updated)\n",
    "\n",
    "#convert back\n",
    "pred_lstm_updated_convert = np.argmax(pred_lstm_updated, axis=1)\n",
    "\n",
    "#evaluate results from the RNN\n",
    "updated_lstm_class_report = classification_report(y_test_RNN_updated, pred_lstm_updated_convert)\n",
    "updated_lstm_confusion_matrix_class = confusion_matrix(y_test_RNN_updated, pred_lstm_updated_convert)\n",
    "updated_lstm_accuracy_class = accuracy_score(y_test_RNN_updated, pred_lstm_updated_convert)\n",
    "\n",
    "#print the results\n",
    "print(\"Classification Report:\\n\", updated_lstm_class_report)\n",
    "print(\"Confusion Matrix:\\n\", updated_lstm_confusion_matrix_class)\n",
    "print(\"Accuracy:\", updated_lstm_accuracy_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f0fe717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5158/5158 [==============================] - 135s 26ms/step - loss: 0.7661 - accuracy: 0.7613 - weighted_accuracy: 0.7643 - val_loss: 0.4911 - val_accuracy: 0.7488 - val_weighted_accuracy: 0.7732 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.4693 - accuracy: 0.7856 - weighted_accuracy: 0.7873 - val_loss: 0.4827 - val_accuracy: 0.7688 - val_weighted_accuracy: 0.7759 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.4508 - accuracy: 0.7939 - weighted_accuracy: 0.7951 - val_loss: 0.4994 - val_accuracy: 0.7850 - val_weighted_accuracy: 0.7671 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.4333 - accuracy: 0.8018 - weighted_accuracy: 0.8028 - val_loss: 0.4773 - val_accuracy: 0.7812 - val_weighted_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.4228 - accuracy: 0.8073 - weighted_accuracy: 0.8081 - val_loss: 0.4854 - val_accuracy: 0.7834 - val_weighted_accuracy: 0.7720 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.4138 - accuracy: 0.8109 - weighted_accuracy: 0.8118 - val_loss: 0.4808 - val_accuracy: 0.7789 - val_weighted_accuracy: 0.7777 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "5156/5158 [============================>.] - ETA: 0s - loss: 0.4061 - accuracy: 0.8152 - weighted_accuracy: 0.8160\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.4061 - accuracy: 0.8152 - weighted_accuracy: 0.8160 - val_loss: 0.4824 - val_accuracy: 0.7680 - val_weighted_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3838 - accuracy: 0.8252 - weighted_accuracy: 0.8257 - val_loss: 0.5078 - val_accuracy: 0.7807 - val_weighted_accuracy: 0.7699 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3766 - accuracy: 0.8289 - weighted_accuracy: 0.8296 - val_loss: 0.5011 - val_accuracy: 0.7754 - val_weighted_accuracy: 0.7730 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "5157/5158 [============================>.] - ETA: 0s - loss: 0.3722 - accuracy: 0.8317 - weighted_accuracy: 0.8320\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3722 - accuracy: 0.8317 - weighted_accuracy: 0.8320 - val_loss: 0.5203 - val_accuracy: 0.7716 - val_weighted_accuracy: 0.7706 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3580 - accuracy: 0.8379 - weighted_accuracy: 0.8383 - val_loss: 0.5293 - val_accuracy: 0.7738 - val_weighted_accuracy: 0.7710 - lr: 2.5000e-04\n",
      "Epoch 12/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3535 - accuracy: 0.8405 - weighted_accuracy: 0.8407 - val_loss: 0.5235 - val_accuracy: 0.7630 - val_weighted_accuracy: 0.7688 - lr: 2.5000e-04\n",
      "Epoch 13/100\n",
      "5156/5158 [============================>.] - ETA: 0s - loss: 0.3506 - accuracy: 0.8415 - weighted_accuracy: 0.8418\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3507 - accuracy: 0.8415 - weighted_accuracy: 0.8418 - val_loss: 0.5506 - val_accuracy: 0.7714 - val_weighted_accuracy: 0.7671 - lr: 2.5000e-04\n",
      "Epoch 14/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3422 - accuracy: 0.8451 - weighted_accuracy: 0.8455 - val_loss: 0.5572 - val_accuracy: 0.7697 - val_weighted_accuracy: 0.7659 - lr: 1.2500e-04\n",
      "Epoch 15/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3402 - accuracy: 0.8457 - weighted_accuracy: 0.8462 - val_loss: 0.5763 - val_accuracy: 0.7742 - val_weighted_accuracy: 0.7644 - lr: 1.2500e-04\n",
      "Epoch 16/100\n",
      "5157/5158 [============================>.] - ETA: 0s - loss: 0.3382 - accuracy: 0.8467 - weighted_accuracy: 0.8469\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3383 - accuracy: 0.8467 - weighted_accuracy: 0.8469 - val_loss: 0.5621 - val_accuracy: 0.7645 - val_weighted_accuracy: 0.7631 - lr: 1.2500e-04\n",
      "Epoch 17/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3335 - accuracy: 0.8486 - weighted_accuracy: 0.8488 - val_loss: 0.5713 - val_accuracy: 0.7665 - val_weighted_accuracy: 0.7634 - lr: 6.2500e-05\n",
      "Epoch 18/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3320 - accuracy: 0.8489 - weighted_accuracy: 0.8492 - val_loss: 0.5764 - val_accuracy: 0.7695 - val_weighted_accuracy: 0.7635 - lr: 6.2500e-05\n",
      "Epoch 19/100\n",
      "5156/5158 [============================>.] - ETA: 0s - loss: 0.3311 - accuracy: 0.8495 - weighted_accuracy: 0.8498\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3310 - accuracy: 0.8495 - weighted_accuracy: 0.8498 - val_loss: 0.5831 - val_accuracy: 0.7716 - val_weighted_accuracy: 0.7631 - lr: 6.2500e-05\n",
      "Epoch 20/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3279 - accuracy: 0.8516 - weighted_accuracy: 0.8516 - val_loss: 0.5857 - val_accuracy: 0.7657 - val_weighted_accuracy: 0.7637 - lr: 3.1250e-05\n",
      "Epoch 21/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3275 - accuracy: 0.8516 - weighted_accuracy: 0.8518 - val_loss: 0.5847 - val_accuracy: 0.7665 - val_weighted_accuracy: 0.7633 - lr: 3.1250e-05\n",
      "Epoch 22/100\n",
      "5157/5158 [============================>.] - ETA: 0s - loss: 0.3267 - accuracy: 0.8513 - weighted_accuracy: 0.8515\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3267 - accuracy: 0.8513 - weighted_accuracy: 0.8515 - val_loss: 0.5915 - val_accuracy: 0.7664 - val_weighted_accuracy: 0.7629 - lr: 3.1250e-05\n",
      "Epoch 23/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3258 - accuracy: 0.8526 - weighted_accuracy: 0.8531 - val_loss: 0.5968 - val_accuracy: 0.7668 - val_weighted_accuracy: 0.7622 - lr: 1.5625e-05\n",
      "Epoch 24/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3250 - accuracy: 0.8522 - weighted_accuracy: 0.8526 - val_loss: 0.5961 - val_accuracy: 0.7676 - val_weighted_accuracy: 0.7625 - lr: 1.5625e-05\n",
      "Epoch 25/100\n",
      "5156/5158 [============================>.] - ETA: 0s - loss: 0.3247 - accuracy: 0.8526 - weighted_accuracy: 0.8530\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3247 - accuracy: 0.8526 - weighted_accuracy: 0.8530 - val_loss: 0.5968 - val_accuracy: 0.7648 - val_weighted_accuracy: 0.7614 - lr: 1.5625e-05\n",
      "Epoch 26/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3244 - accuracy: 0.8526 - weighted_accuracy: 0.8528 - val_loss: 0.6014 - val_accuracy: 0.7672 - val_weighted_accuracy: 0.7619 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3244 - accuracy: 0.8528 - weighted_accuracy: 0.8529 - val_loss: 0.6000 - val_accuracy: 0.7663 - val_weighted_accuracy: 0.7624 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3237 - accuracy: 0.8530 - weighted_accuracy: 0.8533 - val_loss: 0.6032 - val_accuracy: 0.7651 - val_weighted_accuracy: 0.7620 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3236 - accuracy: 0.8534 - weighted_accuracy: 0.8537 - val_loss: 0.6018 - val_accuracy: 0.7667 - val_weighted_accuracy: 0.7617 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3236 - accuracy: 0.8534 - weighted_accuracy: 0.8537 - val_loss: 0.6059 - val_accuracy: 0.7667 - val_weighted_accuracy: 0.7611 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3235 - accuracy: 0.8532 - weighted_accuracy: 0.8533 - val_loss: 0.6049 - val_accuracy: 0.7657 - val_weighted_accuracy: 0.7609 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3230 - accuracy: 0.8532 - weighted_accuracy: 0.8534 - val_loss: 0.6076 - val_accuracy: 0.7662 - val_weighted_accuracy: 0.7608 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3234 - accuracy: 0.8532 - weighted_accuracy: 0.8536 - val_loss: 0.6057 - val_accuracy: 0.7664 - val_weighted_accuracy: 0.7617 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3225 - accuracy: 0.8532 - weighted_accuracy: 0.8535 - val_loss: 0.6040 - val_accuracy: 0.7655 - val_weighted_accuracy: 0.7610 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3228 - accuracy: 0.8535 - weighted_accuracy: 0.8535 - val_loss: 0.6093 - val_accuracy: 0.7663 - val_weighted_accuracy: 0.7610 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3226 - accuracy: 0.8528 - weighted_accuracy: 0.8532 - val_loss: 0.6063 - val_accuracy: 0.7660 - val_weighted_accuracy: 0.7614 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3223 - accuracy: 0.8535 - weighted_accuracy: 0.8541 - val_loss: 0.6087 - val_accuracy: 0.7664 - val_weighted_accuracy: 0.7612 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3224 - accuracy: 0.8539 - weighted_accuracy: 0.8541 - val_loss: 0.6092 - val_accuracy: 0.7661 - val_weighted_accuracy: 0.7617 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3221 - accuracy: 0.8535 - weighted_accuracy: 0.8537 - val_loss: 0.6120 - val_accuracy: 0.7659 - val_weighted_accuracy: 0.7607 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3219 - accuracy: 0.8539 - weighted_accuracy: 0.8541 - val_loss: 0.6143 - val_accuracy: 0.7665 - val_weighted_accuracy: 0.7609 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3223 - accuracy: 0.8536 - weighted_accuracy: 0.8538 - val_loss: 0.6066 - val_accuracy: 0.7648 - val_weighted_accuracy: 0.7609 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3217 - accuracy: 0.8537 - weighted_accuracy: 0.8538 - val_loss: 0.6113 - val_accuracy: 0.7645 - val_weighted_accuracy: 0.7608 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3213 - accuracy: 0.8541 - weighted_accuracy: 0.8544 - val_loss: 0.6108 - val_accuracy: 0.7650 - val_weighted_accuracy: 0.7608 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3215 - accuracy: 0.8545 - weighted_accuracy: 0.8548 - val_loss: 0.6098 - val_accuracy: 0.7651 - val_weighted_accuracy: 0.7607 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3212 - accuracy: 0.8539 - weighted_accuracy: 0.8542 - val_loss: 0.6134 - val_accuracy: 0.7661 - val_weighted_accuracy: 0.7604 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3209 - accuracy: 0.8547 - weighted_accuracy: 0.8547 - val_loss: 0.6151 - val_accuracy: 0.7649 - val_weighted_accuracy: 0.7604 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3206 - accuracy: 0.8546 - weighted_accuracy: 0.8549 - val_loss: 0.6165 - val_accuracy: 0.7638 - val_weighted_accuracy: 0.7594 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3202 - accuracy: 0.8549 - weighted_accuracy: 0.8553 - val_loss: 0.6162 - val_accuracy: 0.7634 - val_weighted_accuracy: 0.7598 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3202 - accuracy: 0.8546 - weighted_accuracy: 0.8550 - val_loss: 0.6126 - val_accuracy: 0.7638 - val_weighted_accuracy: 0.7598 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3204 - accuracy: 0.8547 - weighted_accuracy: 0.8550 - val_loss: 0.6155 - val_accuracy: 0.7653 - val_weighted_accuracy: 0.7600 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3200 - accuracy: 0.8550 - weighted_accuracy: 0.8553 - val_loss: 0.6214 - val_accuracy: 0.7668 - val_weighted_accuracy: 0.7599 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3198 - accuracy: 0.8548 - weighted_accuracy: 0.8550 - val_loss: 0.6159 - val_accuracy: 0.7641 - val_weighted_accuracy: 0.7595 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3199 - accuracy: 0.8549 - weighted_accuracy: 0.8552 - val_loss: 0.6187 - val_accuracy: 0.7639 - val_weighted_accuracy: 0.7604 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3198 - accuracy: 0.8545 - weighted_accuracy: 0.8549 - val_loss: 0.6189 - val_accuracy: 0.7664 - val_weighted_accuracy: 0.7600 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3196 - accuracy: 0.8552 - weighted_accuracy: 0.8555 - val_loss: 0.6197 - val_accuracy: 0.7651 - val_weighted_accuracy: 0.7602 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3193 - accuracy: 0.8554 - weighted_accuracy: 0.8558 - val_loss: 0.6266 - val_accuracy: 0.7647 - val_weighted_accuracy: 0.7593 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3189 - accuracy: 0.8551 - weighted_accuracy: 0.8554 - val_loss: 0.6219 - val_accuracy: 0.7644 - val_weighted_accuracy: 0.7597 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3192 - accuracy: 0.8551 - weighted_accuracy: 0.8554 - val_loss: 0.6219 - val_accuracy: 0.7631 - val_weighted_accuracy: 0.7595 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3193 - accuracy: 0.8549 - weighted_accuracy: 0.8554 - val_loss: 0.6222 - val_accuracy: 0.7642 - val_weighted_accuracy: 0.7595 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3186 - accuracy: 0.8555 - weighted_accuracy: 0.8557 - val_loss: 0.6224 - val_accuracy: 0.7634 - val_weighted_accuracy: 0.7601 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3187 - accuracy: 0.8557 - weighted_accuracy: 0.8559 - val_loss: 0.6263 - val_accuracy: 0.7652 - val_weighted_accuracy: 0.7592 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3180 - accuracy: 0.8561 - weighted_accuracy: 0.8563 - val_loss: 0.6275 - val_accuracy: 0.7641 - val_weighted_accuracy: 0.7593 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3181 - accuracy: 0.8554 - weighted_accuracy: 0.8558 - val_loss: 0.6264 - val_accuracy: 0.7645 - val_weighted_accuracy: 0.7592 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3184 - accuracy: 0.8557 - weighted_accuracy: 0.8560 - val_loss: 0.6229 - val_accuracy: 0.7634 - val_weighted_accuracy: 0.7591 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3178 - accuracy: 0.8558 - weighted_accuracy: 0.8560 - val_loss: 0.6287 - val_accuracy: 0.7656 - val_weighted_accuracy: 0.7592 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3173 - accuracy: 0.8558 - weighted_accuracy: 0.8562 - val_loss: 0.6307 - val_accuracy: 0.7642 - val_weighted_accuracy: 0.7598 - lr: 1.0000e-05\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3173 - accuracy: 0.8562 - weighted_accuracy: 0.8565 - val_loss: 0.6300 - val_accuracy: 0.7656 - val_weighted_accuracy: 0.7592 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3173 - accuracy: 0.8561 - weighted_accuracy: 0.8562 - val_loss: 0.6299 - val_accuracy: 0.7632 - val_weighted_accuracy: 0.7595 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3169 - accuracy: 0.8561 - weighted_accuracy: 0.8566 - val_loss: 0.6264 - val_accuracy: 0.7637 - val_weighted_accuracy: 0.7596 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3172 - accuracy: 0.8561 - weighted_accuracy: 0.8564 - val_loss: 0.6279 - val_accuracy: 0.7632 - val_weighted_accuracy: 0.7595 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3167 - accuracy: 0.8563 - weighted_accuracy: 0.8564 - val_loss: 0.6335 - val_accuracy: 0.7646 - val_weighted_accuracy: 0.7595 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3165 - accuracy: 0.8568 - weighted_accuracy: 0.8573 - val_loss: 0.6302 - val_accuracy: 0.7634 - val_weighted_accuracy: 0.7598 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3164 - accuracy: 0.8564 - weighted_accuracy: 0.8569 - val_loss: 0.6345 - val_accuracy: 0.7635 - val_weighted_accuracy: 0.7589 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3167 - accuracy: 0.8567 - weighted_accuracy: 0.8570 - val_loss: 0.6326 - val_accuracy: 0.7624 - val_weighted_accuracy: 0.7591 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3165 - accuracy: 0.8562 - weighted_accuracy: 0.8565 - val_loss: 0.6338 - val_accuracy: 0.7638 - val_weighted_accuracy: 0.7593 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3164 - accuracy: 0.8561 - weighted_accuracy: 0.8563 - val_loss: 0.6383 - val_accuracy: 0.7649 - val_weighted_accuracy: 0.7592 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3162 - accuracy: 0.8565 - weighted_accuracy: 0.8568 - val_loss: 0.6354 - val_accuracy: 0.7639 - val_weighted_accuracy: 0.7587 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3157 - accuracy: 0.8568 - weighted_accuracy: 0.8570 - val_loss: 0.6328 - val_accuracy: 0.7631 - val_weighted_accuracy: 0.7590 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3156 - accuracy: 0.8568 - weighted_accuracy: 0.8571 - val_loss: 0.6355 - val_accuracy: 0.7631 - val_weighted_accuracy: 0.7595 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3151 - accuracy: 0.8567 - weighted_accuracy: 0.8569 - val_loss: 0.6326 - val_accuracy: 0.7627 - val_weighted_accuracy: 0.7591 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3152 - accuracy: 0.8569 - weighted_accuracy: 0.8573 - val_loss: 0.6386 - val_accuracy: 0.7624 - val_weighted_accuracy: 0.7590 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3152 - accuracy: 0.8570 - weighted_accuracy: 0.8572 - val_loss: 0.6395 - val_accuracy: 0.7638 - val_weighted_accuracy: 0.7584 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3150 - accuracy: 0.8571 - weighted_accuracy: 0.8574 - val_loss: 0.6399 - val_accuracy: 0.7649 - val_weighted_accuracy: 0.7591 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3150 - accuracy: 0.8572 - weighted_accuracy: 0.8574 - val_loss: 0.6415 - val_accuracy: 0.7636 - val_weighted_accuracy: 0.7580 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3149 - accuracy: 0.8573 - weighted_accuracy: 0.8576 - val_loss: 0.6428 - val_accuracy: 0.7648 - val_weighted_accuracy: 0.7587 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3149 - accuracy: 0.8568 - weighted_accuracy: 0.8572 - val_loss: 0.6411 - val_accuracy: 0.7646 - val_weighted_accuracy: 0.7583 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3143 - accuracy: 0.8574 - weighted_accuracy: 0.8576 - val_loss: 0.6426 - val_accuracy: 0.7636 - val_weighted_accuracy: 0.7591 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3145 - accuracy: 0.8572 - weighted_accuracy: 0.8575 - val_loss: 0.6398 - val_accuracy: 0.7614 - val_weighted_accuracy: 0.7584 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "5158/5158 [==============================] - 133s 26ms/step - loss: 0.3144 - accuracy: 0.8575 - weighted_accuracy: 0.8575 - val_loss: 0.6439 - val_accuracy: 0.7626 - val_weighted_accuracy: 0.7588 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3141 - accuracy: 0.8571 - weighted_accuracy: 0.8576 - val_loss: 0.6447 - val_accuracy: 0.7633 - val_weighted_accuracy: 0.7579 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3144 - accuracy: 0.8575 - weighted_accuracy: 0.8578 - val_loss: 0.6432 - val_accuracy: 0.7629 - val_weighted_accuracy: 0.7584 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3133 - accuracy: 0.8580 - weighted_accuracy: 0.8582 - val_loss: 0.6491 - val_accuracy: 0.7627 - val_weighted_accuracy: 0.7581 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3137 - accuracy: 0.8574 - weighted_accuracy: 0.8579 - val_loss: 0.6439 - val_accuracy: 0.7640 - val_weighted_accuracy: 0.7592 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3130 - accuracy: 0.8577 - weighted_accuracy: 0.8579 - val_loss: 0.6456 - val_accuracy: 0.7621 - val_weighted_accuracy: 0.7578 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3133 - accuracy: 0.8583 - weighted_accuracy: 0.8586 - val_loss: 0.6494 - val_accuracy: 0.7625 - val_weighted_accuracy: 0.7584 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3127 - accuracy: 0.8580 - weighted_accuracy: 0.8585 - val_loss: 0.6483 - val_accuracy: 0.7631 - val_weighted_accuracy: 0.7584 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3130 - accuracy: 0.8582 - weighted_accuracy: 0.8582 - val_loss: 0.6476 - val_accuracy: 0.7618 - val_weighted_accuracy: 0.7579 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3130 - accuracy: 0.8581 - weighted_accuracy: 0.8584 - val_loss: 0.6460 - val_accuracy: 0.7616 - val_weighted_accuracy: 0.7579 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3120 - accuracy: 0.8588 - weighted_accuracy: 0.8591 - val_loss: 0.6490 - val_accuracy: 0.7621 - val_weighted_accuracy: 0.7573 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "5158/5158 [==============================] - 134s 26ms/step - loss: 0.3123 - accuracy: 0.8580 - weighted_accuracy: 0.8584 - val_loss: 0.6471 - val_accuracy: 0.7606 - val_weighted_accuracy: 0.7581 - lr: 1.0000e-05\n",
      "3224/3224 [==============================] - 9s 3ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.75      0.69     36165\n",
      "           1       0.85      0.77      0.81     66983\n",
      "\n",
      "    accuracy                           0.76    103148\n",
      "   macro avg       0.74      0.76      0.75    103148\n",
      "weighted avg       0.78      0.76      0.77    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[27226  8939]\n",
      " [15629 51354]]\n",
      "Accuracy: 0.7618179702951099\n"
     ]
    }
   ],
   "source": [
    "#create the bi-lstm model\n",
    "model_bi_lstm_updated = Sequential()\n",
    "model_bi_lstm_updated.add(Embedding(input_dim=len(tokenizer_RNN_updated.word_index) + 1, output_dim=128, input_length=30))\n",
    "model_bi_lstm_updated.add(BatchNormalization())\n",
    "model_bi_lstm_updated.add(Bidirectional(LSTM(units=50, kernel_regularizer=l2(0.1))))\n",
    "model_bi_lstm_updated.add(BatchNormalization())\n",
    "model_bi_lstm_updated.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model_bi_lstm_updated.compile(\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'],    \n",
    "    weighted_metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#train\n",
    "model_bi_lstm_updated.fit(X_train_RNN_updated, y_train_RNN_updated, epochs=100, batch_size=64, validation_split=0.2, sample_weight=sample_weights_updated, callbacks=[reduce_lr])\n",
    "\n",
    "# test predictions and get evaluation metrics\n",
    "pred_bi_lstm_updated = model_bi_lstm_updated.predict(X_test_RNN_updated)\n",
    "\n",
    "#convert back\n",
    "pred_bi_lstm_updated_convert = np.argmax(pred_bi_lstm_updated, axis=1)\n",
    "\n",
    "#evaluate results from the RNN\n",
    "updated_bi_lstm_class_report = classification_report(y_test_RNN_updated, pred_bi_lstm_updated_convert)\n",
    "updated_bi_lstm_confusion_matrix_class = confusion_matrix(y_test_RNN_updated, pred_bi_lstm_updated_convert)\n",
    "updated_bi_lstm_accuracy_class = accuracy_score(y_test_RNN_updated, pred_bi_lstm_updated_convert)\n",
    "\n",
    "#print the results\n",
    "print(\"Classification Report:\\n\", updated_bi_lstm_class_report)\n",
    "print(\"Confusion Matrix:\\n\", updated_bi_lstm_confusion_matrix_class)\n",
    "print(\"Accuracy:\", updated_bi_lstm_accuracy_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "459fe1a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5158/5158 [==============================] - 220s 42ms/step - loss: 0.6046 - accuracy: 0.7618 - weighted_accuracy: 0.7645 - val_loss: 0.4736 - val_accuracy: 0.7823 - val_weighted_accuracy: 0.7763 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "5158/5158 [==============================] - 221s 43ms/step - loss: 0.4616 - accuracy: 0.7888 - weighted_accuracy: 0.7896 - val_loss: 0.4822 - val_accuracy: 0.7942 - val_weighted_accuracy: 0.7773 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "5158/5158 [==============================] - 234s 45ms/step - loss: 0.4429 - accuracy: 0.7994 - weighted_accuracy: 0.7996 - val_loss: 0.4679 - val_accuracy: 0.7811 - val_weighted_accuracy: 0.7815 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "5158/5158 [==============================] - 248s 48ms/step - loss: 0.4280 - accuracy: 0.8087 - weighted_accuracy: 0.8085 - val_loss: 0.4845 - val_accuracy: 0.7880 - val_weighted_accuracy: 0.7729 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "5158/5158 [==============================] - 242s 47ms/step - loss: 0.4140 - accuracy: 0.8169 - weighted_accuracy: 0.8164 - val_loss: 0.4854 - val_accuracy: 0.7801 - val_weighted_accuracy: 0.7767 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "5157/5158 [============================>.] - ETA: 0s - loss: 0.4007 - accuracy: 0.8251 - weighted_accuracy: 0.8242\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "5158/5158 [==============================] - 262s 51ms/step - loss: 0.4007 - accuracy: 0.8251 - weighted_accuracy: 0.8242 - val_loss: 0.4971 - val_accuracy: 0.7764 - val_weighted_accuracy: 0.7731 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "5158/5158 [==============================] - 263s 51ms/step - loss: 0.3697 - accuracy: 0.8388 - weighted_accuracy: 0.8380 - val_loss: 0.5197 - val_accuracy: 0.7784 - val_weighted_accuracy: 0.7685 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "5158/5158 [==============================] - 258s 50ms/step - loss: 0.3581 - accuracy: 0.8448 - weighted_accuracy: 0.8435 - val_loss: 0.5495 - val_accuracy: 0.7717 - val_weighted_accuracy: 0.7669 - lr: 5.0000e-04\n",
      "Epoch 9/10\n",
      "5157/5158 [============================>.] - ETA: 0s - loss: 0.3496 - accuracy: 0.8490 - weighted_accuracy: 0.8476\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "5158/5158 [==============================] - 263s 51ms/step - loss: 0.3496 - accuracy: 0.8490 - weighted_accuracy: 0.8476 - val_loss: 0.5377 - val_accuracy: 0.7720 - val_weighted_accuracy: 0.7667 - lr: 5.0000e-04\n",
      "Epoch 10/10\n",
      "5158/5158 [==============================] - 256s 50ms/step - loss: 0.3281 - accuracy: 0.8587 - weighted_accuracy: 0.8577 - val_loss: 0.5737 - val_accuracy: 0.7713 - val_weighted_accuracy: 0.7636 - lr: 2.5000e-04\n",
      "3224/3224 [==============================] - 17s 5ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69     36165\n",
      "           1       0.85      0.79      0.82     66983\n",
      "\n",
      "    accuracy                           0.77    103148\n",
      "   macro avg       0.75      0.76      0.76    103148\n",
      "weighted avg       0.78      0.77      0.77    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[26786  9379]\n",
      " [14283 52700]]\n",
      "Accuracy: 0.7706014658548881\n"
     ]
    }
   ],
   "source": [
    "# create the GRU model\n",
    "model_gru_updated = Sequential()\n",
    "model_gru_updated.add(Embedding(input_dim=len(tokenizer_RNN_updated.word_index) + 1, output_dim=128, input_length=30))\n",
    "model_gru_updated.add(BatchNormalization())\n",
    "model_gru_updated.add(GRU(units=100, kernel_regularizer=l2(0.01), return_sequences=True))\n",
    "model_gru_updated.add(BatchNormalization())\n",
    "model_gru_updated.add(GRU(units=50, kernel_regularizer=l2(0.01)))\n",
    "model_gru_updated.add(BatchNormalization())\n",
    "model_gru_updated.add(Dropout(0.5))\n",
    "model_gru_updated.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model_gru_updated.compile(\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'],    \n",
    "    weighted_metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#train\n",
    "model_gru_updated.fit(X_train_RNN_updated, y_train_RNN_updated, epochs=10, batch_size=64, validation_split=0.2, sample_weight=sample_weights_updated, callbacks=[reduce_lr])\n",
    "\n",
    "# test predictions and get evaluation metrics\n",
    "pred_gru_updated = model_gru_updated.predict(X_test_RNN_updated)\n",
    "\n",
    "#convert back\n",
    "pred_gru_updated_convert = np.argmax(pred_gru_updated, axis=1)\n",
    "\n",
    "#evaluate results from the RNN\n",
    "updated_gru_class_report = classification_report(y_test_RNN_updated, pred_gru_updated_convert)\n",
    "updated_gru_confusion_matrix_class = confusion_matrix(y_test_RNN_updated, pred_gru_updated_convert)\n",
    "updated_gru_accuracy_class = accuracy_score(y_test_RNN_updated, pred_gru_updated_convert)\n",
    "\n",
    "#print the results\n",
    "print(\"Classification Report:\\n\", updated_gru_class_report)\n",
    "print(\"Confusion Matrix:\\n\", updated_gru_confusion_matrix_class)\n",
    "print(\"Accuracy:\", updated_gru_accuracy_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c841b",
   "metadata": {},
   "source": [
    "Taking the best results with the SimpleRNN, I will test a larger batch size as a scenario to see if that helps. I will also try to overfit the minority class to see if it helps more in a following model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38441a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.6478 - accuracy: 0.7265 - weighted_accuracy: 0.7303 - val_loss: 0.5164 - val_accuracy: 0.7791 - val_weighted_accuracy: 0.7525 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "2579/2579 [==============================] - 54s 21ms/step - loss: 0.4831 - accuracy: 0.7703 - weighted_accuracy: 0.7725 - val_loss: 0.4929 - val_accuracy: 0.7374 - val_weighted_accuracy: 0.7620 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.4512 - accuracy: 0.7887 - weighted_accuracy: 0.7898 - val_loss: 0.4772 - val_accuracy: 0.7783 - val_weighted_accuracy: 0.7731 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.4333 - accuracy: 0.7996 - weighted_accuracy: 0.8002 - val_loss: 0.4825 - val_accuracy: 0.7873 - val_weighted_accuracy: 0.7725 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "2579/2579 [==============================] - 54s 21ms/step - loss: 0.4155 - accuracy: 0.8103 - weighted_accuracy: 0.8101 - val_loss: 0.4997 - val_accuracy: 0.7562 - val_weighted_accuracy: 0.7710 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "2577/2579 [============================>.] - ETA: 0s - loss: 0.4031 - accuracy: 0.8166 - weighted_accuracy: 0.8170\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2579/2579 [==============================] - 54s 21ms/step - loss: 0.4031 - accuracy: 0.8166 - weighted_accuracy: 0.8170 - val_loss: 0.5028 - val_accuracy: 0.7663 - val_weighted_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.3725 - accuracy: 0.8318 - weighted_accuracy: 0.8329 - val_loss: 0.4951 - val_accuracy: 0.7652 - val_weighted_accuracy: 0.7720 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.3537 - accuracy: 0.8422 - weighted_accuracy: 0.8426 - val_loss: 0.5052 - val_accuracy: 0.7809 - val_weighted_accuracy: 0.7697 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "2578/2579 [============================>.] - ETA: 0s - loss: 0.3411 - accuracy: 0.8485 - weighted_accuracy: 0.8488\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.3411 - accuracy: 0.8485 - weighted_accuracy: 0.8488 - val_loss: 0.5238 - val_accuracy: 0.7812 - val_weighted_accuracy: 0.7656 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.3185 - accuracy: 0.8607 - weighted_accuracy: 0.8613 - val_loss: 0.5211 - val_accuracy: 0.7721 - val_weighted_accuracy: 0.7657 - lr: 2.5000e-04\n",
      "Epoch 11/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.3071 - accuracy: 0.8671 - weighted_accuracy: 0.8675 - val_loss: 0.5490 - val_accuracy: 0.7669 - val_weighted_accuracy: 0.7678 - lr: 2.5000e-04\n",
      "Epoch 12/100\n",
      "2578/2579 [============================>.] - ETA: 0s - loss: 0.2980 - accuracy: 0.8716 - weighted_accuracy: 0.8721\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "2579/2579 [==============================] - 54s 21ms/step - loss: 0.2981 - accuracy: 0.8716 - weighted_accuracy: 0.8721 - val_loss: 0.5520 - val_accuracy: 0.7733 - val_weighted_accuracy: 0.7666 - lr: 2.5000e-04\n",
      "Epoch 13/100\n",
      "2579/2579 [==============================] - 54s 21ms/step - loss: 0.2851 - accuracy: 0.8780 - weighted_accuracy: 0.8786 - val_loss: 0.5759 - val_accuracy: 0.7724 - val_weighted_accuracy: 0.7638 - lr: 1.2500e-04\n",
      "Epoch 14/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2784 - accuracy: 0.8814 - weighted_accuracy: 0.8819 - val_loss: 0.5817 - val_accuracy: 0.7695 - val_weighted_accuracy: 0.7623 - lr: 1.2500e-04\n",
      "Epoch 15/100\n",
      "2578/2579 [============================>.] - ETA: 0s - loss: 0.2737 - accuracy: 0.8837 - weighted_accuracy: 0.8845\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2737 - accuracy: 0.8837 - weighted_accuracy: 0.8845 - val_loss: 0.5859 - val_accuracy: 0.7691 - val_weighted_accuracy: 0.7625 - lr: 1.2500e-04\n",
      "Epoch 16/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2662 - accuracy: 0.8877 - weighted_accuracy: 0.8881 - val_loss: 0.6020 - val_accuracy: 0.7684 - val_weighted_accuracy: 0.7610 - lr: 6.2500e-05\n",
      "Epoch 17/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2632 - accuracy: 0.8886 - weighted_accuracy: 0.8894 - val_loss: 0.6132 - val_accuracy: 0.7687 - val_weighted_accuracy: 0.7607 - lr: 6.2500e-05\n",
      "Epoch 18/100\n",
      "2578/2579 [============================>.] - ETA: 0s - loss: 0.2602 - accuracy: 0.8904 - weighted_accuracy: 0.8911\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2602 - accuracy: 0.8904 - weighted_accuracy: 0.8911 - val_loss: 0.6101 - val_accuracy: 0.7667 - val_weighted_accuracy: 0.7601 - lr: 6.2500e-05\n",
      "Epoch 19/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2558 - accuracy: 0.8925 - weighted_accuracy: 0.8932 - val_loss: 0.6178 - val_accuracy: 0.7686 - val_weighted_accuracy: 0.7594 - lr: 3.1250e-05\n",
      "Epoch 20/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2534 - accuracy: 0.8941 - weighted_accuracy: 0.8948 - val_loss: 0.6306 - val_accuracy: 0.7652 - val_weighted_accuracy: 0.7601 - lr: 3.1250e-05\n",
      "Epoch 21/100\n",
      "2578/2579 [============================>.] - ETA: 0s - loss: 0.2527 - accuracy: 0.8941 - weighted_accuracy: 0.8949\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2527 - accuracy: 0.8941 - weighted_accuracy: 0.8949 - val_loss: 0.6299 - val_accuracy: 0.7673 - val_weighted_accuracy: 0.7595 - lr: 3.1250e-05\n",
      "Epoch 22/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2503 - accuracy: 0.8955 - weighted_accuracy: 0.8962 - val_loss: 0.6409 - val_accuracy: 0.7666 - val_weighted_accuracy: 0.7584 - lr: 1.5625e-05\n",
      "Epoch 23/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2495 - accuracy: 0.8957 - weighted_accuracy: 0.8965 - val_loss: 0.6383 - val_accuracy: 0.7661 - val_weighted_accuracy: 0.7584 - lr: 1.5625e-05\n",
      "Epoch 24/100\n",
      "2578/2579 [============================>.] - ETA: 0s - loss: 0.2485 - accuracy: 0.8966 - weighted_accuracy: 0.8973\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2484 - accuracy: 0.8966 - weighted_accuracy: 0.8973 - val_loss: 0.6416 - val_accuracy: 0.7662 - val_weighted_accuracy: 0.7580 - lr: 1.5625e-05\n",
      "Epoch 25/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2478 - accuracy: 0.8964 - weighted_accuracy: 0.8971 - val_loss: 0.6475 - val_accuracy: 0.7653 - val_weighted_accuracy: 0.7584 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2474 - accuracy: 0.8964 - weighted_accuracy: 0.8973 - val_loss: 0.6459 - val_accuracy: 0.7663 - val_weighted_accuracy: 0.7581 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2466 - accuracy: 0.8971 - weighted_accuracy: 0.8979 - val_loss: 0.6450 - val_accuracy: 0.7660 - val_weighted_accuracy: 0.7579 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2465 - accuracy: 0.8970 - weighted_accuracy: 0.8979 - val_loss: 0.6488 - val_accuracy: 0.7653 - val_weighted_accuracy: 0.7582 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2460 - accuracy: 0.8974 - weighted_accuracy: 0.8983 - val_loss: 0.6499 - val_accuracy: 0.7654 - val_weighted_accuracy: 0.7580 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2458 - accuracy: 0.8975 - weighted_accuracy: 0.8983 - val_loss: 0.6523 - val_accuracy: 0.7658 - val_weighted_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2453 - accuracy: 0.8975 - weighted_accuracy: 0.8983 - val_loss: 0.6498 - val_accuracy: 0.7655 - val_weighted_accuracy: 0.7575 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2447 - accuracy: 0.8978 - weighted_accuracy: 0.8986 - val_loss: 0.6538 - val_accuracy: 0.7648 - val_weighted_accuracy: 0.7580 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2443 - accuracy: 0.8984 - weighted_accuracy: 0.8992 - val_loss: 0.6519 - val_accuracy: 0.7650 - val_weighted_accuracy: 0.7572 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2441 - accuracy: 0.8984 - weighted_accuracy: 0.8993 - val_loss: 0.6581 - val_accuracy: 0.7650 - val_weighted_accuracy: 0.7578 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2430 - accuracy: 0.8989 - weighted_accuracy: 0.8998 - val_loss: 0.6562 - val_accuracy: 0.7652 - val_weighted_accuracy: 0.7576 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2427 - accuracy: 0.8989 - weighted_accuracy: 0.8997 - val_loss: 0.6588 - val_accuracy: 0.7650 - val_weighted_accuracy: 0.7575 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2423 - accuracy: 0.8993 - weighted_accuracy: 0.9002 - val_loss: 0.6621 - val_accuracy: 0.7654 - val_weighted_accuracy: 0.7571 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2420 - accuracy: 0.8995 - weighted_accuracy: 0.9003 - val_loss: 0.6592 - val_accuracy: 0.7641 - val_weighted_accuracy: 0.7572 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2418 - accuracy: 0.8991 - weighted_accuracy: 0.9000 - val_loss: 0.6612 - val_accuracy: 0.7645 - val_weighted_accuracy: 0.7572 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2415 - accuracy: 0.8996 - weighted_accuracy: 0.9005 - val_loss: 0.6650 - val_accuracy: 0.7647 - val_weighted_accuracy: 0.7570 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2410 - accuracy: 0.8995 - weighted_accuracy: 0.9004 - val_loss: 0.6681 - val_accuracy: 0.7643 - val_weighted_accuracy: 0.7567 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2405 - accuracy: 0.8999 - weighted_accuracy: 0.9008 - val_loss: 0.6700 - val_accuracy: 0.7641 - val_weighted_accuracy: 0.7569 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2404 - accuracy: 0.9000 - weighted_accuracy: 0.9009 - val_loss: 0.6652 - val_accuracy: 0.7641 - val_weighted_accuracy: 0.7564 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2398 - accuracy: 0.9006 - weighted_accuracy: 0.9014 - val_loss: 0.6684 - val_accuracy: 0.7654 - val_weighted_accuracy: 0.7567 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2395 - accuracy: 0.9007 - weighted_accuracy: 0.9016 - val_loss: 0.6713 - val_accuracy: 0.7657 - val_weighted_accuracy: 0.7559 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2390 - accuracy: 0.9008 - weighted_accuracy: 0.9018 - val_loss: 0.6722 - val_accuracy: 0.7642 - val_weighted_accuracy: 0.7561 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2390 - accuracy: 0.9009 - weighted_accuracy: 0.9018 - val_loss: 0.6744 - val_accuracy: 0.7659 - val_weighted_accuracy: 0.7564 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2383 - accuracy: 0.9011 - weighted_accuracy: 0.9019 - val_loss: 0.6699 - val_accuracy: 0.7649 - val_weighted_accuracy: 0.7566 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2380 - accuracy: 0.9011 - weighted_accuracy: 0.9021 - val_loss: 0.6707 - val_accuracy: 0.7644 - val_weighted_accuracy: 0.7562 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2375 - accuracy: 0.9015 - weighted_accuracy: 0.9024 - val_loss: 0.6741 - val_accuracy: 0.7649 - val_weighted_accuracy: 0.7563 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2371 - accuracy: 0.9014 - weighted_accuracy: 0.9025 - val_loss: 0.6769 - val_accuracy: 0.7642 - val_weighted_accuracy: 0.7563 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2365 - accuracy: 0.9019 - weighted_accuracy: 0.9029 - val_loss: 0.6786 - val_accuracy: 0.7632 - val_weighted_accuracy: 0.7557 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2369 - accuracy: 0.9015 - weighted_accuracy: 0.9024 - val_loss: 0.6810 - val_accuracy: 0.7632 - val_weighted_accuracy: 0.7557 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2361 - accuracy: 0.9023 - weighted_accuracy: 0.9033 - val_loss: 0.6810 - val_accuracy: 0.7642 - val_weighted_accuracy: 0.7561 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2358 - accuracy: 0.9024 - weighted_accuracy: 0.9033 - val_loss: 0.6842 - val_accuracy: 0.7630 - val_weighted_accuracy: 0.7554 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2352 - accuracy: 0.9020 - weighted_accuracy: 0.9030 - val_loss: 0.6830 - val_accuracy: 0.7630 - val_weighted_accuracy: 0.7555 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2352 - accuracy: 0.9021 - weighted_accuracy: 0.9031 - val_loss: 0.6827 - val_accuracy: 0.7635 - val_weighted_accuracy: 0.7550 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2348 - accuracy: 0.9028 - weighted_accuracy: 0.9038 - val_loss: 0.6834 - val_accuracy: 0.7633 - val_weighted_accuracy: 0.7555 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2343 - accuracy: 0.9029 - weighted_accuracy: 0.9040 - val_loss: 0.6853 - val_accuracy: 0.7638 - val_weighted_accuracy: 0.7550 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2341 - accuracy: 0.9032 - weighted_accuracy: 0.9040 - val_loss: 0.6823 - val_accuracy: 0.7627 - val_weighted_accuracy: 0.7552 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2336 - accuracy: 0.9031 - weighted_accuracy: 0.9041 - val_loss: 0.6882 - val_accuracy: 0.7638 - val_weighted_accuracy: 0.7554 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2331 - accuracy: 0.9032 - weighted_accuracy: 0.9043 - val_loss: 0.6925 - val_accuracy: 0.7639 - val_weighted_accuracy: 0.7549 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2329 - accuracy: 0.9035 - weighted_accuracy: 0.9045 - val_loss: 0.6884 - val_accuracy: 0.7629 - val_weighted_accuracy: 0.7548 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2326 - accuracy: 0.9037 - weighted_accuracy: 0.9047 - val_loss: 0.6961 - val_accuracy: 0.7633 - val_weighted_accuracy: 0.7548 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2324 - accuracy: 0.9037 - weighted_accuracy: 0.9048 - val_loss: 0.6889 - val_accuracy: 0.7627 - val_weighted_accuracy: 0.7548 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2322 - accuracy: 0.9036 - weighted_accuracy: 0.9046 - val_loss: 0.6992 - val_accuracy: 0.7632 - val_weighted_accuracy: 0.7545 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2314 - accuracy: 0.9043 - weighted_accuracy: 0.9052 - val_loss: 0.6945 - val_accuracy: 0.7625 - val_weighted_accuracy: 0.7543 - lr: 1.0000e-05\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2318 - accuracy: 0.9040 - weighted_accuracy: 0.9050 - val_loss: 0.6929 - val_accuracy: 0.7623 - val_weighted_accuracy: 0.7551 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2307 - accuracy: 0.9049 - weighted_accuracy: 0.9060 - val_loss: 0.7010 - val_accuracy: 0.7625 - val_weighted_accuracy: 0.7548 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2314 - accuracy: 0.9044 - weighted_accuracy: 0.9053 - val_loss: 0.6996 - val_accuracy: 0.7630 - val_weighted_accuracy: 0.7543 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2305 - accuracy: 0.9046 - weighted_accuracy: 0.9057 - val_loss: 0.7005 - val_accuracy: 0.7632 - val_weighted_accuracy: 0.7546 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2304 - accuracy: 0.9049 - weighted_accuracy: 0.9058 - val_loss: 0.6989 - val_accuracy: 0.7625 - val_weighted_accuracy: 0.7547 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2295 - accuracy: 0.9052 - weighted_accuracy: 0.9063 - val_loss: 0.7054 - val_accuracy: 0.7629 - val_weighted_accuracy: 0.7548 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2296 - accuracy: 0.9053 - weighted_accuracy: 0.9062 - val_loss: 0.7049 - val_accuracy: 0.7632 - val_weighted_accuracy: 0.7544 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2294 - accuracy: 0.9048 - weighted_accuracy: 0.9058 - val_loss: 0.7048 - val_accuracy: 0.7632 - val_weighted_accuracy: 0.7543 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2294 - accuracy: 0.9056 - weighted_accuracy: 0.9066 - val_loss: 0.7121 - val_accuracy: 0.7626 - val_weighted_accuracy: 0.7544 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2295 - accuracy: 0.9049 - weighted_accuracy: 0.9059 - val_loss: 0.7007 - val_accuracy: 0.7616 - val_weighted_accuracy: 0.7547 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2287 - accuracy: 0.9055 - weighted_accuracy: 0.9064 - val_loss: 0.7068 - val_accuracy: 0.7625 - val_weighted_accuracy: 0.7545 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "2579/2579 [==============================] - 55s 22ms/step - loss: 0.2284 - accuracy: 0.9054 - weighted_accuracy: 0.9064 - val_loss: 0.7064 - val_accuracy: 0.7621 - val_weighted_accuracy: 0.7536 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2282 - accuracy: 0.9061 - weighted_accuracy: 0.9071 - val_loss: 0.7069 - val_accuracy: 0.7630 - val_weighted_accuracy: 0.7542 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2275 - accuracy: 0.9063 - weighted_accuracy: 0.9073 - val_loss: 0.7133 - val_accuracy: 0.7623 - val_weighted_accuracy: 0.7545 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2276 - accuracy: 0.9059 - weighted_accuracy: 0.9068 - val_loss: 0.7097 - val_accuracy: 0.7627 - val_weighted_accuracy: 0.7541 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2272 - accuracy: 0.9062 - weighted_accuracy: 0.9071 - val_loss: 0.7089 - val_accuracy: 0.7615 - val_weighted_accuracy: 0.7540 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2266 - accuracy: 0.9064 - weighted_accuracy: 0.9072 - val_loss: 0.7155 - val_accuracy: 0.7613 - val_weighted_accuracy: 0.7538 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2265 - accuracy: 0.9068 - weighted_accuracy: 0.9077 - val_loss: 0.7154 - val_accuracy: 0.7627 - val_weighted_accuracy: 0.7536 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2260 - accuracy: 0.9066 - weighted_accuracy: 0.9078 - val_loss: 0.7200 - val_accuracy: 0.7624 - val_weighted_accuracy: 0.7540 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2260 - accuracy: 0.9066 - weighted_accuracy: 0.9076 - val_loss: 0.7139 - val_accuracy: 0.7615 - val_weighted_accuracy: 0.7537 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2253 - accuracy: 0.9072 - weighted_accuracy: 0.9082 - val_loss: 0.7200 - val_accuracy: 0.7619 - val_weighted_accuracy: 0.7537 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2254 - accuracy: 0.9069 - weighted_accuracy: 0.9079 - val_loss: 0.7192 - val_accuracy: 0.7619 - val_weighted_accuracy: 0.7540 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2247 - accuracy: 0.9071 - weighted_accuracy: 0.9083 - val_loss: 0.7205 - val_accuracy: 0.7615 - val_weighted_accuracy: 0.7534 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2245 - accuracy: 0.9074 - weighted_accuracy: 0.9084 - val_loss: 0.7222 - val_accuracy: 0.7620 - val_weighted_accuracy: 0.7540 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "2579/2579 [==============================] - 56s 22ms/step - loss: 0.2246 - accuracy: 0.9075 - weighted_accuracy: 0.9086 - val_loss: 0.7216 - val_accuracy: 0.7617 - val_weighted_accuracy: 0.7533 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2240 - accuracy: 0.9075 - weighted_accuracy: 0.9084 - val_loss: 0.7259 - val_accuracy: 0.7627 - val_weighted_accuracy: 0.7526 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2241 - accuracy: 0.9075 - weighted_accuracy: 0.9086 - val_loss: 0.7251 - val_accuracy: 0.7613 - val_weighted_accuracy: 0.7536 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "2579/2579 [==============================] - 55s 22ms/step - loss: 0.2236 - accuracy: 0.9082 - weighted_accuracy: 0.9092 - val_loss: 0.7191 - val_accuracy: 0.7614 - val_weighted_accuracy: 0.7531 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2234 - accuracy: 0.9079 - weighted_accuracy: 0.9090 - val_loss: 0.7246 - val_accuracy: 0.7622 - val_weighted_accuracy: 0.7524 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "2579/2579 [==============================] - 54s 21ms/step - loss: 0.2232 - accuracy: 0.9081 - weighted_accuracy: 0.9090 - val_loss: 0.7268 - val_accuracy: 0.7610 - val_weighted_accuracy: 0.7534 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "2579/2579 [==============================] - 54s 21ms/step - loss: 0.2231 - accuracy: 0.9084 - weighted_accuracy: 0.9093 - val_loss: 0.7246 - val_accuracy: 0.7613 - val_weighted_accuracy: 0.7529 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2222 - accuracy: 0.9089 - weighted_accuracy: 0.9098 - val_loss: 0.7279 - val_accuracy: 0.7620 - val_weighted_accuracy: 0.7530 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "2579/2579 [==============================] - 55s 21ms/step - loss: 0.2224 - accuracy: 0.9083 - weighted_accuracy: 0.9094 - val_loss: 0.7340 - val_accuracy: 0.7611 - val_weighted_accuracy: 0.7528 - lr: 1.0000e-05\n",
      "3224/3224 [==============================] - 3s 871us/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.73      0.68     36165\n",
      "           1       0.84      0.78      0.81     66983\n",
      "\n",
      "    accuracy                           0.76    103148\n",
      "   macro avg       0.74      0.75      0.75    103148\n",
      "weighted avg       0.77      0.76      0.77    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[26264  9901]\n",
      " [14632 52351]]\n",
      "Accuracy: 0.7621572885562493\n"
     ]
    }
   ],
   "source": [
    "#adjust the batch size\n",
    "model_simpleRNN_updated_2 = Sequential()\n",
    "model_simpleRNN_updated_2.add(Embedding(input_dim=len(tokenizer_RNN_updated.word_index) + 1, output_dim=128, input_length=30))\n",
    "model_simpleRNN_updated_2.add(BatchNormalization())\n",
    "model_simpleRNN_updated_2.add(SimpleRNN(units=50))\n",
    "model_simpleRNN_updated_2.add(BatchNormalization())\n",
    "model_simpleRNN_updated_2.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model_simpleRNN_updated_2.add(BatchNormalization())\n",
    "model_simpleRNN_updated_2.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model_simpleRNN_updated_2.add(BatchNormalization())\n",
    "model_simpleRNN_updated_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model_simpleRNN_updated_2.compile(\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'],    \n",
    "    weighted_metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_simpleRNN_updated_2.fit(X_train_RNN_updated, y_train_RNN_updated, epochs=100, batch_size=128, validation_split=0.2, sample_weight=sample_weights_updated, callbacks=[reduce_lr])\n",
    "\n",
    "# test predictions and get evaluation metrics\n",
    "pred_simpleRNN_updated_2 = model_simpleRNN_updated_2.predict(X_test_RNN_updated)\n",
    "\n",
    "#convert back\n",
    "pred_simpleRNN_updated_convert_2 = np.argmax(pred_simpleRNN_updated_2, axis=1)\n",
    "\n",
    "#evaluate results from the RNN\n",
    "updated_simpleRNN_class_report_2 = classification_report(y_test_RNN_updated, pred_simpleRNN_updated_convert_2)\n",
    "updated_simpleRNN_confusion_matrix_class_2 = confusion_matrix(y_test_RNN_updated, pred_simpleRNN_updated_convert_2)\n",
    "updated_simpleRNN_accuracy_class_2 = accuracy_score(y_test_RNN_updated, pred_simpleRNN_updated_convert_2)\n",
    "\n",
    "#print the results\n",
    "print(\"Classification Report:\\n\", updated_simpleRNN_class_report_2)\n",
    "print(\"Confusion Matrix:\\n\", updated_simpleRNN_confusion_matrix_class_2)\n",
    "print(\"Accuracy:\", updated_simpleRNN_accuracy_class_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "190aea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these results did not make much of an impact, will now try using smote to oversample the minority class\n",
    "smote_over = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_RNN_over, y_train_RNN_over = smote_over.fit_resample(X_train_RNN_updated, y_train_RNN_updated)\n",
    "\n",
    "#need to readjust the class weights for this new training data\n",
    "class_weights_over = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_RNN_over), y=y_train_RNN_over)\n",
    "class_weights_dict_over = {i: weight for i, weight in enumerate(class_weights_over)}\n",
    "sample_weights_over = np.array([class_weights_dict_over[y] for y in y_train_RNN_over])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a7c0b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6717/6717 [==============================] - 110s 16ms/step - loss: 0.6278 - accuracy: 0.7129 - weighted_accuracy: 0.7129 - val_loss: 0.7732 - val_accuracy: 0.6361 - val_weighted_accuracy: 0.6361 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "6717/6717 [==============================] - 110s 16ms/step - loss: 0.4768 - accuracy: 0.7744 - weighted_accuracy: 0.7744 - val_loss: 0.6700 - val_accuracy: 0.6563 - val_weighted_accuracy: 0.6563 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "6717/6717 [==============================] - 110s 16ms/step - loss: 0.4621 - accuracy: 0.7822 - weighted_accuracy: 0.7822 - val_loss: 0.9751 - val_accuracy: 0.3273 - val_weighted_accuracy: 0.3273 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "6717/6717 [==============================] - 110s 16ms/step - loss: 0.4607 - accuracy: 0.7848 - weighted_accuracy: 0.7848 - val_loss: 0.7974 - val_accuracy: 0.5571 - val_weighted_accuracy: 0.5571 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "6717/6717 [==============================] - 110s 16ms/step - loss: 0.4403 - accuracy: 0.7954 - weighted_accuracy: 0.7954 - val_loss: 0.5101 - val_accuracy: 0.7789 - val_weighted_accuracy: 0.7789 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "6717/6717 [==============================] - 111s 16ms/step - loss: 0.4280 - accuracy: 0.8029 - weighted_accuracy: 0.8029 - val_loss: 0.4531 - val_accuracy: 0.7843 - val_weighted_accuracy: 0.7843 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "6717/6717 [==============================] - 111s 16ms/step - loss: 0.4198 - accuracy: 0.8077 - weighted_accuracy: 0.8077 - val_loss: 0.5543 - val_accuracy: 0.7150 - val_weighted_accuracy: 0.7150 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "6717/6717 [==============================] - 110s 16ms/step - loss: 0.4136 - accuracy: 0.8104 - weighted_accuracy: 0.8104 - val_loss: 0.5092 - val_accuracy: 0.7342 - val_weighted_accuracy: 0.7342 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "6714/6717 [============================>.] - ETA: 0s - loss: 0.4127 - accuracy: 0.8118 - weighted_accuracy: 0.8118\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "6717/6717 [==============================] - 111s 16ms/step - loss: 0.4128 - accuracy: 0.8118 - weighted_accuracy: 0.8118 - val_loss: 0.8321 - val_accuracy: 0.5583 - val_weighted_accuracy: 0.5583 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.4036 - accuracy: 0.8163 - weighted_accuracy: 0.8163 - val_loss: 0.6435 - val_accuracy: 0.6859 - val_weighted_accuracy: 0.6859 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3861 - accuracy: 0.8260 - weighted_accuracy: 0.8260 - val_loss: 0.5126 - val_accuracy: 0.7495 - val_weighted_accuracy: 0.7495 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "6717/6717 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.8306 - weighted_accuracy: 0.8306\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3777 - accuracy: 0.8306 - weighted_accuracy: 0.8306 - val_loss: 0.5925 - val_accuracy: 0.7154 - val_weighted_accuracy: 0.7154 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3624 - accuracy: 0.8388 - weighted_accuracy: 0.8388 - val_loss: 0.6036 - val_accuracy: 0.7093 - val_weighted_accuracy: 0.7093 - lr: 2.5000e-04\n",
      "Epoch 14/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3547 - accuracy: 0.8432 - weighted_accuracy: 0.8432 - val_loss: 0.6374 - val_accuracy: 0.6840 - val_weighted_accuracy: 0.6840 - lr: 2.5000e-04\n",
      "Epoch 15/100\n",
      "6715/6717 [============================>.] - ETA: 0s - loss: 0.3483 - accuracy: 0.8469 - weighted_accuracy: 0.8469\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3483 - accuracy: 0.8469 - weighted_accuracy: 0.8469 - val_loss: 0.5384 - val_accuracy: 0.7347 - val_weighted_accuracy: 0.7347 - lr: 2.5000e-04\n",
      "Epoch 16/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3389 - accuracy: 0.8520 - weighted_accuracy: 0.8520 - val_loss: 0.5321 - val_accuracy: 0.7441 - val_weighted_accuracy: 0.7441 - lr: 1.2500e-04\n",
      "Epoch 17/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3345 - accuracy: 0.8539 - weighted_accuracy: 0.8539 - val_loss: 0.6042 - val_accuracy: 0.7014 - val_weighted_accuracy: 0.7014 - lr: 1.2500e-04\n",
      "Epoch 18/100\n",
      "6715/6717 [============================>.] - ETA: 0s - loss: 0.3310 - accuracy: 0.8562 - weighted_accuracy: 0.8562\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3310 - accuracy: 0.8562 - weighted_accuracy: 0.8562 - val_loss: 0.5699 - val_accuracy: 0.7252 - val_weighted_accuracy: 0.7252 - lr: 1.2500e-04\n",
      "Epoch 19/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3251 - accuracy: 0.8588 - weighted_accuracy: 0.8588 - val_loss: 0.5452 - val_accuracy: 0.7370 - val_weighted_accuracy: 0.7370 - lr: 6.2500e-05\n",
      "Epoch 20/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3227 - accuracy: 0.8604 - weighted_accuracy: 0.8604 - val_loss: 0.5528 - val_accuracy: 0.7394 - val_weighted_accuracy: 0.7394 - lr: 6.2500e-05\n",
      "Epoch 21/100\n",
      "6714/6717 [============================>.] - ETA: 0s - loss: 0.3210 - accuracy: 0.8615 - weighted_accuracy: 0.8615\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3210 - accuracy: 0.8615 - weighted_accuracy: 0.8615 - val_loss: 0.5686 - val_accuracy: 0.7251 - val_weighted_accuracy: 0.7251 - lr: 6.2500e-05\n",
      "Epoch 22/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3180 - accuracy: 0.8628 - weighted_accuracy: 0.8628 - val_loss: 0.5706 - val_accuracy: 0.7298 - val_weighted_accuracy: 0.7298 - lr: 3.1250e-05\n",
      "Epoch 23/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3166 - accuracy: 0.8634 - weighted_accuracy: 0.8634 - val_loss: 0.5835 - val_accuracy: 0.7213 - val_weighted_accuracy: 0.7213 - lr: 3.1250e-05\n",
      "Epoch 24/100\n",
      "6716/6717 [============================>.] - ETA: 0s - loss: 0.3157 - accuracy: 0.8642 - weighted_accuracy: 0.8642\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "6717/6717 [==============================] - 111s 16ms/step - loss: 0.3157 - accuracy: 0.8642 - weighted_accuracy: 0.8642 - val_loss: 0.5651 - val_accuracy: 0.7344 - val_weighted_accuracy: 0.7344 - lr: 3.1250e-05\n",
      "Epoch 25/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3142 - accuracy: 0.8645 - weighted_accuracy: 0.8645 - val_loss: 0.5736 - val_accuracy: 0.7269 - val_weighted_accuracy: 0.7269 - lr: 1.5625e-05\n",
      "Epoch 26/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3137 - accuracy: 0.8648 - weighted_accuracy: 0.8648 - val_loss: 0.5691 - val_accuracy: 0.7321 - val_weighted_accuracy: 0.7321 - lr: 1.5625e-05\n",
      "Epoch 27/100\n",
      "6716/6717 [============================>.] - ETA: 0s - loss: 0.3134 - accuracy: 0.8653 - weighted_accuracy: 0.8653\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3134 - accuracy: 0.8653 - weighted_accuracy: 0.8653 - val_loss: 0.5770 - val_accuracy: 0.7275 - val_weighted_accuracy: 0.7275 - lr: 1.5625e-05\n",
      "Epoch 28/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3126 - accuracy: 0.8657 - weighted_accuracy: 0.8657 - val_loss: 0.5722 - val_accuracy: 0.7288 - val_weighted_accuracy: 0.7288 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3118 - accuracy: 0.8663 - weighted_accuracy: 0.8663 - val_loss: 0.5704 - val_accuracy: 0.7296 - val_weighted_accuracy: 0.7296 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3117 - accuracy: 0.8662 - weighted_accuracy: 0.8662 - val_loss: 0.5622 - val_accuracy: 0.7345 - val_weighted_accuracy: 0.7345 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3120 - accuracy: 0.8661 - weighted_accuracy: 0.8661 - val_loss: 0.5784 - val_accuracy: 0.7265 - val_weighted_accuracy: 0.7265 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3110 - accuracy: 0.8660 - weighted_accuracy: 0.8660 - val_loss: 0.5578 - val_accuracy: 0.7353 - val_weighted_accuracy: 0.7353 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3108 - accuracy: 0.8667 - weighted_accuracy: 0.8667 - val_loss: 0.5771 - val_accuracy: 0.7272 - val_weighted_accuracy: 0.7272 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3107 - accuracy: 0.8669 - weighted_accuracy: 0.8669 - val_loss: 0.5808 - val_accuracy: 0.7250 - val_weighted_accuracy: 0.7250 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3100 - accuracy: 0.8668 - weighted_accuracy: 0.8668 - val_loss: 0.5790 - val_accuracy: 0.7260 - val_weighted_accuracy: 0.7260 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3101 - accuracy: 0.8672 - weighted_accuracy: 0.8672 - val_loss: 0.5593 - val_accuracy: 0.7368 - val_weighted_accuracy: 0.7368 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3096 - accuracy: 0.8669 - weighted_accuracy: 0.8669 - val_loss: 0.5662 - val_accuracy: 0.7337 - val_weighted_accuracy: 0.7337 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3096 - accuracy: 0.8673 - weighted_accuracy: 0.8673 - val_loss: 0.5736 - val_accuracy: 0.7301 - val_weighted_accuracy: 0.7301 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3095 - accuracy: 0.8674 - weighted_accuracy: 0.8674 - val_loss: 0.5761 - val_accuracy: 0.7276 - val_weighted_accuracy: 0.7276 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3086 - accuracy: 0.8677 - weighted_accuracy: 0.8677 - val_loss: 0.5652 - val_accuracy: 0.7337 - val_weighted_accuracy: 0.7337 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3092 - accuracy: 0.8674 - weighted_accuracy: 0.8674 - val_loss: 0.5807 - val_accuracy: 0.7295 - val_weighted_accuracy: 0.7295 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3088 - accuracy: 0.8677 - weighted_accuracy: 0.8677 - val_loss: 0.5722 - val_accuracy: 0.7305 - val_weighted_accuracy: 0.7305 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3083 - accuracy: 0.8679 - weighted_accuracy: 0.8679 - val_loss: 0.5664 - val_accuracy: 0.7318 - val_weighted_accuracy: 0.7318 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3082 - accuracy: 0.8679 - weighted_accuracy: 0.8679 - val_loss: 0.5693 - val_accuracy: 0.7321 - val_weighted_accuracy: 0.7321 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3078 - accuracy: 0.8676 - weighted_accuracy: 0.8676 - val_loss: 0.5782 - val_accuracy: 0.7293 - val_weighted_accuracy: 0.7293 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3075 - accuracy: 0.8681 - weighted_accuracy: 0.8681 - val_loss: 0.5826 - val_accuracy: 0.7268 - val_weighted_accuracy: 0.7268 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3069 - accuracy: 0.8682 - weighted_accuracy: 0.8682 - val_loss: 0.5783 - val_accuracy: 0.7292 - val_weighted_accuracy: 0.7292 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3073 - accuracy: 0.8682 - weighted_accuracy: 0.8682 - val_loss: 0.5768 - val_accuracy: 0.7292 - val_weighted_accuracy: 0.7292 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3063 - accuracy: 0.8686 - weighted_accuracy: 0.8686 - val_loss: 0.5694 - val_accuracy: 0.7325 - val_weighted_accuracy: 0.7325 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3066 - accuracy: 0.8685 - weighted_accuracy: 0.8685 - val_loss: 0.5772 - val_accuracy: 0.7311 - val_weighted_accuracy: 0.7311 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3063 - accuracy: 0.8687 - weighted_accuracy: 0.8687 - val_loss: 0.5748 - val_accuracy: 0.7302 - val_weighted_accuracy: 0.7302 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "6717/6717 [==============================] - 113s 17ms/step - loss: 0.3061 - accuracy: 0.8691 - weighted_accuracy: 0.8691 - val_loss: 0.5798 - val_accuracy: 0.7290 - val_weighted_accuracy: 0.7290 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "6717/6717 [==============================] - 113s 17ms/step - loss: 0.3056 - accuracy: 0.8692 - weighted_accuracy: 0.8692 - val_loss: 0.5860 - val_accuracy: 0.7268 - val_weighted_accuracy: 0.7268 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "6717/6717 [==============================] - 113s 17ms/step - loss: 0.3051 - accuracy: 0.8695 - weighted_accuracy: 0.8695 - val_loss: 0.5789 - val_accuracy: 0.7297 - val_weighted_accuracy: 0.7297 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "6717/6717 [==============================] - 113s 17ms/step - loss: 0.3052 - accuracy: 0.8693 - weighted_accuracy: 0.8693 - val_loss: 0.5732 - val_accuracy: 0.7324 - val_weighted_accuracy: 0.7324 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3044 - accuracy: 0.8696 - weighted_accuracy: 0.8696 - val_loss: 0.5840 - val_accuracy: 0.7269 - val_weighted_accuracy: 0.7269 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3047 - accuracy: 0.8696 - weighted_accuracy: 0.8696 - val_loss: 0.5808 - val_accuracy: 0.7271 - val_weighted_accuracy: 0.7271 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3046 - accuracy: 0.8696 - weighted_accuracy: 0.8696 - val_loss: 0.5900 - val_accuracy: 0.7267 - val_weighted_accuracy: 0.7267 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3038 - accuracy: 0.8699 - weighted_accuracy: 0.8699 - val_loss: 0.5863 - val_accuracy: 0.7266 - val_weighted_accuracy: 0.7266 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3041 - accuracy: 0.8698 - weighted_accuracy: 0.8698 - val_loss: 0.5810 - val_accuracy: 0.7284 - val_weighted_accuracy: 0.7284 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3042 - accuracy: 0.8697 - weighted_accuracy: 0.8697 - val_loss: 0.5844 - val_accuracy: 0.7294 - val_weighted_accuracy: 0.7294 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3034 - accuracy: 0.8703 - weighted_accuracy: 0.8703 - val_loss: 0.5785 - val_accuracy: 0.7296 - val_weighted_accuracy: 0.7296 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3033 - accuracy: 0.8702 - weighted_accuracy: 0.8702 - val_loss: 0.5837 - val_accuracy: 0.7277 - val_weighted_accuracy: 0.7277 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3034 - accuracy: 0.8703 - weighted_accuracy: 0.8703 - val_loss: 0.5855 - val_accuracy: 0.7277 - val_weighted_accuracy: 0.7277 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3026 - accuracy: 0.8704 - weighted_accuracy: 0.8704 - val_loss: 0.5827 - val_accuracy: 0.7278 - val_weighted_accuracy: 0.7278 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3026 - accuracy: 0.8706 - weighted_accuracy: 0.8706 - val_loss: 0.5962 - val_accuracy: 0.7232 - val_weighted_accuracy: 0.7232 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3023 - accuracy: 0.8711 - weighted_accuracy: 0.8711 - val_loss: 0.5840 - val_accuracy: 0.7276 - val_weighted_accuracy: 0.7276 - lr: 1.0000e-05\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6717/6717 [==============================] - 111s 16ms/step - loss: 0.3021 - accuracy: 0.8709 - weighted_accuracy: 0.8709 - val_loss: 0.5829 - val_accuracy: 0.7292 - val_weighted_accuracy: 0.7292 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3019 - accuracy: 0.8707 - weighted_accuracy: 0.8707 - val_loss: 0.5844 - val_accuracy: 0.7268 - val_weighted_accuracy: 0.7268 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3015 - accuracy: 0.8711 - weighted_accuracy: 0.8711 - val_loss: 0.5792 - val_accuracy: 0.7338 - val_weighted_accuracy: 0.7338 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3014 - accuracy: 0.8712 - weighted_accuracy: 0.8712 - val_loss: 0.5844 - val_accuracy: 0.7293 - val_weighted_accuracy: 0.7293 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3007 - accuracy: 0.8717 - weighted_accuracy: 0.8717 - val_loss: 0.5858 - val_accuracy: 0.7286 - val_weighted_accuracy: 0.7286 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3010 - accuracy: 0.8717 - weighted_accuracy: 0.8717 - val_loss: 0.5837 - val_accuracy: 0.7302 - val_weighted_accuracy: 0.7302 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3003 - accuracy: 0.8715 - weighted_accuracy: 0.8715 - val_loss: 0.5901 - val_accuracy: 0.7283 - val_weighted_accuracy: 0.7283 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.3002 - accuracy: 0.8721 - weighted_accuracy: 0.8721 - val_loss: 0.5778 - val_accuracy: 0.7305 - val_weighted_accuracy: 0.7305 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.3002 - accuracy: 0.8718 - weighted_accuracy: 0.8718 - val_loss: 0.5771 - val_accuracy: 0.7332 - val_weighted_accuracy: 0.7332 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.2999 - accuracy: 0.8720 - weighted_accuracy: 0.8720 - val_loss: 0.5927 - val_accuracy: 0.7262 - val_weighted_accuracy: 0.7262 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.2997 - accuracy: 0.8721 - weighted_accuracy: 0.8721 - val_loss: 0.5980 - val_accuracy: 0.7255 - val_weighted_accuracy: 0.7255 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.2991 - accuracy: 0.8723 - weighted_accuracy: 0.8723 - val_loss: 0.5915 - val_accuracy: 0.7278 - val_weighted_accuracy: 0.7278 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.2993 - accuracy: 0.8724 - weighted_accuracy: 0.8724 - val_loss: 0.5914 - val_accuracy: 0.7271 - val_weighted_accuracy: 0.7271 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.2990 - accuracy: 0.8726 - weighted_accuracy: 0.8726 - val_loss: 0.5972 - val_accuracy: 0.7239 - val_weighted_accuracy: 0.7239 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.2990 - accuracy: 0.8724 - weighted_accuracy: 0.8724 - val_loss: 0.5925 - val_accuracy: 0.7303 - val_weighted_accuracy: 0.7303 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.2988 - accuracy: 0.8728 - weighted_accuracy: 0.8728 - val_loss: 0.5817 - val_accuracy: 0.7310 - val_weighted_accuracy: 0.7310 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.2985 - accuracy: 0.8725 - weighted_accuracy: 0.8725 - val_loss: 0.5852 - val_accuracy: 0.7305 - val_weighted_accuracy: 0.7305 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.2985 - accuracy: 0.8728 - weighted_accuracy: 0.8728 - val_loss: 0.5775 - val_accuracy: 0.7345 - val_weighted_accuracy: 0.7345 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.2979 - accuracy: 0.8729 - weighted_accuracy: 0.8729 - val_loss: 0.5861 - val_accuracy: 0.7305 - val_weighted_accuracy: 0.7305 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.2975 - accuracy: 0.8731 - weighted_accuracy: 0.8731 - val_loss: 0.5824 - val_accuracy: 0.7317 - val_weighted_accuracy: 0.7317 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.2975 - accuracy: 0.8733 - weighted_accuracy: 0.8733 - val_loss: 0.5892 - val_accuracy: 0.7306 - val_weighted_accuracy: 0.7306 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.2978 - accuracy: 0.8731 - weighted_accuracy: 0.8731 - val_loss: 0.5918 - val_accuracy: 0.7264 - val_weighted_accuracy: 0.7264 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.2971 - accuracy: 0.8733 - weighted_accuracy: 0.8733 - val_loss: 0.5863 - val_accuracy: 0.7325 - val_weighted_accuracy: 0.7325 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.2971 - accuracy: 0.8734 - weighted_accuracy: 0.8734 - val_loss: 0.5886 - val_accuracy: 0.7301 - val_weighted_accuracy: 0.7301 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.2969 - accuracy: 0.8733 - weighted_accuracy: 0.8733 - val_loss: 0.5768 - val_accuracy: 0.7351 - val_weighted_accuracy: 0.7351 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.2966 - accuracy: 0.8737 - weighted_accuracy: 0.8737 - val_loss: 0.5932 - val_accuracy: 0.7275 - val_weighted_accuracy: 0.7275 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "6717/6717 [==============================] - 111s 17ms/step - loss: 0.2969 - accuracy: 0.8733 - weighted_accuracy: 0.8733 - val_loss: 0.5916 - val_accuracy: 0.7298 - val_weighted_accuracy: 0.7298 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.2960 - accuracy: 0.8738 - weighted_accuracy: 0.8738 - val_loss: 0.5706 - val_accuracy: 0.7363 - val_weighted_accuracy: 0.7363 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.2959 - accuracy: 0.8743 - weighted_accuracy: 0.8743 - val_loss: 0.5948 - val_accuracy: 0.7286 - val_weighted_accuracy: 0.7286 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.2960 - accuracy: 0.8740 - weighted_accuracy: 0.8740 - val_loss: 0.5847 - val_accuracy: 0.7329 - val_weighted_accuracy: 0.7329 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.2957 - accuracy: 0.8742 - weighted_accuracy: 0.8742 - val_loss: 0.6011 - val_accuracy: 0.7244 - val_weighted_accuracy: 0.7244 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.2953 - accuracy: 0.8739 - weighted_accuracy: 0.8739 - val_loss: 0.5790 - val_accuracy: 0.7343 - val_weighted_accuracy: 0.7343 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "6717/6717 [==============================] - 112s 17ms/step - loss: 0.2952 - accuracy: 0.8744 - weighted_accuracy: 0.8744 - val_loss: 0.5838 - val_accuracy: 0.7313 - val_weighted_accuracy: 0.7313 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x3301908d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model for the SimpleRNN with smote and complex layers\n",
    "model_simpleRNN_over = Sequential()\n",
    "model_simpleRNN_over.add(Embedding(input_dim=len(tokenizer_RNN_updated.word_index) + 1, output_dim=128, input_length=30))\n",
    "model_simpleRNN_over.add(BatchNormalization())\n",
    "model_simpleRNN_over.add(SimpleRNN(units=50))\n",
    "model_simpleRNN_over.add(BatchNormalization())\n",
    "model_simpleRNN_over.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model_simpleRNN_over.add(BatchNormalization())\n",
    "model_simpleRNN_over.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model_simpleRNN_over.add(BatchNormalization())\n",
    "model_simpleRNN_over.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model_simpleRNN_over.compile(\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'],    \n",
    "    weighted_metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#train\n",
    "model_simpleRNN_over.fit(X_train_RNN_over, y_train_RNN_over, epochs=100, batch_size=64, validation_split=0.2, sample_weight=sample_weights_over, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c41b7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3224/3224 [==============================] - 3s 883us/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.66      0.68     36165\n",
      "           1       0.82      0.84      0.83     66983\n",
      "\n",
      "    accuracy                           0.78    103148\n",
      "   macro avg       0.76      0.75      0.76    103148\n",
      "weighted avg       0.78      0.78      0.78    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[23908 12257]\n",
      " [10397 56586]]\n",
      "Accuracy: 0.780373831775701\n"
     ]
    }
   ],
   "source": [
    "# test predictions and get evaluation metrics\n",
    "pred_simpleRNN_over = model_simpleRNN_over.predict(X_test_RNN_updated)\n",
    "\n",
    "#convert back\n",
    "pred_simpleRNN_over_convert = np.argmax(pred_simpleRNN_over, axis=1)\n",
    "\n",
    "#evaluate results from the RNN\n",
    "over_simpleRNN_class_report = classification_report(y_test_RNN_updated, pred_simpleRNN_over_convert)\n",
    "over_simpleRNN_confusion_matrix_class = confusion_matrix(y_test_RNN_updated, pred_simpleRNN_over_convert)\n",
    "over_simpleRNN_accuracy_class = accuracy_score(y_test_RNN_updated, pred_simpleRNN_over_convert)\n",
    "\n",
    "#print the results\n",
    "print(\"Classification Report:\\n\", over_simpleRNN_class_report)\n",
    "print(\"Confusion Matrix:\\n\", over_simpleRNN_confusion_matrix_class)\n",
    "print(\"Accuracy:\", over_simpleRNN_accuracy_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4d2533",
   "metadata": {},
   "source": [
    "## Part 8: Scraping Reviews to Get New Data From a Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02a74f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: selenium in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (4.12.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "#ensure libraries are installed for scraping needs [20][21]\n",
    "!pip install beautifulsoup4\n",
    "!pip install --upgrade selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f27a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a0333ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, I need to specify the driver path for the web driver for Selenium to work\n",
    "#set up selenium webdriver [21]\n",
    "service = Service('/Users/coreyreid/Documents/Final Project/Final Project - Implementation & Evaluation/chromedriver')\n",
    "options = webdriver.ChromeOptions()\n",
    "#options.add_argument('--headless') #to make it headless and not run the chrome instance\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "#example website to use for the scraping\n",
    "url = \"https://www.mainecottagekeepers.com/2-beautiful-water-view-properties-in-1-for-extended-families-orp5b4a2abx\"\n",
    "driver.get(url)\n",
    "\n",
    "# delay as needed\n",
    "time.sleep(10)  \n",
    "\n",
    "# Switch to the iframe containing the reviews - need to switch the focus into the iframe\n",
    "iframe = driver.find_element(By.CSS_SELECTOR, 'div.ownerrez-widget[data-widgetid=\"dc0c1ee92566447e81ba5e68a8a2ac1a\"] iframe')\n",
    "driver.switch_to.frame(iframe)\n",
    "\n",
    "# delay as needed\n",
    "time.sleep(10)  \n",
    "\n",
    "# Extract the HTML content\n",
    "html = driver.page_source\n",
    "\n",
    "# now, I will scrape the website to expose the review content\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "review_elements = soup.find_all('div', class_='review-item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb697403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The title of the review is: \n",
      "The review content is: A big thank you from us to be able to stay in this wonderful place in order to be with our family during the Lobstah fest.  We drove from Florida to see our Massachusetts family as we gathered in Maine to welcome our Grandson from the ship that anchored in Rockland for the Festival.  We loved being able to see him as he did us.  We felt at home in this Airbnb as we gathered at the fire pit and the deck table for meals. We did several meals at the Dip Net too.  Great food and very close to house.This house is very well equipped, clean, and is an old farmhouse with a lot of Character.We did host an Airbnb on the Cape at one time and know that Shawn-Elise deserves a 5 star rating to become a super host if she is not already.Would we come again?  You Bet.Sharyn\n",
      "---------------------------------\n",
      "The title of the review is: \n",
      "The review content is: Great stay. Just didn’t understand why they took 500 for a security deposit\n",
      "---------------------------------\n",
      "The title of the review is: \n",
      "The review content is: The place is absolutely beautiful and there was plenty of room for all 10 f us to sleep. The houses are just a short drive from a bunch of cool spots. Highly recommend!\n",
      "---------------------------------\n",
      "The title of the review is: A peace of heaven with 10 family members\n",
      "The review content is: We enjoyed the peace and quit of this lovely 2 home farm house.My family of 10  celebrated a wonderful 1 night get together.  For myBrother-in-law 60th birthday dinner and we flew in from all over .We all enjoyed the large outdoor eating area .And then in the evening we made s’mores at the fire pit and just watched the beautiful  Stars. we all had a private area to go to get away if we needed .the beds were  very comfortable So if you want to enjoy everyone under one roof…Book this ASAP because it  will be a wonderful place to make family or friends memories Sincerely Audrey & Douglas and family\n",
      "---------------------------------\n",
      "The title of the review is: \n",
      "The review content is: It was a very charming Home\n",
      "---------------------------------\n",
      "The title of the review is: Large, well located summer rental\n",
      "The review content is: Our 3 families enjoyed our 5 nights on this well located property. The kids had their own ‘lofted apartment’ and enjoyed their independence. The house is located near Drift In Beach and Clark Island and Port Clyde Harbor.The beds were all wonderfully comfortable and everyone slept well. This property is right on RT. 131, which is the main thoroughfare for traffic going to Port Vlyde Harbor. It can be a bit noisy at night, but each time was provided with a fan which blocked the noise well. I would definitely recommend this rental for large groups and the hosts were always available for questions.\n",
      "---------------------------------\n",
      "The title of the review is: Large, well located summer rental\n",
      "The review content is: Our 3 families enjoyed our 5 nights on this well located property. The kids had their own ‘lofted apartment’ and enjoyed their independence. The house is located near Drift In Beach and Clark Island and Port Clyde Harbor.The beds were all wonderfully comfortable and everyone slept well. This property is right on RT. 131, which is the main thoroughfare for traffic going to Port Vlyde Harbor. It can be a bit noisy at night, but each time was provided with a fan which blocked the noise well. I would definitely recommend this rental for large groups and the hosts were always available for questions.\n",
      "---------------------------------\n",
      "The title of the review is: \n",
      "The review content is: We had a wonderful time, the house was very clean and the grass was freshly mowed. We really enjoyed our stay and all their recommendations for local activities!\n",
      "---------------------------------\n",
      "The title of the review is: \n",
      "The review content is: The house and loft were clean and staying there was comfortable.\n",
      "---------------------------------\n",
      "The title of the review is: \n",
      "The review content is: Excellent hosts\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "#now that we have isolated the html element that matters, we will want to go through all the reviews\n",
    "#and collect just the relevant text\n",
    "#initialize\n",
    "real_reviews = []\n",
    "\n",
    "#loop through the review elements\n",
    "for review in review_elements:\n",
    "    # Scrape the review title text\n",
    "    review_title = review.find(\"span\", class_=\"review-item-title\").strong\n",
    "    # Scrape the review body text\n",
    "    review_body = review.find(\"div\", class_=\"has-read-more\").text.strip()\n",
    "    #check that a review exists\n",
    "    if review_title and review_body:\n",
    "        #get review title text \n",
    "        review_title_text = review_title.text.strip()\n",
    "        #get review body text\n",
    "        review_body_text = review_body\n",
    "        # put the data in a dataframe\n",
    "                # Append the scraped data as a dictionary to the 'data' list\n",
    "        real_reviews.append(\n",
    "            review_body_text\n",
    "        )\n",
    "        #print the details through the loop\n",
    "        print(\"The title of the review is:\", review_title_text)\n",
    "        print(\"The review content is:\", review_body_text)\n",
    "        print(\"---------------------------------\")\n",
    "    else:\n",
    "        #error handling\n",
    "        print(\"There is no review title or text.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73f5edf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A big thank you from us to be able to stay in this wonderful place in order to be with our family during the Lobstah fest.\\xa0 We drove from Florida to see our Massachusetts family as we gathered in Maine to welcome our Grandson from the ship that anchored in Rockland for the Festival.\\xa0 We loved being able to see him as he did us.\\xa0 We felt at home in this Airbnb as we gathered at the fire pit and the deck table for meals. We did several meals at the Dip Net too.\\xa0 Great food and very close to house.This house is very well equipped, clean, and is an old farmhouse with a lot of Character.We did host an Airbnb on the Cape at one time and know that Shawn-Elise deserves a 5 star rating to become a super host if she is not already.Would we come again?\\xa0 You Bet.Sharyn',\n",
       " 'Great stay. Just didn’t understand why they took 500 for a security deposit',\n",
       " 'The place is absolutely beautiful and there was plenty of room for all 10 f us to sleep. The houses are just a short drive from a bunch of cool spots. Highly recommend!',\n",
       " 'We enjoyed the peace and quit of this lovely 2 home farm house.My family of 10\\xa0 celebrated a wonderful 1 night get together.\\xa0 For myBrother-in-law 60th birthday dinner and we flew in from all over .We all enjoyed the large outdoor eating area .And then in the evening we made s’mores at the fire pit and just watched the beautiful\\xa0 Stars. we all had a private area to go to get away if we needed .the beds were\\xa0 very comfortable So if you want to enjoy everyone under one roof…Book this ASAP because it\\xa0 will be a wonderful place to make family or friends memories Sincerely Audrey & Douglas and family',\n",
       " 'It was a very charming Home',\n",
       " 'Our 3 families enjoyed our 5 nights on this well located property. The kids had their own ‘lofted apartment’ and enjoyed their independence. The house is located near Drift In Beach and Clark Island and Port Clyde Harbor.The beds were all wonderfully comfortable and everyone slept well. This property is right on RT. 131, which is the main thoroughfare for traffic going to Port Vlyde Harbor. It can be a bit noisy at night, but each time was provided with a fan which blocked the noise well. I would definitely recommend this rental for large groups and the hosts were always available for questions.',\n",
       " 'Our 3 families enjoyed our 5 nights on this well located property. The kids had their own ‘lofted apartment’ and enjoyed their independence. The house is located near Drift In Beach and Clark Island and Port Clyde Harbor.The beds were all wonderfully comfortable and everyone slept well. This property is right on RT. 131, which is the main thoroughfare for traffic going to Port Vlyde Harbor. It can be a bit noisy at night, but each time was provided with a fan which blocked the noise well. I would definitely recommend this rental for large groups and the hosts were always available for questions.',\n",
       " 'We had a wonderful time, the house was very clean and the grass was freshly mowed. We really enjoyed our stay and all their recommendations for local activities!',\n",
       " 'The house and loft were clean and staying there was comfortable.',\n",
       " 'Excellent hosts']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the way the data is structured by looking at the output\n",
    "real_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5888e427",
   "metadata": {},
   "source": [
    "## Part 9: Testing on Real Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb65b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to scale the preprocessing to be able to be used with new reviews, I need to generalize the \n",
    "# preprocessing function - I will do that now for the one with no POS tagging\n",
    "\n",
    "def preprocess_no_pos(review):\n",
    "    \n",
    "    #remove special characters and ensure lowercase\n",
    "    def preprocess_remove_special(review):\n",
    "        review_handled = re.sub(r'[^a-zA-Z\\s]', '', review)\n",
    "        review_lower = review_handled.lower()\n",
    "        return review_lower\n",
    "\n",
    "    #tokenize\n",
    "    def preprocess_tokenize(review):\n",
    "        bag_of_words = word_tokenize(review)\n",
    "        return bag_of_words\n",
    "\n",
    "    #remove stopwords\n",
    "    def preprocess_stopwords(review):\n",
    "        words = stopwords.words('english')\n",
    "        set_stop_words = set(words)\n",
    "        removed_stopwords_words = []\n",
    "        for word in review:\n",
    "            if word not in set_stop_words:\n",
    "                removed_stopwords_words.append(word)\n",
    "        return removed_stopwords_words\n",
    "\n",
    "    #lemmatize\n",
    "    def preprocess_lemmatize(review):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized_review = [lemmatizer.lemmatize(word) for word in review ]\n",
    "        return lemmatized_review\n",
    "\n",
    "    # Apply the preprocessing steps\n",
    "    review = preprocess_remove_special(review)\n",
    "    review = preprocess_tokenize(review)\n",
    "    review = preprocess_stopwords(review)\n",
    "    review = preprocess_lemmatize(review)\n",
    "\n",
    "    # Join the tokens back into a single string\n",
    "    preprocessed_review = ' '.join(review)\n",
    "\n",
    "    #return the preprocessed reviews\n",
    "    return preprocessed_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d225040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A big thank you from us to be able to stay in this wonderful place in order to be with our family during the Lobstah fest.\\xa0 We drove from Florida to see our Massachusetts family as we gathered in Maine to welcome our Grandson from the ship that anchored in Rockland for the Festival.\\xa0 We loved being able to see him as he did us.\\xa0 We felt at home in this Airbnb as we gathered at the fire pit and the deck table for meals. We did several meals at the Dip Net too.\\xa0 Great food and very close to house.This house is very well equipped, clean, and is an old farmhouse with a lot of Character.We did host an Airbnb on the Cape at one time and know that Shawn-Elise deserves a 5 star rating to become a super host if she is not already.Would we come again?\\xa0 You Bet.Sharyn',\n",
       " 'Great stay. Just didn’t understand why they took 500 for a security deposit',\n",
       " 'The place is absolutely beautiful and there was plenty of room for all 10 f us to sleep. The houses are just a short drive from a bunch of cool spots. Highly recommend!',\n",
       " 'We enjoyed the peace and quit of this lovely 2 home farm house.My family of 10\\xa0 celebrated a wonderful 1 night get together.\\xa0 For myBrother-in-law 60th birthday dinner and we flew in from all over .We all enjoyed the large outdoor eating area .And then in the evening we made s’mores at the fire pit and just watched the beautiful\\xa0 Stars. we all had a private area to go to get away if we needed .the beds were\\xa0 very comfortable So if you want to enjoy everyone under one roof…Book this ASAP because it\\xa0 will be a wonderful place to make family or friends memories Sincerely Audrey & Douglas and family',\n",
       " 'It was a very charming Home',\n",
       " 'Our 3 families enjoyed our 5 nights on this well located property. The kids had their own ‘lofted apartment’ and enjoyed their independence. The house is located near Drift In Beach and Clark Island and Port Clyde Harbor.The beds were all wonderfully comfortable and everyone slept well. This property is right on RT. 131, which is the main thoroughfare for traffic going to Port Vlyde Harbor. It can be a bit noisy at night, but each time was provided with a fan which blocked the noise well. I would definitely recommend this rental for large groups and the hosts were always available for questions.',\n",
       " 'Our 3 families enjoyed our 5 nights on this well located property. The kids had their own ‘lofted apartment’ and enjoyed their independence. The house is located near Drift In Beach and Clark Island and Port Clyde Harbor.The beds were all wonderfully comfortable and everyone slept well. This property is right on RT. 131, which is the main thoroughfare for traffic going to Port Vlyde Harbor. It can be a bit noisy at night, but each time was provided with a fan which blocked the noise well. I would definitely recommend this rental for large groups and the hosts were always available for questions.',\n",
       " 'We had a wonderful time, the house was very clean and the grass was freshly mowed. We really enjoyed our stay and all their recommendations for local activities!',\n",
       " 'The house and loft were clean and staying there was comfortable.',\n",
       " 'Excellent hosts',\n",
       " 'Awful',\n",
       " 'It was a bad rental unit and was very ugly. The ammenities were all broken.',\n",
       " 'I will never return to this or recommend it to anyone - it was a horrible rental and it ruined my holiday.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turns out they are all positive, which when you look above you can see is the case - this will happen \n",
    "# from time to time. I will manually add data to the reviews data to put in a few negative reviews for further \n",
    "# testing - this will confirm the model is working properly\n",
    "\n",
    "updated_real_reviews = real_reviews.copy()\n",
    "\n",
    "updated_real_reviews.extend(['Awful', 'It was a bad rental unit and was very ugly. The ammenities were all broken.', 'I will never return to this or recommend it to anyone - it was a horrible rental and it ruined my holiday.'])\n",
    "\n",
    "updated_real_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e65dc714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, I will test this set with Multinomial Naive Bayes with no POS tags\n",
    "# to start I will preprocess the data using this function and looping through all the reviews\n",
    "updated_real_reviews_processed = [preprocess_no_pos(review) for review in updated_real_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5eab739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#last I will test the best 3-class RNN model with the real review data\n",
    "# to do this, we will need to process the data a bit more to get it into it's final model training state.\n",
    "# we will use the no POS tagging version as it always seemed to perform a bit better, even if the difference was\n",
    "# very small between no POS tags and POS tagged data\n",
    "\n",
    "# prepare the review text data for RNN usage\n",
    "tokenizer_RNN_noPOS_test_3 = Tokenizer()\n",
    "tokenizer_RNN_noPOS_test_3.fit_on_texts(updated_real_reviews_processed)\n",
    "review_prepped_RNN_noPOS_test = tokenizer_RNN_noPOS_test_3.texts_to_sequences(updated_real_reviews_processed)\n",
    "\n",
    "# pad the text with a set length - used 10 previously so will use it again\n",
    "review_prepped_RNN_noPOS_padded = pad_sequences(review_prepped_RNN_noPOS_test, maxlen=30)\n",
    "\n",
    "real_pred_RNN_noPOS_test = model_simpleRNN_normalized_only.predict(review_prepped_RNN_noPOS_padded)\n",
    "\n",
    "# convert back to positive, negative, or neutral\n",
    "real_pred_RNN_noPOS_converted_back_test = label_encoder_RNN_noPOS.inverse_transform_sentiment_noPOS(real_pred_RNN_noPOS_test.argmax(axis=1))\n",
    "\n",
    "# get the predictions\n",
    "real_pred_RNN_noPOS_converted_back_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96d6404",
   "metadata": {},
   "source": [
    "As can be seen, the 3-class predictor is overfit to positive and chooses positive each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63ede80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# additionally, I will test the sentiment analysis on the redefined threshold 2-class  models \n",
    "# which performed a bit better than the previous 3-class's best results\n",
    "\n",
    "\n",
    "# prepare the review text data for RNN usage\n",
    "tokenizer_RNN_noPOS_test_2 = Tokenizer()\n",
    "tokenizer_RNN_noPOS_test_2.fit_on_texts(updated_real_reviews_processed)\n",
    "review_prepped_RNN_noPOS_test_2 = tokenizer_RNN_noPOS_test_2.texts_to_sequences(updated_real_reviews_processed)\n",
    "\n",
    "# pad the text with a set length - used 10 previously so will use it again\n",
    "review_prepped_RNN_noPOS_padded_2 = pad_sequences(review_prepped_RNN_noPOS_test_2, maxlen=30)\n",
    "\n",
    "real_pred_RNN_noPOS_test_2 = model_simpleRNN_over.predict(review_prepped_RNN_noPOS_padded_2)\n",
    "\n",
    "encoded_labels = real_pred_RNN_noPOS_test_2.argmax(axis=1)\n",
    "\n",
    "# convert back to positive, negative, or neutral\n",
    "real_pred_RNN_noPOS_converted_back_test_2 = LabelEncoderSentiment_updated.inverse_transform_sentiment_updated(encoded_labels)\n",
    "\n",
    "# get the predictions\n",
    "real_pred_RNN_noPOS_converted_back_test_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f94968",
   "metadata": {},
   "source": [
    "## Part 10: Product Development\n",
    "\n",
    "I will start by building a product for the 3-class model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6ac93f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary GUI libraries\n",
    "#I will use message box from Tkinter to build the GUI and the Tkinter library in general [22]\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import joblib\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "81c5a0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "#first I need to define a function that will run on the button click. \n",
    "# this will include the preprocessing, vectorization, and model execution for the sentiment analysis\n",
    "\n",
    "# function to determine the preprocessed state for the reviews\n",
    "def determine_preprocess(review):\n",
    "    # Create a list of reviews, for any \";\" will seperate the list so input needs to seperate reviews by \";\"\n",
    "    reviews_list = review.split(\";\")\n",
    "    #initialize the results list to be used to append the results\n",
    "    reviews_list_processed = []\n",
    "    \n",
    "    #loop through the reviews and analyze individually\n",
    "    for review in reviews_list:\n",
    "        # Preprocess each review individually\n",
    "        processed_review = preprocess_no_pos(review) \n",
    "        tokenizer_RNN_noPOS_prod = Tokenizer()\n",
    "        tokenizer_RNN_noPOS_prod.fit_on_texts(processed_review)\n",
    "        review_prepped_RNN_noPOS_prod = tokenizer_RNN_noPOS_prod.texts_to_sequences(processed_review)\n",
    "        # pad the text with a set length - used 10 previously so will use it again\n",
    "        review_prepped_RNN_noPOS_padded_prod = pad_sequences(review_prepped_RNN_noPOS_prod, maxlen=30)\n",
    "        # predict the sentiment of the reviews\n",
    "        reviews_list_predictions = model_simpleRNN_normalized_only.predict(review_prepped_RNN_noPOS_padded_prod)\n",
    "        # convert back to positive, negative, or neutral\n",
    "        sentiment_labels = label_encoder_RNN_noPOS.inverse_transform_sentiment_noPOS(real_pred_RNN_noPOS_test.argmax(axis=1))\n",
    "        #append the results\n",
    "        reviews_list_processed.append((review, sentiment_labels[0])) \n",
    "    #return the results\n",
    "    return reviews_list_processed\n",
    "\n",
    "# create a function for the sentiment analysis\n",
    "def get_sentiment():\n",
    "    #get the entry from the form \n",
    "    user_reviews_list = entry.get()\n",
    "    # if there are reviews, then analyze them \n",
    "    if user_reviews_list:\n",
    "        #determine sentiment\n",
    "        sentiment_out = determine_preprocess(user_reviews_list)\n",
    "        #clear the previous review info to ensure each review is looked at individually\n",
    "        review_text.delete(1.0, tk.END)\n",
    "        \n",
    "        # analyse the review\n",
    "        for review, sentiment in sentiment_out:\n",
    "            # in the text output that is part of the GUI, we will now get the values needed in our presentation of results\n",
    "            # get the review\n",
    "            review_text.insert(tk.END, \"Review:\\n{}\\n\".format(review))\n",
    "            # get the sentiment\n",
    "            review_text.insert(tk.END, \"Sentiment: {}\\n\".format(sentiment))\n",
    "            \n",
    "            #logic for giving recommendations on the handling procedures for the review\n",
    "            #positive\n",
    "            if sentiment == 'positive':\n",
    "                message = \"Message: This is a positive review. You should consider reaching out to learn more about what was so great about the stay and thank them for leaving a good review.\"\n",
    "            #negative\n",
    "            elif sentiment == 'negative':\n",
    "                message = \"Message: This is a negative review. You should consider reaching out to learn more about their bad experience and offer them a 10% discount for their next stay. Also thank them for the feedback.\"\n",
    "            #nuetral or other\n",
    "            else:\n",
    "                message = \"Message: Sentiment is uncertain. You may want to connect with them for more information.\"\n",
    "            \n",
    "            #add the message to the text output for presentation\n",
    "            review_text.insert(tk.END, message + \"\\n\\n\")\n",
    "    #if no reviews input and button clicked\n",
    "    else:\n",
    "        #give an error to the user\n",
    "        messagebox.showerror(\"Error\", \"Please enter a review.\")\n",
    "\n",
    "\n",
    "# initialize the tkinter model\n",
    "root = tk.Tk()\n",
    "#provide a title for the GUI\n",
    "root.title(\"Short-Term Rental Review Sentiment Analysis\")\n",
    "\n",
    "# give the label for the GUI input\n",
    "label = tk.Label(root, text=\"Enter your Short-Term Rental review (seperate multiple reviews with a ';')\")\n",
    "#update the label\n",
    "label.pack()\n",
    "\n",
    "#define the form entry size\n",
    "entry = tk.Entry(root, width=50)\n",
    "#update the entry\n",
    "entry.pack()\n",
    "\n",
    "#define the button and actions from the button click - in this case we will run the get_sentiment function\n",
    "analyze_button = tk.Button(root, text=\"Determine Sentiment\", command=get_sentiment)\n",
    "#update the button\n",
    "analyze_button.pack()\n",
    "\n",
    "# Size the text widget which will be used to display the review analysis output - including the resolution message \n",
    "review_text = tk.Text(root, height=10, width=50)\n",
    "# update the text details\n",
    "review_text.pack()\n",
    "\n",
    "#loop the root GUI to keep the window running\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b06301f",
   "metadata": {},
   "source": [
    "As can be seen when you run the code, a GUI is created that allows the user to input reviews - multiple are seperated with a \";\" - and get outcomes from the sentiment analysis with recommendations on what to do. This proves that a sentiment analysis tool like this could be created, and the minimal viable product is completed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae89e2b",
   "metadata": {},
   "source": [
    "Next, I will build a 2-class model GUI for demonstrative purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f237ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#first I need to define a function that will run on the button click. \n",
    "# this will include the preprocessing, vectorization, and model execution for the sentiment analysis\n",
    "\n",
    "# function to determine the preprocessed state for the reviews\n",
    "def determine_preprocess_2(review):\n",
    "    # Create a list of reviews, for any \";\" will seperate the list so input needs to seperate reviews by \";\"\n",
    "    reviews_list_2 = review.split(\";\")\n",
    "    #initialize the results list to be used to append the results\n",
    "    reviews_list_processed_2 = []\n",
    "    \n",
    "    #loop through the reviews and analyze individually\n",
    "    for review in reviews_list_2:\n",
    "        # Preprocess each review individually\n",
    "        processed_review_2 = preprocess_no_pos(review) \n",
    "        tokenizer_RNN_noPOS_prod_2 = Tokenizer()\n",
    "        tokenizer_RNN_noPOS_prod_2.fit_on_texts(processed_review_2)\n",
    "        review_prepped_RNN_noPOS_prod_2 = tokenizer_RNN_noPOS_test_2.texts_to_sequences(processed_review_2)\n",
    "        # pad the text with a set length - used 10 previously so will use it again\n",
    "        review_prepped_RNN_noPOS_padded_prod_2 = pad_sequences(review_prepped_RNN_noPOS_prod_2, maxlen=30)\n",
    "        # predict the sentiment of the reviews\n",
    "        reviews_list_predictions_2 = model_simpleRNN_over.predict(review_prepped_RNN_noPOS_padded_prod_2)\n",
    "        # convert back to positive, negative, or neutral\n",
    "        sentiment_labels_2 = label_encoder_RNN_noPOS.inverse_transform_sentiment_noPOS(real_pred_RNN_noPOS_test_2.argmax(axis=1))\n",
    "        #append the results\n",
    "        reviews_list_processed_2.append((review, sentiment_labels_2[0])) \n",
    "    #return the results\n",
    "    return reviews_list_processed_2\n",
    "\n",
    "# create a function for the sentiment analysis\n",
    "def get_sentiment_2():\n",
    "    #get the entry from the form \n",
    "    user_reviews_list_2 = entry_2.get()\n",
    "    # if there are reviews, then analyze them \n",
    "    if user_reviews_list_2:\n",
    "        #determine sentiment\n",
    "        sentiment_out_2 = determine_preprocess_2(user_reviews_list_2)\n",
    "        #clear the previous review info to ensure each review is looked at individually\n",
    "        review_text.delete(1.0, tk.END)\n",
    "        \n",
    "        # analyse the review\n",
    "        for review, sentiment in sentiment_out_2:\n",
    "            # in the text output that is part of the GUI, we will now get the values needed in our presentation of results\n",
    "            # get the review\n",
    "            review_text.insert(tk.END, \"Review:\\n{}\\n\".format(review))\n",
    "            # get the sentiment\n",
    "            review_text.insert(tk.END, \"Sentiment: {}\\n\".format(sentiment))\n",
    "            \n",
    "            #logic for giving recommendations on the handling procedures for the review\n",
    "            #positive\n",
    "            if sentiment == 'positive':\n",
    "                message = \"Message: This is a positive review. You should consider reaching out to learn more about what was so great about the stay and thank them for leaving a good review.\"\n",
    "            #negative\n",
    "            elif sentiment == 'negative':\n",
    "                message = \"Message: This is a negative review. You should consider reaching out to learn more about their bad experience and offer them a 10% discount for their next stay. Also thank them for the feedback.\"\n",
    "\n",
    "            #add the message to the text output for presentation\n",
    "            review_text.insert(tk.END, message + \"\\n\\n\")\n",
    "    #if no reviews input and button clicked\n",
    "    else:\n",
    "        #give an error to the user\n",
    "        messagebox.showerror(\"Error\", \"Please enter a review.\")\n",
    "\n",
    "\n",
    "# initialize the tkinter model\n",
    "root_2 = tk.Tk()\n",
    "#provide a title for the GUI\n",
    "root_2.title(\"Short-Term Rental Review Sentiment Analysis\")\n",
    "\n",
    "# give the label for the GUI input\n",
    "label_2 = tk.Label(root_2, text=\"Enter your Short-Term Rental review (seperate multiple reviews with a ';')\")\n",
    "#update the label\n",
    "label_2.pack()\n",
    "\n",
    "#define the form entry size\n",
    "entry_2 = tk.Entry(root_2, width=50)\n",
    "#update the entry\n",
    "entry_2.pack()\n",
    "\n",
    "#define the button and actions from the button click - in this case we will run the get_sentiment function\n",
    "analyze_button_2 = tk.Button(root_2, text=\"Determine Sentiment\", command=get_sentiment_2)\n",
    "#update the button\n",
    "analyze_button_2.pack()\n",
    "\n",
    "# Size the text widget which will be used to display the review analysis output - including the resolution message \n",
    "review_text = tk.Text(root_2, height=10, width=50)\n",
    "# update the text details\n",
    "review_text.pack()\n",
    "\n",
    "#loop the root GUI to keep the window running\n",
    "root_2.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce0b333",
   "metadata": {},
   "source": [
    "While the 2-class predictor performed better, it was still not as accurate as the Random Forest model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
