{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc360176",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Short-Term Rental Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78357219",
   "metadata": {},
   "source": [
    "## Part 1: Loading Data into Python Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d791542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In starting out with the product developement, the first step will be getting the data into a dataframe.\n",
    "# This will allow me to pre-process the data with Pandas built in functions [1].\n",
    "# In order to do this, pandas must be added to the notebook. \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9fca626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, I will read in the CSV into a pandas dataframe\n",
    "file = \"Hotel_Reviews.csv\"\n",
    "original_data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b58d641a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>8/3/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Russia</td>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>397</td>\n",
       "      <td>1403</td>\n",
       "      <td>Only the park outside of the hotel was beauti...</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>0 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>8/3/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1403</td>\n",
       "      <td>No real complaints the hotel was great great ...</td>\n",
       "      <td>105</td>\n",
       "      <td>7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>0 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/31/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>42</td>\n",
       "      <td>1403</td>\n",
       "      <td>Location was good and staff were ok It is cut...</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>[' Leisure trip ', ' Family with young childre...</td>\n",
       "      <td>3 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Hotel_Address  \\\n",
       "0   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "1   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "2   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "\n",
       "   Additional_Number_of_Scoring Review_Date  Average_Score   Hotel_Name  \\\n",
       "0                           194    8/3/2017            7.7  Hotel Arena   \n",
       "1                           194    8/3/2017            7.7  Hotel Arena   \n",
       "2                           194   7/31/2017            7.7  Hotel Arena   \n",
       "\n",
       "  Reviewer_Nationality                                    Negative_Review  \\\n",
       "0              Russia    I am so angry that i made this post available...   \n",
       "1             Ireland                                         No Negative   \n",
       "2           Australia    Rooms are nice but for elderly a bit difficul...   \n",
       "\n",
       "   Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  \\\n",
       "0                                397                     1403   \n",
       "1                                  0                     1403   \n",
       "2                                 42                     1403   \n",
       "\n",
       "                                     Positive_Review  \\\n",
       "0   Only the park outside of the hotel was beauti...   \n",
       "1   No real complaints the hotel was great great ...   \n",
       "2   Location was good and staff were ok It is cut...   \n",
       "\n",
       "   Review_Total_Positive_Word_Counts  \\\n",
       "0                                 11   \n",
       "1                                105   \n",
       "2                                 21   \n",
       "\n",
       "   Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  \\\n",
       "0                                           7             2.9   \n",
       "1                                           7             7.5   \n",
       "2                                           9             7.1   \n",
       "\n",
       "                                                Tags days_since_review  \\\n",
       "0  [' Leisure trip ', ' Couple ', ' Duplex Double...            0 days   \n",
       "1  [' Leisure trip ', ' Couple ', ' Duplex Double...            0 days   \n",
       "2  [' Leisure trip ', ' Family with young childre...            3 days   \n",
       "\n",
       "         lat       lng  \n",
       "0  52.360576  4.915968  \n",
       "1  52.360576  4.915968  \n",
       "2  52.360576  4.915968  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show some of the data to start to understand it better. \n",
    "original_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ba3d33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Negative  No real complaints the hotel was ...</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Total_Review  Reviewer_Score\n",
       "0   I am so angry that i made this post available...             2.9\n",
       "1  No Negative  No real complaints the hotel was ...             7.5\n",
       "2   Rooms are nice but for elderly a bit difficul...             7.1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for sentiment analysis, we will want to combine the data into a new dataframe that will be used for pre-processing.\n",
    "# the fields that are relevant are the positive review, negative review, and the reviewer score\n",
    "# reviewer score can be used for labelling our sentiment as per the review \n",
    "\n",
    "original_data[\"Total_Review\"] = original_data[\"Negative_Review\"] + \" \" + original_data[\"Positive_Review\"]\n",
    "\n",
    "columns = [\"Total_Review\", \"Reviewer_Score\"]\n",
    "\n",
    "review_data = original_data[columns]\n",
    "\n",
    "review_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b4fddc",
   "metadata": {},
   "source": [
    "## Preprocessing The Review Data for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1a16f7",
   "metadata": {},
   "source": [
    "This section will be used to explore all the different preprocessing options and build functions that will work for my data cleaning and preprocessing pipeline. Once completed, I will optimize it into one function that can be used and adjusted more effectively for determining the best preprocessing techniques for the sentiment analysis. \n",
    "\n",
    "While there will be lots of work through this section that should be reviewed, the code will all be commented out and the optimized function will be the function I work with to allow me to change steps easier and get new results to see the impact of preprocessing steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d502e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, I will be using nltk to pre-process the reviews for machine learning applications. \n",
    "# I will also use regular expressions to remove special characters\n",
    "\n",
    "# import nltk\n",
    "# import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c69f5dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Total_Review_handled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>i am so angry that i made this post available...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Negative  No real complaints the hotel was ...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>no negative  no real complaints the hotel was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>7.1</td>\n",
       "      <td>rooms are nice but for elderly a bit difficul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>my room was dirty and i was afraid to walk ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>6.7</td>\n",
       "      <td>you when i booked with your company on line y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>no trolly or staff to help you take the lugga...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>no trolly or staff to help you take the lugga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>The hotel looks like 3 but surely not 4   Bre...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>the hotel looks like  but surely not    break...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>The ac was useless It was a hot week in vienn...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>the ac was useless it was a hot week in vienn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515736</th>\n",
       "      <td>No Negative  The rooms are enormous and really...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>no negative  the rooms are enormous and really...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>I was in 3rd floor It didn t work Free Wife  ...</td>\n",
       "      <td>8.3</td>\n",
       "      <td>i was in rd floor it didn t work free wife   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515738 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Total_Review  Reviewer_Score  \\\n",
       "0        I am so angry that i made this post available...             2.9   \n",
       "1       No Negative  No real complaints the hotel was ...             7.5   \n",
       "2        Rooms are nice but for elderly a bit difficul...             7.1   \n",
       "3        My room was dirty and I was afraid to walk ba...             3.8   \n",
       "4        You When I booked with your company on line y...             6.7   \n",
       "...                                                   ...             ...   \n",
       "515733   no trolly or staff to help you take the lugga...             7.0   \n",
       "515734   The hotel looks like 3 but surely not 4   Bre...             5.8   \n",
       "515735   The ac was useless It was a hot week in vienn...             2.5   \n",
       "515736  No Negative  The rooms are enormous and really...             8.8   \n",
       "515737   I was in 3rd floor It didn t work Free Wife  ...             8.3   \n",
       "\n",
       "                                     Total_Review_handled  \n",
       "0        i am so angry that i made this post available...  \n",
       "1       no negative  no real complaints the hotel was ...  \n",
       "2        rooms are nice but for elderly a bit difficul...  \n",
       "3        my room was dirty and i was afraid to walk ba...  \n",
       "4        you when i booked with your company on line y...  \n",
       "...                                                   ...  \n",
       "515733   no trolly or staff to help you take the lugga...  \n",
       "515734   the hotel looks like  but surely not    break...  \n",
       "515735   the ac was useless it was a hot week in vienn...  \n",
       "515736  no negative  the rooms are enormous and really...  \n",
       "515737   i was in rd floor it didn t work free wife   ...  \n",
       "\n",
       "[515738 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first I want to remove special characters\n",
    "# I will define a function for this\n",
    "\n",
    "# def preprocess_remove_special(review):\n",
    "#     #to remove all special characters and ensure they are all alphabetic, I will use regular expression substitution\n",
    "#     # i will just remove them in this case if there are any\n",
    "#     review_handled = re.sub(r'[^a-zA-Z\\s]', '', review)\n",
    "#     #to extend the functionality I will also lowercase all the text\n",
    "#     review_lower = review_handled.lower()\n",
    "#     return review_lower\n",
    "\n",
    "# #in order to compare I want to make a copy of the original data and then compare it to the processed later on\n",
    "# #also, just to be safe so that we don't currupt data and have backups\n",
    "# review_data_copy = review_data.copy()\n",
    "\n",
    "# review_data_copy.loc[:, 'Total_Review_handled'] = review_data[\"Total_Review\"].apply(preprocess_remove_special)\n",
    "\n",
    "# review_data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83b2a783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Total_Review_handled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>i am so angry that i made this post available...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Negative  No real complaints the hotel was ...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>no real complaints the hotel was great great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>7.1</td>\n",
       "      <td>rooms are nice but for elderly a bit difficul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>my room was dirty and i was afraid to walk ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>6.7</td>\n",
       "      <td>you when i booked with your company on line y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>no trolly or staff to help you take the lugga...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>no trolly or staff to help you take the lugga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>The hotel looks like 3 but surely not 4   Bre...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>the hotel looks like  but surely not    break...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>The ac was useless It was a hot week in vienn...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>the ac was useless it was a hot week in vienn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515736</th>\n",
       "      <td>No Negative  The rooms are enormous and really...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>the rooms are enormous and really comfortabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>I was in 3rd floor It didn t work Free Wife  ...</td>\n",
       "      <td>8.3</td>\n",
       "      <td>i was in rd floor it didn t work free wife   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515738 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Total_Review  Reviewer_Score  \\\n",
       "0        I am so angry that i made this post available...             2.9   \n",
       "1       No Negative  No real complaints the hotel was ...             7.5   \n",
       "2        Rooms are nice but for elderly a bit difficul...             7.1   \n",
       "3        My room was dirty and I was afraid to walk ba...             3.8   \n",
       "4        You When I booked with your company on line y...             6.7   \n",
       "...                                                   ...             ...   \n",
       "515733   no trolly or staff to help you take the lugga...             7.0   \n",
       "515734   The hotel looks like 3 but surely not 4   Bre...             5.8   \n",
       "515735   The ac was useless It was a hot week in vienn...             2.5   \n",
       "515736  No Negative  The rooms are enormous and really...             8.8   \n",
       "515737   I was in 3rd floor It didn t work Free Wife  ...             8.3   \n",
       "\n",
       "                                     Total_Review_handled  \n",
       "0        i am so angry that i made this post available...  \n",
       "1         no real complaints the hotel was great great...  \n",
       "2        rooms are nice but for elderly a bit difficul...  \n",
       "3        my room was dirty and i was afraid to walk ba...  \n",
       "4        you when i booked with your company on line y...  \n",
       "...                                                   ...  \n",
       "515733   no trolly or staff to help you take the lugga...  \n",
       "515734   the hotel looks like  but surely not    break...  \n",
       "515735   the ac was useless it was a hot week in vienn...  \n",
       "515736    the rooms are enormous and really comfortabl...  \n",
       "515737   i was in rd floor it didn t work free wife   ...  \n",
       "\n",
       "[515738 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next, I want to remove the \"no positive\" and \"no negative\" as this does not add any value to the text \n",
    "# it also may be confusing if it sees \"positive\" but it is actually not positive - since it adds little\n",
    "# value I can remove it - ran into issues here - regex = true was needed \n",
    "# see source: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html [2]\n",
    "\n",
    "# review_data_stripped = review_data_copy.copy()\n",
    "\n",
    "# review_data_stripped['Total_Review_handled'] = review_data_stripped[\"Total_Review_handled\"].replace(['no negative', 'no positive'], '', regex=True)\n",
    "\n",
    "# review_data_stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a4d6544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next preprocessing techniques I am going to perform are tokenization, remove stopwords, and lemmatize\n",
    "# in order to do this, I will still use nltk and import the relevant libraries\n",
    "# I will use the WordNetLemmatizer first as I have most experience with it from the courses. \n",
    "\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52a210fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/coreyreid/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first I will define a function for tokenizing the data\n",
    "# I will use nltk first with the punkt sentance tokenizer - and may consider SpaCy in the future to compare\n",
    "# coding refernce: nltk.org/_modules/nltk/tokenize/punkt.html\n",
    "\n",
    "# download the NLTK Punkt resource\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45697d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Total_Review_handled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[i, am, so, angry, that, i, made, this, post, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Negative  No real complaints the hotel was ...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>[no, real, complaints, the, hotel, was, great,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>7.1</td>\n",
       "      <td>[rooms, are, nice, but, for, elderly, a, bit, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[my, room, was, dirty, and, i, was, afraid, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>6.7</td>\n",
       "      <td>[you, when, i, booked, with, your, company, on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>no trolly or staff to help you take the lugga...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[no, trolly, or, staff, to, help, you, take, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>The hotel looks like 3 but surely not 4   Bre...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>[the, hotel, looks, like, but, surely, not, br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>The ac was useless It was a hot week in vienn...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>[the, ac, was, useless, it, was, a, hot, week,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515736</th>\n",
       "      <td>No Negative  The rooms are enormous and really...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>[the, rooms, are, enormous, and, really, comfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>I was in 3rd floor It didn t work Free Wife  ...</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[i, was, in, rd, floor, it, didn, t, work, fre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515738 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Total_Review  Reviewer_Score  \\\n",
       "0        I am so angry that i made this post available...             2.9   \n",
       "1       No Negative  No real complaints the hotel was ...             7.5   \n",
       "2        Rooms are nice but for elderly a bit difficul...             7.1   \n",
       "3        My room was dirty and I was afraid to walk ba...             3.8   \n",
       "4        You When I booked with your company on line y...             6.7   \n",
       "...                                                   ...             ...   \n",
       "515733   no trolly or staff to help you take the lugga...             7.0   \n",
       "515734   The hotel looks like 3 but surely not 4   Bre...             5.8   \n",
       "515735   The ac was useless It was a hot week in vienn...             2.5   \n",
       "515736  No Negative  The rooms are enormous and really...             8.8   \n",
       "515737   I was in 3rd floor It didn t work Free Wife  ...             8.3   \n",
       "\n",
       "                                     Total_Review_handled  \n",
       "0       [i, am, so, angry, that, i, made, this, post, ...  \n",
       "1       [no, real, complaints, the, hotel, was, great,...  \n",
       "2       [rooms, are, nice, but, for, elderly, a, bit, ...  \n",
       "3       [my, room, was, dirty, and, i, was, afraid, to...  \n",
       "4       [you, when, i, booked, with, your, company, on...  \n",
       "...                                                   ...  \n",
       "515733  [no, trolly, or, staff, to, help, you, take, t...  \n",
       "515734  [the, hotel, looks, like, but, surely, not, br...  \n",
       "515735  [the, ac, was, useless, it, was, a, hot, week,...  \n",
       "515736  [the, rooms, are, enormous, and, really, comfo...  \n",
       "515737  [i, was, in, rd, floor, it, didn, t, work, fre...  \n",
       "\n",
       "[515738 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the function for tokenizing the column \"Total review handled\"\n",
    "\n",
    "# def preprocess_tokenize(review):\n",
    "#     bag_of_words = word_tokenize(review)\n",
    "#     return bag_of_words\n",
    "\n",
    "# review_data_tokenized = review_data_stripped.copy()\n",
    "\n",
    "# review_data_tokenized['Total_Review_handled'] = review_data_tokenized[\"Total_Review_handled\"].apply(preprocess_tokenize)\n",
    "\n",
    "# review_data_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "95d861ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/coreyreid/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next, I will remove all stopwords from Total_Review_handled\n",
    "# first, I need to download the stopwords from nltk\n",
    "\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d17b5112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now I will create a function to remove stopwords\n",
    "\n",
    "# def preprocess_stopwords(review):\n",
    "#     #define the language for the stopwords\n",
    "#     words = stopwords.words('english')\n",
    "#     #set the stopword data to check against\n",
    "#     set_stop_words = set(words)\n",
    "    \n",
    "#     #create the loop to check all the words in the review against the stopword text\n",
    "#     removed_stopwords_words = []\n",
    "#     #loop through the review text and if it is not a stopword append it to a new list\n",
    "#     for word in review:\n",
    "#         if word not in set_stop_words:\n",
    "#             removed_stopwords_words.append(word)\n",
    "#     # return the new list with stopwords removed\n",
    "#     return removed_stopwords_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c66e083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Total_Review_handled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[angry, made, post, available, via, possible, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Negative  No real complaints the hotel was ...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>[real, complaints, hotel, great, great, locati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>7.1</td>\n",
       "      <td>[rooms, nice, elderly, bit, difficult, rooms, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[room, dirty, afraid, walk, barefoot, floor, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>6.7</td>\n",
       "      <td>[booked, company, line, showed, pictures, room...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>no trolly or staff to help you take the lugga...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[trolly, staff, help, take, luggage, room, loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>The hotel looks like 3 but surely not 4   Bre...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>[hotel, looks, like, surely, breakfast, ok, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>The ac was useless It was a hot week in vienn...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>[ac, useless, hot, week, vienna, gave, hot, air]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515736</th>\n",
       "      <td>No Negative  The rooms are enormous and really...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>[rooms, enormous, really, comfortable, believe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>I was in 3rd floor It didn t work Free Wife  ...</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[rd, floor, work, free, wife, staff, kind]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515738 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Total_Review  Reviewer_Score  \\\n",
       "0        I am so angry that i made this post available...             2.9   \n",
       "1       No Negative  No real complaints the hotel was ...             7.5   \n",
       "2        Rooms are nice but for elderly a bit difficul...             7.1   \n",
       "3        My room was dirty and I was afraid to walk ba...             3.8   \n",
       "4        You When I booked with your company on line y...             6.7   \n",
       "...                                                   ...             ...   \n",
       "515733   no trolly or staff to help you take the lugga...             7.0   \n",
       "515734   The hotel looks like 3 but surely not 4   Bre...             5.8   \n",
       "515735   The ac was useless It was a hot week in vienn...             2.5   \n",
       "515736  No Negative  The rooms are enormous and really...             8.8   \n",
       "515737   I was in 3rd floor It didn t work Free Wife  ...             8.3   \n",
       "\n",
       "                                     Total_Review_handled  \n",
       "0       [angry, made, post, available, via, possible, ...  \n",
       "1       [real, complaints, hotel, great, great, locati...  \n",
       "2       [rooms, nice, elderly, bit, difficult, rooms, ...  \n",
       "3       [room, dirty, afraid, walk, barefoot, floor, l...  \n",
       "4       [booked, company, line, showed, pictures, room...  \n",
       "...                                                   ...  \n",
       "515733  [trolly, staff, help, take, luggage, room, loc...  \n",
       "515734  [hotel, looks, like, surely, breakfast, ok, go...  \n",
       "515735   [ac, useless, hot, week, vienna, gave, hot, air]  \n",
       "515736  [rooms, enormous, really, comfortable, believe...  \n",
       "515737         [rd, floor, work, free, wife, staff, kind]  \n",
       "\n",
       "[515738 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now I will apply the stopword removal function to my dataframe column Total_Review_handled\n",
    "\n",
    "# review_data_removed = review_data_tokenized.copy()\n",
    "\n",
    "# review_data_removed['Total_Review_handled'] = review_data_removed[\"Total_Review_handled\"].apply(preprocess_stopwords)\n",
    "\n",
    "# review_data_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6aab535a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/coreyreid/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/coreyreid/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next, I want to lemmatize the column Total_Review_handled\n",
    "# first I will download the needed nltk library, which will be wordnet in this application\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# #need to explicitly download this - found when exception was raised executing the lemmatizer code\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "db9982a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that I have the nltk library I will use, I will build a function for lemmatizing the column\n",
    "\n",
    "# def preprocess_lemmatize(review):\n",
    "    \n",
    "#     #need to initiate the lemmatizer model\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "#     #now I will lemmatize each review\n",
    "#     lemmatized_review = [lemmatizer.lemmatize(word) for word in review ]\n",
    "    \n",
    "#     #return the lemmatized review\n",
    "#     return lemmatized_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "280676d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Total_Review_handled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[angry, made, post, available, via, possible, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Negative  No real complaints the hotel was ...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>[real, complaint, hotel, great, great, locatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>7.1</td>\n",
       "      <td>[room, nice, elderly, bit, difficult, room, tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[room, dirty, afraid, walk, barefoot, floor, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>6.7</td>\n",
       "      <td>[booked, company, line, showed, picture, room,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>no trolly or staff to help you take the lugga...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[trolly, staff, help, take, luggage, room, loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>The hotel looks like 3 but surely not 4   Bre...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>[hotel, look, like, surely, breakfast, ok, got...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>The ac was useless It was a hot week in vienn...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>[ac, useless, hot, week, vienna, gave, hot, air]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515736</th>\n",
       "      <td>No Negative  The rooms are enormous and really...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>[room, enormous, really, comfortable, believe,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>I was in 3rd floor It didn t work Free Wife  ...</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[rd, floor, work, free, wife, staff, kind]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515738 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Total_Review  Reviewer_Score  \\\n",
       "0        I am so angry that i made this post available...             2.9   \n",
       "1       No Negative  No real complaints the hotel was ...             7.5   \n",
       "2        Rooms are nice but for elderly a bit difficul...             7.1   \n",
       "3        My room was dirty and I was afraid to walk ba...             3.8   \n",
       "4        You When I booked with your company on line y...             6.7   \n",
       "...                                                   ...             ...   \n",
       "515733   no trolly or staff to help you take the lugga...             7.0   \n",
       "515734   The hotel looks like 3 but surely not 4   Bre...             5.8   \n",
       "515735   The ac was useless It was a hot week in vienn...             2.5   \n",
       "515736  No Negative  The rooms are enormous and really...             8.8   \n",
       "515737   I was in 3rd floor It didn t work Free Wife  ...             8.3   \n",
       "\n",
       "                                     Total_Review_handled  \n",
       "0       [angry, made, post, available, via, possible, ...  \n",
       "1       [real, complaint, hotel, great, great, locatio...  \n",
       "2       [room, nice, elderly, bit, difficult, room, tw...  \n",
       "3       [room, dirty, afraid, walk, barefoot, floor, l...  \n",
       "4       [booked, company, line, showed, picture, room,...  \n",
       "...                                                   ...  \n",
       "515733  [trolly, staff, help, take, luggage, room, loc...  \n",
       "515734  [hotel, look, like, surely, breakfast, ok, got...  \n",
       "515735   [ac, useless, hot, week, vienna, gave, hot, air]  \n",
       "515736  [room, enormous, really, comfortable, believe,...  \n",
       "515737         [rd, floor, work, free, wife, staff, kind]  \n",
       "\n",
       "[515738 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implement the function on the Total_Review_handled column\n",
    "\n",
    "# review_data_lemmatized = review_data_removed.copy()\n",
    "\n",
    "# review_data_lemmatized['Total_Review_handled'] = review_data_lemmatized[\"Total_Review_handled\"].apply(preprocess_lemmatize)\n",
    "\n",
    "# review_data_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7cfafedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/coreyreid/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As a final step in my data preprocessing pipeline, I am going to implement POS tagging \n",
    "\n",
    "#first, I need to download the tagger I want to use\n",
    "\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "02b5765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now I will complete the POS tagger function\n",
    "\n",
    "# def preprocess_tagger(review):\n",
    "#     tagged_review = nltk.pos_tag(review)\n",
    "#     return tagged_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "baa3b7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Total_Review_handled</th>\n",
       "      <th>POS_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[angry, made, post, available, via, possible, ...</td>\n",
       "      <td>[(angry, JJ), (made, VBD), (post, NN), (availa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Negative  No real complaints the hotel was ...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>[real, complaint, hotel, great, great, locatio...</td>\n",
       "      <td>[(real, JJ), (complaint, NN), (hotel, NN), (gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>7.1</td>\n",
       "      <td>[room, nice, elderly, bit, difficult, room, tw...</td>\n",
       "      <td>[(room, NN), (nice, RB), (elderly, JJ), (bit, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[room, dirty, afraid, walk, barefoot, floor, l...</td>\n",
       "      <td>[(room, NN), (dirty, NN), (afraid, JJ), (walk,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>6.7</td>\n",
       "      <td>[booked, company, line, showed, picture, room,...</td>\n",
       "      <td>[(booked, VBN), (company, NN), (line, NN), (sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>no trolly or staff to help you take the lugga...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[trolly, staff, help, take, luggage, room, loc...</td>\n",
       "      <td>[(trolly, RB), (staff, NN), (help, NN), (take,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>The hotel looks like 3 but surely not 4   Bre...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>[hotel, look, like, surely, breakfast, ok, got...</td>\n",
       "      <td>[(hotel, NN), (look, NN), (like, IN), (surely,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>The ac was useless It was a hot week in vienn...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>[ac, useless, hot, week, vienna, gave, hot, air]</td>\n",
       "      <td>[(ac, JJ), (useless, JJ), (hot, JJ), (week, NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515736</th>\n",
       "      <td>No Negative  The rooms are enormous and really...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>[room, enormous, really, comfortable, believe,...</td>\n",
       "      <td>[(room, NN), (enormous, JJ), (really, RB), (co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>I was in 3rd floor It didn t work Free Wife  ...</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[rd, floor, work, free, wife, staff, kind]</td>\n",
       "      <td>[(rd, NN), (floor, NN), (work, NN), (free, JJ)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515738 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Total_Review  Reviewer_Score  \\\n",
       "0        I am so angry that i made this post available...             2.9   \n",
       "1       No Negative  No real complaints the hotel was ...             7.5   \n",
       "2        Rooms are nice but for elderly a bit difficul...             7.1   \n",
       "3        My room was dirty and I was afraid to walk ba...             3.8   \n",
       "4        You When I booked with your company on line y...             6.7   \n",
       "...                                                   ...             ...   \n",
       "515733   no trolly or staff to help you take the lugga...             7.0   \n",
       "515734   The hotel looks like 3 but surely not 4   Bre...             5.8   \n",
       "515735   The ac was useless It was a hot week in vienn...             2.5   \n",
       "515736  No Negative  The rooms are enormous and really...             8.8   \n",
       "515737   I was in 3rd floor It didn t work Free Wife  ...             8.3   \n",
       "\n",
       "                                     Total_Review_handled  \\\n",
       "0       [angry, made, post, available, via, possible, ...   \n",
       "1       [real, complaint, hotel, great, great, locatio...   \n",
       "2       [room, nice, elderly, bit, difficult, room, tw...   \n",
       "3       [room, dirty, afraid, walk, barefoot, floor, l...   \n",
       "4       [booked, company, line, showed, picture, room,...   \n",
       "...                                                   ...   \n",
       "515733  [trolly, staff, help, take, luggage, room, loc...   \n",
       "515734  [hotel, look, like, surely, breakfast, ok, got...   \n",
       "515735   [ac, useless, hot, week, vienna, gave, hot, air]   \n",
       "515736  [room, enormous, really, comfortable, believe,...   \n",
       "515737         [rd, floor, work, free, wife, staff, kind]   \n",
       "\n",
       "                                                  POS_Tag  \n",
       "0       [(angry, JJ), (made, VBD), (post, NN), (availa...  \n",
       "1       [(real, JJ), (complaint, NN), (hotel, NN), (gr...  \n",
       "2       [(room, NN), (nice, RB), (elderly, JJ), (bit, ...  \n",
       "3       [(room, NN), (dirty, NN), (afraid, JJ), (walk,...  \n",
       "4       [(booked, VBN), (company, NN), (line, NN), (sh...  \n",
       "...                                                   ...  \n",
       "515733  [(trolly, RB), (staff, NN), (help, NN), (take,...  \n",
       "515734  [(hotel, NN), (look, NN), (like, IN), (surely,...  \n",
       "515735  [(ac, JJ), (useless, JJ), (hot, JJ), (week, NN...  \n",
       "515736  [(room, NN), (enormous, JJ), (really, RB), (co...  \n",
       "515737  [(rd, NN), (floor, NN), (work, NN), (free, JJ)...  \n",
       "\n",
       "[515738 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally, I will add a column that shows the POS tags\n",
    "\n",
    "# review_data_tagged = review_data_lemmatized.copy()\n",
    "\n",
    "# review_data_tagged['POS_Tag'] = review_data_tagged[\"Total_Review_handled\"].apply(preprocess_tagger)\n",
    "\n",
    "# review_data_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "302d872f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS_Tag</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(angry, JJ), (made, VBD), (post, NN), (availa...</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(real, JJ), (complaint, NN), (hotel, NN), (gr...</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(room, NN), (nice, RB), (elderly, JJ), (bit, ...</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(room, NN), (dirty, NN), (afraid, JJ), (walk,...</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(booked, VBN), (company, NN), (line, NN), (sh...</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>[(trolly, RB), (staff, NN), (help, NN), (take,...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>[(hotel, NN), (look, NN), (like, IN), (surely,...</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>[(ac, JJ), (useless, JJ), (hot, JJ), (week, NN...</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515736</th>\n",
       "      <td>[(room, NN), (enormous, JJ), (really, RB), (co...</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>[(rd, NN), (floor, NN), (work, NN), (free, JJ)...</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515738 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  POS_Tag  Reviewer_Score\n",
       "0       [(angry, JJ), (made, VBD), (post, NN), (availa...             2.9\n",
       "1       [(real, JJ), (complaint, NN), (hotel, NN), (gr...             7.5\n",
       "2       [(room, NN), (nice, RB), (elderly, JJ), (bit, ...             7.1\n",
       "3       [(room, NN), (dirty, NN), (afraid, JJ), (walk,...             3.8\n",
       "4       [(booked, VBN), (company, NN), (line, NN), (sh...             6.7\n",
       "...                                                   ...             ...\n",
       "515733  [(trolly, RB), (staff, NN), (help, NN), (take,...             7.0\n",
       "515734  [(hotel, NN), (look, NN), (like, IN), (surely,...             5.8\n",
       "515735  [(ac, JJ), (useless, JJ), (hot, JJ), (week, NN...             2.5\n",
       "515736  [(room, NN), (enormous, JJ), (really, RB), (co...             8.8\n",
       "515737  [(rd, NN), (floor, NN), (work, NN), (free, JJ)...             8.3\n",
       "\n",
       "[515738 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that I can confirm the cleaning and preprocessing was successful, I will reduce the data to two columns\n",
    "# the POS_Tag column and the Reviewer_Score column\n",
    "# first I will copy to have a backup\n",
    "# review_data_final = review_data_tagged.copy()\n",
    "\n",
    "# #next I will remove columns from the copy\n",
    "# review_data_final = review_data_final.drop(columns=['Total_Review', 'Total_Review_handled'])\n",
    "\n",
    "# review_data_final = review_data_final[['POS_Tag', 'Reviewer_Score']]\n",
    "\n",
    "# review_data_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6614ace5",
   "metadata": {},
   "source": [
    "## Part 3: Optimizing the Pre-Processing into one Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3087941c",
   "metadata": {},
   "source": [
    "This section will be used for developing final preprocessing pipelines that can be used in my ML development. There will be two because one will be with using POS tagging and the other will be without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20a752e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/coreyreid/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/coreyreid/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/coreyreid/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/coreyreid/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/coreyreid/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "#import the relevant libraries and download the relevant nltk dependancies [3]\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#download the needed nltk toolkits\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# optimized all-encompassing function for preprocessing that can easily be manipulated for tests\n",
    "def preprocess_pos(review):\n",
    "    \n",
    "    #preprocess remove special characters and ensure lowercase \n",
    "    def preprocess_remove_special(review):\n",
    "        review_handled = re.sub(r'[^a-zA-Z\\s]', '', review)\n",
    "        review_lower = review_handled.lower()\n",
    "        return review_lower\n",
    "\n",
    "    #tokenize the words\n",
    "    def preprocess_tokenize(review):\n",
    "        bag_of_words = word_tokenize(review)\n",
    "        return bag_of_words\n",
    "\n",
    "    #remove the stopwords\n",
    "    def preprocess_stopwords(review):\n",
    "        words = stopwords.words('english')\n",
    "        set_stop_words = set(words)\n",
    "        removed_stopwords_words = []\n",
    "        for word in review:\n",
    "            if word not in set_stop_words:\n",
    "                removed_stopwords_words.append(word)\n",
    "        return removed_stopwords_words\n",
    "\n",
    "    #lemmatize\n",
    "    def preprocess_lemmatize(review):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized_review = [lemmatizer.lemmatize(word) for word in review ]\n",
    "        return lemmatized_review\n",
    "\n",
    "    #POS Tagging\n",
    "    def preprocess_tagger(review):\n",
    "        tagged_review = nltk.pos_tag(review)\n",
    "        return tagged_review\n",
    "\n",
    "\n",
    "    #execute the individual part functions within this bigger function\n",
    "    review_data_copy = review_data.copy()\n",
    "    review_data_copy['Total_Review_handled'] = review_data_copy[\"Total_Review\"].apply(preprocess_remove_special)\n",
    "    review_data_copy['Total_Review_handled'] = review_data_copy['Total_Review_handled'].apply(preprocess_tokenize)\n",
    "    review_data_copy['Total_Review_handled'] = review_data_copy['Total_Review_handled'].apply(preprocess_stopwords)\n",
    "    review_data_copy['Total_Review_handled'] = review_data_copy['Total_Review_handled'].apply(preprocess_lemmatize)\n",
    "    review_data_copy['POS_Tag'] = review_data_copy['Total_Review_handled'].apply(preprocess_tagger)\n",
    "\n",
    "    #create the final data\n",
    "    review_data_final = review_data_copy[['POS_Tag', 'Reviewer_Score']]\n",
    "    \n",
    "    #return the data\n",
    "    return review_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b86cd07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, I will create a similar function without POS Tagging and we will compare two techniques\n",
    "# with and without POS Tagging\n",
    "\n",
    "def preprocess_no_pos(review):\n",
    "    \n",
    "    # remove special characters and ensure it is lowercase\n",
    "    def preprocess_remove_special(review):\n",
    "        review_handled = re.sub(r'[^a-zA-Z\\s]', '', review)\n",
    "        review_lower = review_handled.lower()\n",
    "        return review_lower\n",
    "\n",
    "    #tokenize\n",
    "    def preprocess_tokenize(review):\n",
    "        bag_of_words = word_tokenize(review)\n",
    "        return bag_of_words\n",
    "\n",
    "    #remove stopwords\n",
    "    def preprocess_stopwords(review):\n",
    "        words = stopwords.words('english')\n",
    "        set_stop_words = set(words)\n",
    "        removed_stopwords_words = []\n",
    "        for word in review:\n",
    "            if word not in set_stop_words:\n",
    "                removed_stopwords_words.append(word)\n",
    "        return removed_stopwords_words\n",
    "\n",
    "    #lemmatize\n",
    "    def preprocess_lemmatize(review):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized_review = [lemmatizer.lemmatize(word) for word in review ]\n",
    "        return lemmatized_review\n",
    "\n",
    "    #execute functions within the bigger function\n",
    "    review_data_copy = review_data.copy()\n",
    "    review_data_copy['Total_Review_handled'] = review_data_copy[\"Total_Review\"].apply(preprocess_remove_special)\n",
    "    review_data_copy['Total_Review_handled'] = review_data_copy['Total_Review_handled'].apply(preprocess_tokenize)\n",
    "    review_data_copy['Total_Review_handled'] = review_data_copy['Total_Review_handled'].apply(preprocess_stopwords)\n",
    "    review_data_copy['Total_Review_handled'] = review_data_copy['Total_Review_handled'].apply(preprocess_lemmatize)\n",
    "\n",
    "    #finalize data\n",
    "    review_data_final = review_data_copy[['Total_Review_handled', 'Reviewer_Score']]\n",
    "\n",
    "    #return the preprocessed data\n",
    "    return review_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9870ba09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS_Tag</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(angry, JJ), (made, VBD), (post, NN), (availa...</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(negative, JJ), (real, JJ), (complaint, NN), ...</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(room, NN), (nice, RB), (elderly, JJ), (bit, ...</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(room, NN), (dirty, NN), (afraid, JJ), (walk,...</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(booked, VBN), (company, NN), (line, NN), (sh...</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>[(trolly, RB), (staff, NN), (help, NN), (take,...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>[(hotel, NN), (look, NN), (like, IN), (surely,...</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>[(ac, JJ), (useless, JJ), (hot, JJ), (week, NN...</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515736</th>\n",
       "      <td>[(negative, JJ), (room, NN), (enormous, JJ), (...</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>[(rd, NN), (floor, NN), (work, NN), (free, JJ)...</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515738 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  POS_Tag  Reviewer_Score\n",
       "0       [(angry, JJ), (made, VBD), (post, NN), (availa...             2.9\n",
       "1       [(negative, JJ), (real, JJ), (complaint, NN), ...             7.5\n",
       "2       [(room, NN), (nice, RB), (elderly, JJ), (bit, ...             7.1\n",
       "3       [(room, NN), (dirty, NN), (afraid, JJ), (walk,...             3.8\n",
       "4       [(booked, VBN), (company, NN), (line, NN), (sh...             6.7\n",
       "...                                                   ...             ...\n",
       "515733  [(trolly, RB), (staff, NN), (help, NN), (take,...             7.0\n",
       "515734  [(hotel, NN), (look, NN), (like, IN), (surely,...             5.8\n",
       "515735  [(ac, JJ), (useless, JJ), (hot, JJ), (week, NN...             2.5\n",
       "515736  [(negative, JJ), (room, NN), (enormous, JJ), (...             8.8\n",
       "515737  [(rd, NN), (floor, NN), (work, NN), (free, JJ)...             8.3\n",
       "\n",
       "[515738 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#next I will process the data with POS Tagging to compare to the previous section\n",
    "#these should be the same as it is just an optimized function\n",
    "preprocessed_reviews_pos_tagging = preprocess_pos(review_data)\n",
    "preprocessed_reviews_pos_tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5a6d329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Review_handled</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[angry, made, post, available, via, possible, ...</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[negative, real, complaint, hotel, great, grea...</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[room, nice, elderly, bit, difficult, room, tw...</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[room, dirty, afraid, walk, barefoot, floor, l...</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[booked, company, line, showed, picture, room,...</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>[trolly, staff, help, take, luggage, room, loc...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>[hotel, look, like, surely, breakfast, ok, got...</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>[ac, useless, hot, week, vienna, gave, hot, ai...</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515736</th>\n",
       "      <td>[negative, room, enormous, really, comfortable...</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>[rd, floor, work, free, wife, staff, kind]</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515738 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Total_Review_handled  Reviewer_Score\n",
       "0       [angry, made, post, available, via, possible, ...             2.9\n",
       "1       [negative, real, complaint, hotel, great, grea...             7.5\n",
       "2       [room, nice, elderly, bit, difficult, room, tw...             7.1\n",
       "3       [room, dirty, afraid, walk, barefoot, floor, l...             3.8\n",
       "4       [booked, company, line, showed, picture, room,...             6.7\n",
       "...                                                   ...             ...\n",
       "515733  [trolly, staff, help, take, luggage, room, loc...             7.0\n",
       "515734  [hotel, look, like, surely, breakfast, ok, got...             5.8\n",
       "515735  [ac, useless, hot, week, vienna, gave, hot, ai...             2.5\n",
       "515736  [negative, room, enormous, really, comfortable...             8.8\n",
       "515737         [rd, floor, work, free, wife, staff, kind]             8.3\n",
       "\n",
       "[515738 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#last, I will process the review data without POS Tagging, the processing will end at lemmatizing. \n",
    "preprocessed_reviews_no_pos_tagging = preprocess_no_pos(review_data)\n",
    "preprocessed_reviews_no_pos_tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e281d302",
   "metadata": {},
   "source": [
    "These two dataframes will be the two types of preprocessing methods I will consider in each of the models. This will show the difference between using POS tags and not using them. Additionally, we will now have two cases for exploring the impact on machine learning outcomes. \n",
    "\n",
    "The dataframes both are showing the data as expected so we can now proceed to implementing different machine learning models. We will then compare the results and determine which machine learning model is best for sentiment analysis of the Short-Term Rental review data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6925112",
   "metadata": {},
   "source": [
    "## Part 4: Classifying the Review Score Data for Machine Learning Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5acb74cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS_Tag</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(angry, JJ), (made, VBD), (post, NN), (availa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(negative, JJ), (real, JJ), (complaint, NN), ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(room, NN), (nice, RB), (elderly, JJ), (bit, ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(room, NN), (dirty, NN), (afraid, JJ), (walk,...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(booked, VBN), (company, NN), (line, NN), (sh...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>[(trolly, RB), (staff, NN), (help, NN), (take,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>[(hotel, NN), (look, NN), (like, IN), (surely,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>[(ac, JJ), (useless, JJ), (hot, JJ), (week, NN...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515736</th>\n",
       "      <td>[(negative, JJ), (room, NN), (enormous, JJ), (...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>[(rd, NN), (floor, NN), (work, NN), (free, JJ)...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515738 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  POS_Tag Reviewer_Score\n",
       "0       [(angry, JJ), (made, VBD), (post, NN), (availa...       negative\n",
       "1       [(negative, JJ), (real, JJ), (complaint, NN), ...       positive\n",
       "2       [(room, NN), (nice, RB), (elderly, JJ), (bit, ...       positive\n",
       "3       [(room, NN), (dirty, NN), (afraid, JJ), (walk,...       negative\n",
       "4       [(booked, VBN), (company, NN), (line, NN), (sh...       positive\n",
       "...                                                   ...            ...\n",
       "515733  [(trolly, RB), (staff, NN), (help, NN), (take,...       positive\n",
       "515734  [(hotel, NN), (look, NN), (like, IN), (surely,...       positive\n",
       "515735  [(ac, JJ), (useless, JJ), (hot, JJ), (week, NN...       negative\n",
       "515736  [(negative, JJ), (room, NN), (enormous, JJ), (...       positive\n",
       "515737  [(rd, NN), (floor, NN), (work, NN), (free, JJ)...       positive\n",
       "\n",
       "[515738 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first I will define the thresholds - our labels will be positive, negative, and neutral \n",
    "# I decided to use a small window for neutral, between 4.5 and 5.5 - this will ensure most the review classifications\n",
    "# are sensative - it can be updated later if desired by changing the following threshold values\n",
    "\n",
    "positive_threshold = 5.5\n",
    "negative_threshold = 4.5\n",
    "\n",
    "# next, I will classify by building a classification function\n",
    "\n",
    "def classify_scores(score_value):\n",
    "    if score_value >= positive_threshold:\n",
    "        return 'positive'\n",
    "    elif score_value <= negative_threshold:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "    \n",
    "preprocessed_reviews_pos_tagging_final = preprocessed_reviews_pos_tagging.copy()\n",
    "    \n",
    "preprocessed_reviews_pos_tagging_final['Reviewer_Score'] = preprocessed_reviews_pos_tagging_final['Reviewer_Score'].apply(classify_scores)\n",
    "\n",
    "preprocessed_reviews_pos_tagging_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4e8b4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Review_handled</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[angry, made, post, available, via, possible, ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[negative, real, complaint, hotel, great, grea...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[room, nice, elderly, bit, difficult, room, tw...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[room, dirty, afraid, walk, barefoot, floor, l...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[booked, company, line, showed, picture, room,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>[trolly, staff, help, take, luggage, room, loc...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>[hotel, look, like, surely, breakfast, ok, got...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>[ac, useless, hot, week, vienna, gave, hot, ai...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515736</th>\n",
       "      <td>[negative, room, enormous, really, comfortable...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>[rd, floor, work, free, wife, staff, kind]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515738 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Total_Review_handled Reviewer_Score\n",
       "0       [angry, made, post, available, via, possible, ...       negative\n",
       "1       [negative, real, complaint, hotel, great, grea...       positive\n",
       "2       [room, nice, elderly, bit, difficult, room, tw...       positive\n",
       "3       [room, dirty, afraid, walk, barefoot, floor, l...       negative\n",
       "4       [booked, company, line, showed, picture, room,...       positive\n",
       "...                                                   ...            ...\n",
       "515733  [trolly, staff, help, take, luggage, room, loc...       positive\n",
       "515734  [hotel, look, like, surely, breakfast, ok, got...       positive\n",
       "515735  [ac, useless, hot, week, vienna, gave, hot, ai...       negative\n",
       "515736  [negative, room, enormous, really, comfortable...       positive\n",
       "515737         [rd, floor, work, free, wife, staff, kind]       positive\n",
       "\n",
       "[515738 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will also do the same for the no POS tagging scenario\n",
    "\n",
    "preprocessed_reviews_no_pos_tagging_final = preprocessed_reviews_no_pos_tagging.copy()\n",
    "    \n",
    "preprocessed_reviews_no_pos_tagging_final['Reviewer_Score'] = preprocessed_reviews_no_pos_tagging_final['Reviewer_Score'].apply(classify_scores)\n",
    "\n",
    "preprocessed_reviews_no_pos_tagging_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6e2262b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive    475509\n",
      "neutral      24188\n",
      "negative     16041\n",
      "Name: Reviewer_Score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# determine the counts of each category\n",
    "review_counts = preprocessed_reviews_no_pos_tagging_final['Reviewer_Score'].value_counts()\n",
    "print(review_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462acba7",
   "metadata": {},
   "source": [
    "The data has now been preprocessed and categorized. As can be seen, the dataset is very unbalanced as most of the data is positive reviews at this threshold. This may be problematic in some of our machine learning models that we will be exploring. There are techniques for unbalanced datasets, so we may need to employ some of those to get better classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cb4d3a",
   "metadata": {},
   "source": [
    "## Part 5: Exploring Multinomial Naive Bayes Outcomes for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aa783bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first machine learning algorithm I am going to explore is Multinomial Naive Bayes. \n",
    "# First, I will need to perform feature extraction this will be done using TF-IDF (Term Frequency-Inverse Document Frequency) \n",
    "# Also, I will need to split my data into training and testing data. \n",
    "# last, I will train the multinomial naive bayes algorithm and make predictions on the test data. \n",
    "\n",
    "#import the models I need for this machine learning algorithm - sklearn will be used [4]\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# First I will perform the training on the POS_tagged data\n",
    "# prepare the data back into strings which will be needed for Multinomial Naive bayes \n",
    "reviews_MNB = preprocessed_reviews_pos_tagging_final.copy()\n",
    "reviews_MNB['Review'] = reviews_MNB['POS_Tag'].apply(lambda tokens: ' '.join([f'{word}_{pos}' for word, pos in tokens]))\n",
    "\n",
    "#initialize the tfidf vectorizer \n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# vectorize the combined POS and Text from the review text and get the score values for y\n",
    "X_combined = vectorizer.fit_transform(reviews_MNB['Review'])\n",
    "y = reviews_MNB['Reviewer_Score']\n",
    "\n",
    "#split into test and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#now, I need to initialize the classifier and train it. \n",
    "multi_naive_bayes = MultinomialNB()\n",
    "multi_naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "#using the trained model, we will make predictions on the test set for final evaluation of the effectiveness \n",
    "y_predicted = multi_naive_bayes.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79f00150",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00      3198\n",
      "     neutral       0.08      0.00      0.00      4981\n",
      "    positive       0.92      1.00      0.96     94969\n",
      "\n",
      "    accuracy                           0.92    103148\n",
      "   macro avg       0.33      0.33      0.32    103148\n",
      "weighted avg       0.85      0.92      0.88    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[    0     2  3196]\n",
      " [    3     3  4975]\n",
      " [    4    33 94932]]\n",
      "Accuracy: 0.92037654632179\n"
     ]
    }
   ],
   "source": [
    "# Last, I will evaluate the data using SKLearn metrics [5]\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# run metric functions for the predicted data\n",
    "MNB_postag_report = classification_report(y_test, y_predicted)\n",
    "MNB_postag_confusion_matrix = confusion_matrix(y_test, y_predicted)\n",
    "MNB_postag_accuracy = accuracy_score(y_test, y_predicted)\n",
    "\n",
    "#print the results\n",
    "print(\"Classification Report:\\n\", MNB_postag_report)\n",
    "print(\"Confusion Matrix:\\n\", MNB_postag_confusion_matrix)\n",
    "print(\"Accuracy:\", MNB_postag_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1083422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "# this did not work very well, so we need to try and oversample the negative classification due to imbalance\n",
    "# to do this I will use SMOTE and try to improve the outcome with oversampling [6]\n",
    "!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ff5918d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.18      0.53      0.27      3198\n",
      "     neutral       0.14      0.51      0.22      4981\n",
      "    positive       0.98      0.78      0.87     94969\n",
      "\n",
      "    accuracy                           0.76    103148\n",
      "   macro avg       0.43      0.61      0.45    103148\n",
      "weighted avg       0.92      0.76      0.82    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1694  1207   297]\n",
      " [ 1483  2557   941]\n",
      " [ 6310 14255 74404]]\n",
      "Accuracy: 0.7625450808546942\n"
     ]
    }
   ],
   "source": [
    "#import the library needed - SMOTE [7]\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Fit and transform the data\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#now, I need to initialize the classifier and train it. \n",
    "multi_naive_bayes_resampled = MultinomialNB()\n",
    "multi_naive_bayes_resampled.fit(X_resampled, y_resampled)\n",
    "\n",
    "#using the trained model, we will make predictions on the test set for final evaluation of the effectiveness \n",
    "y_predicted_resampled = multi_naive_bayes_resampled.predict(X_test)\n",
    "\n",
    "#evaluate\n",
    "MNB_postag_report_resampled = classification_report(y_test, y_predicted_resampled)\n",
    "MNB_postag_confusion_matrix_resampled = confusion_matrix(y_test, y_predicted_resampled)\n",
    "MNB_postag_accuracy_resampled = accuracy_score(y_test, y_predicted_resampled)\n",
    "\n",
    "#print results\n",
    "print(\"Classification Report:\\n\", MNB_postag_report_resampled)\n",
    "print(\"Confusion Matrix:\\n\", MNB_postag_confusion_matrix_resampled)\n",
    "print(\"Accuracy:\", MNB_postag_accuracy_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc73825",
   "metadata": {},
   "source": [
    "When resampling was added, it can be seen that the overall accuracy decreased. This can be misleading, however, because before it had no success finding any of the negatives at all. Therefore, because the data was so imbalanced, it could get lucky predicting positive but it pretty much predicted positive for every value. Here, after the resampling took place, the precision and recall for the negative and neutral classes improved, as was expected because the dataset became more balanced. Also, the number of True Negatives increased in the confusion matrix, meaning that it has become better at finding the actual negative reviews. While the results aren't great, the model itself may not be the best fit for the inbalance dataset we are using. One solution for this may be to increase the threshold of what is considered a positive and negative review. This may be a possible solution because we really only care about the really good reviews, and anything that is below a higher threshold like 7 means that excellence was not achieved. I may consider doing this if none of the models work well with the imbalanced dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23106eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "# last, I am going to try to find a better smoothing value for this imbalanced data to see if I can improve this\n",
    "# this will be done using Grid Search - first I will do it on the original data and not resampled to see if I can\n",
    "# improve the outcome - if so, I will see if resampling and adjusting the alpha value helps more.[8]\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Range of alpha values to explore\n",
    "alpha_values = [0.1, 1, 5, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 30, 40, 50]\n",
    "\n",
    "# Define the paramater grid\n",
    "param_grid = {'alpha': alpha_values}\n",
    "\n",
    "# Initialize the MultinomialNB classifier\n",
    "multi_naive_bayes_smoothing = MultinomialNB()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(multi_naive_bayes_smoothing, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# show the best alpha value\n",
    "optimal_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "#show for confirmation\n",
    "print(optimal_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f36ad29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/coreyreid/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/coreyreid/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/coreyreid/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00      3198\n",
      "     neutral       1.00      0.00      0.00      4981\n",
      "    positive       0.92      1.00      0.96     94969\n",
      "\n",
      "    accuracy                           0.92    103148\n",
      "   macro avg       0.64      0.33      0.32    103148\n",
      "weighted avg       0.90      0.92      0.88    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[    0     0  3198]\n",
      " [    0     1  4980]\n",
      " [    0     0 94969]]\n",
      "Accuracy: 0.9207158645829294\n"
     ]
    }
   ],
   "source": [
    "# we will now train with this alpha on the original data without oversampling\n",
    "# this is done using Multinomial Naive Bayes [9]\n",
    "multi_naive_bayes_optimized_smoothing = MultinomialNB(alpha=optimal_alpha)\n",
    "\n",
    "# this is meant to use the initial train values, as we are first testing on the original data before oversampling\n",
    "multi_naive_bayes_optimized_smoothing.fit(X_train, y_train)\n",
    "\n",
    "#using the trained model, we will make predictions on the test set for final evaluation of the effectiveness \n",
    "y_predicted_optimized_smoothing = multi_naive_bayes_optimized_smoothing.predict(X_test)\n",
    "\n",
    "#evaluate the results\n",
    "MNB_postag_report_optimized_smoothing = classification_report(y_test, y_predicted_optimized_smoothing)\n",
    "MNB_postag_confusion_matrix_optimized_smoothing = confusion_matrix(y_test, y_predicted_optimized_smoothing)\n",
    "MNB_postag_accuracy_optimized_smoothing = accuracy_score(y_test, y_predicted_optimized_smoothing)\n",
    "\n",
    "#print the results\n",
    "print(\"Classification Report:\\n\", MNB_postag_report_optimized_smoothing)\n",
    "print(\"Confusion Matrix:\\n\", MNB_postag_confusion_matrix_optimized_smoothing)\n",
    "print(\"Accuracy:\", MNB_postag_accuracy_optimized_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f52ed39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.20      0.65      0.30      3198\n",
      "     neutral       0.17      0.30      0.22      4981\n",
      "    positive       0.97      0.86      0.91     94969\n",
      "\n",
      "    accuracy                           0.83    103148\n",
      "   macro avg       0.45      0.60      0.48    103148\n",
      "weighted avg       0.91      0.83      0.86    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 2065   615   518]\n",
      " [ 1855  1476  1650]\n",
      " [ 6654  6452 81863]]\n",
      "Accuracy: 0.8279753364098189\n"
     ]
    }
   ],
   "source": [
    "# this didn't impact the values of the original model with the imbalanced data - I will try it on the oversampled data\n",
    "# to see if there is an improvement there\n",
    "multi_naive_bayes_optimized_smoothing_oversampled = MultinomialNB(alpha=optimal_alpha)\n",
    "multi_naive_bayes_optimized_smoothing_oversampled.fit(X_resampled, y_resampled)\n",
    "\n",
    "#using the trained model, we will make predictions on the test set for final evaluation of the effectiveness \n",
    "y_predicted_optimized_smoothing_oversampled = multi_naive_bayes_optimized_smoothing_oversampled.predict(X_test)\n",
    "\n",
    "#evaluate\n",
    "MNB_postag_report_optimized_smoothing_oversampled = classification_report(y_test, y_predicted_optimized_smoothing_oversampled)\n",
    "MNB_postag_confusion_matrix_optimized_smoothing_oversampled = confusion_matrix(y_test, y_predicted_optimized_smoothing_oversampled)\n",
    "MNB_postag_accuracy_optimized_smoothing_oversampled = accuracy_score(y_test, y_predicted_optimized_smoothing_oversampled)\n",
    "\n",
    "#print results\n",
    "print(\"Classification Report:\\n\", MNB_postag_report_optimized_smoothing_oversampled)\n",
    "print(\"Confusion Matrix:\\n\", MNB_postag_confusion_matrix_optimized_smoothing_oversampled)\n",
    "print(\"Accuracy:\", MNB_postag_accuracy_optimized_smoothing_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7b4a182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.20      0.63      0.30      3198\n",
      "     neutral       0.17      0.33      0.23      4981\n",
      "    positive       0.98      0.86      0.91     94969\n",
      "\n",
      "    accuracy                           0.82    103148\n",
      "   macro avg       0.45      0.61      0.48    103148\n",
      "weighted avg       0.91      0.82      0.86    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 2014   694   490]\n",
      " [ 1773  1654  1554]\n",
      " [ 6440  7275 81254]]\n",
      "Accuracy: 0.8233024392135572\n"
     ]
    }
   ],
   "source": [
    "# this clearly improved the accuracy from just oversampling, and more True Negatives are now being found. \n",
    "# I will compare this now against the no POS Tagged data and see which performs better between POS and no POS\n",
    "# prepare the data back into strings which will be needed for Multinomial Naive bayes \n",
    "reviews_MNB_noPOS = preprocessed_reviews_no_pos_tagging_final.copy()\n",
    "reviews_MNB_noPOS['Total_Review_handled'] = reviews_MNB_noPOS['Total_Review_handled'].apply(lambda words: ' '.join(words))\n",
    "\n",
    "#initialize the tfidf vectorizer \n",
    "vectorizer_noPOS = TfidfVectorizer()\n",
    "\n",
    "# vectorize\n",
    "X = vectorizer_noPOS.fit_transform(reviews_MNB_noPOS['Total_Review_handled'])\n",
    "y = reviews_MNB['Reviewer_Score']\n",
    "\n",
    "#split into test and training data\n",
    "X_train_noPOS, X_test_noPOS, y_train_noPOS, y_test_noPOS = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote_noPOS = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "# Fit and transform the data\n",
    "X_resampled_noPOS, y_resampled_noPOS = smote_noPOS.fit_resample(X_train_noPOS, y_train_noPOS)\n",
    "\n",
    "# we will now train with the optimized alpha\n",
    "multi_naive_bayes_optimized_smoothing_noPOS = MultinomialNB(alpha=11)\n",
    "multi_naive_bayes_optimized_smoothing_noPOS.fit(X_resampled_noPOS, y_resampled_noPOS)\n",
    "\n",
    "#using the trained model, we will make predictions on the test set for final evaluation of the effectiveness \n",
    "y_predicted_noPOS = multi_naive_bayes_optimized_smoothing_noPOS.predict(X_test_noPOS)\n",
    "\n",
    "# evaluate\n",
    "MNB_report_optimized_smoothing = classification_report(y_test_noPOS, y_predicted_noPOS)\n",
    "MNB_confusion_matrix_optimized_smoothing = confusion_matrix(y_test_noPOS, y_predicted_noPOS)\n",
    "MNB_accuracy_optimized_smoothing = accuracy_score(y_test_noPOS, y_predicted_noPOS)\n",
    "\n",
    "#print the results\n",
    "print(\"Classification Report:\\n\", MNB_report_optimized_smoothing)\n",
    "print(\"Confusion Matrix:\\n\", MNB_confusion_matrix_optimized_smoothing)\n",
    "print(\"Accuracy:\", MNB_accuracy_optimized_smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1c86a8",
   "metadata": {},
   "source": [
    "The results of the scenario when we didn't use POS tagging is slightly lower accuracy than when we did use POS tagging. However, the change is pretty much negligible. This means that the POS tagging has little impact on the results of the classification when using multinomial naive bayes. The biggest issue with this model is that the data is so imbalanced it is having trouble with finding the negative because it does not have enough negative examples to train with. One solution would be to skew the thresholds. In reality, only really good reviews (above say, 8) would be considered reviews that are worth reaching out to so you can highlight the review and get more info about what they loved. Additionally, when people choose lower than a 7, generally they aren't thrilled with their experience. \n",
    "\n",
    "To try and see if we can improve the accuracy of the classifier with this dataset, we could adjust the thresholds and only consider above 9 as a very positive review, and anything below 7 as a negative review worth reaching out to to collect data on about how to improve the guest experience. Doing so, with an simple Multinomial Naive Bayes implementation would yield the following results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d16b943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS_Tag</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(angry, JJ), (made, VBD), (post, NN), (availa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(negative, JJ), (real, JJ), (complaint, NN), ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(room, NN), (nice, RB), (elderly, JJ), (bit, ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(room, NN), (dirty, NN), (afraid, JJ), (walk,...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(booked, VBN), (company, NN), (line, NN), (sh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>[(trolly, RB), (staff, NN), (help, NN), (take,...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>[(hotel, NN), (look, NN), (like, IN), (surely,...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>[(ac, JJ), (useless, JJ), (hot, JJ), (week, NN...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515736</th>\n",
       "      <td>[(negative, JJ), (room, NN), (enormous, JJ), (...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>[(rd, NN), (floor, NN), (work, NN), (free, JJ)...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515738 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  POS_Tag Reviewer_Score\n",
       "0       [(angry, JJ), (made, VBD), (post, NN), (availa...       negative\n",
       "1       [(negative, JJ), (real, JJ), (complaint, NN), ...        neutral\n",
       "2       [(room, NN), (nice, RB), (elderly, JJ), (bit, ...        neutral\n",
       "3       [(room, NN), (dirty, NN), (afraid, JJ), (walk,...       negative\n",
       "4       [(booked, VBN), (company, NN), (line, NN), (sh...       negative\n",
       "...                                                   ...            ...\n",
       "515733  [(trolly, RB), (staff, NN), (help, NN), (take,...       negative\n",
       "515734  [(hotel, NN), (look, NN), (like, IN), (surely,...       negative\n",
       "515735  [(ac, JJ), (useless, JJ), (hot, JJ), (week, NN...       negative\n",
       "515736  [(negative, JJ), (room, NN), (enormous, JJ), (...        neutral\n",
       "515737  [(rd, NN), (floor, NN), (work, NN), (free, JJ)...        neutral\n",
       "\n",
       "[515738 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adjust the thresholds to try and force a better balance in the data\n",
    "positive_threshold = 9.0\n",
    "negative_threshold = 7.0\n",
    "\n",
    "# next, I will classify the scores by building a classification function\n",
    "def classify_scores(score_value):\n",
    "    if score_value >= positive_threshold:\n",
    "        return 'positive'\n",
    "    elif score_value <= negative_threshold:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# I will use this function to categorize and provide labels to the Review_Score data\n",
    "preprocessed_reviews_pos_tagging_skewed = preprocessed_reviews_pos_tagging.copy()   \n",
    "preprocessed_reviews_pos_tagging_skewed['Reviewer_Score'] = preprocessed_reviews_pos_tagging_skewed['Reviewer_Score'].apply(classify_scores)\n",
    "preprocessed_reviews_pos_tagging_skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d22ab9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive    247037\n",
      "neutral     181439\n",
      "negative     87262\n",
      "Name: Reviewer_Score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# determine the counts of each category to see balance of data\n",
    "review_counts_skewed = preprocessed_reviews_pos_tagging_skewed['Reviewer_Score'].value_counts()\n",
    "print(review_counts_skewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37e5e1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when compared to the original thresholds, this is more balanced, but not much more \n",
    "# we will now explore the impact on the classification\n",
    "reviews_MNB_skewed = preprocessed_reviews_pos_tagging_skewed.copy()\n",
    "reviews_MNB_skewed['Review'] = reviews_MNB_skewed['POS_Tag'].apply(lambda tokens: ' '.join([f'{word}_{pos}' for word, pos in tokens]))\n",
    "\n",
    "#initialize the tfidf vectorizer \n",
    "vectorizer_skewed = TfidfVectorizer()\n",
    "\n",
    "# vectorize the combined POS and Text from the review text and get the score values for y\n",
    "X_skewed = vectorizer_skewed.fit_transform(reviews_MNB_skewed['Review'])\n",
    "y_skewed = reviews_MNB['Reviewer_Score']\n",
    "\n",
    "#split into test and training data\n",
    "X_train_skewed, X_test_skewed, y_train_skewed, y_test_skewed = train_test_split(X_skewed, y_skewed, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote_skewed = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "# Fit and transform the data\n",
    "X_resampled_skewed, y_resampled_skewed = smote_skewed.fit_resample(X_train_skewed, y_train_skewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ef085d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    }
   ],
   "source": [
    "# Range of alpha values to explore\n",
    "alpha_values_skewed = [0.01, 0.05, 0.1, 0.125, 0.15]\n",
    "\n",
    "# Define the paramater grid\n",
    "param_grid_skewed = {'alpha': alpha_values_skewed}\n",
    "\n",
    "# Initialize the MultinomialNB classifier\n",
    "multi_naive_bayes_skewed_smoothing = MultinomialNB()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search_skewed = GridSearchCV(multi_naive_bayes_skewed_smoothing, param_grid_skewed, cv=5)\n",
    "grid_search_skewed.fit(X_resampled_skewed, y_resampled_skewed)\n",
    "\n",
    "# show the best alpha value\n",
    "optimal_alpha_skewed = grid_search_skewed.best_params_['alpha']\n",
    "\n",
    "#print for confirmation\n",
    "print(optimal_alpha_skewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05ac5eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.17      0.46      0.25      3198\n",
      "     neutral       0.13      0.46      0.20      4981\n",
      "    positive       0.97      0.79      0.87     94969\n",
      "\n",
      "    accuracy                           0.76    103148\n",
      "   macro avg       0.43      0.57      0.44    103148\n",
      "weighted avg       0.91      0.76      0.82    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1465  1184   549]\n",
      " [ 1284  2312  1385]\n",
      " [ 5772 14203 74994]]\n",
      "Accuracy: 0.7636696785201846\n"
     ]
    }
   ],
   "source": [
    "# we will now train \n",
    "multi_naive_bayes_skewed = MultinomialNB(alpha=optimal_alpha_skewed)\n",
    "multi_naive_bayes_skewed.fit(X_resampled_skewed, y_resampled_skewed)\n",
    "\n",
    "#using the trained model, we will make predictions on the test set for final evaluation of the effectiveness \n",
    "y_predicted_skewed = multi_naive_bayes_skewed.predict(X_test_skewed)\n",
    "\n",
    "#evaluate results\n",
    "MNB_report_skewed = classification_report(y_test_skewed, y_predicted_skewed)\n",
    "MNB_confusion_matrix_skewed = confusion_matrix(y_test_skewed, y_predicted_skewed)\n",
    "MNB_accuracy_skewed = accuracy_score(y_test_skewed, y_predicted_skewed)\n",
    "\n",
    "#print the results\n",
    "print(\"Classification Report:\\n\", MNB_report_skewed)\n",
    "print(\"Confusion Matrix:\\n\", MNB_confusion_matrix_skewed)\n",
    "print(\"Accuracy:\", MNB_accuracy_skewed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a502a8",
   "metadata": {},
   "source": [
    "Even with the skewed data, the results are the same as the original with oversampling and optimized alpha, therefore, the conclusion is that in order to improve the results we may need to take further imbalance techniques or access more negative review data to further balance the data. When the data was skewed even further, the data became a bit more balanced, but it was using unreasonable thresholds and the results didn't improve all that much. This makes me think that we may want to explore better models for dealing with our data, find more data for training the model, or figure out better preprocessing techniques for this model to improve the results above 82.7%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46f9698",
   "metadata": {},
   "source": [
    "## Part 6: Exploring Random Forest Outcomes for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7104e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To start, I need to import the classifier library for Random Forest [10]\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# confirm the dataframes are still in order\n",
    "# preprocessed_reviews_pos_tagging_final\n",
    "# preprocessed_reviews_no_pos_tagging_final\n",
    "\n",
    "#Copy the data so we use a different then original version, but the same values\n",
    "#This will ensure this section has it's own data\n",
    "reviews_pos_tagging_RF = preprocessed_reviews_pos_tagging_final.copy()\n",
    "reviews_no_pos_tagging_RF = preprocessed_reviews_no_pos_tagging_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "168f4d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first I will work on the pos tagged version - turn it into strings with the tags\n",
    "reviews_pos_tagging_RF['Review'] = reviews_pos_tagging_RF['POS_Tag'].apply(lambda tokens: ' '.join([f'{word}_{pos}' for word, pos in tokens]))\n",
    "\n",
    "# next, I will vectorize the data with TF-IDF\n",
    "RF_vectorizer = TfidfVectorizer()  # Adjust max_features as needed\n",
    "X_RF = RF_vectorizer.fit_transform(reviews_pos_tagging_RF['Review'])\n",
    "y_RF = reviews_pos_tagging_RF['Reviewer_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a36f6e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to split the data for Random Forest\n",
    "X_RF_train, X_RF_test, y_RF_train, y_RF_test = train_test_split(X_RF, y_RF, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d0c24c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.03      0.05      3198\n",
      "     neutral       0.35      0.01      0.01      4981\n",
      "    positive       0.92      1.00      0.96     94969\n",
      "\n",
      "    accuracy                           0.92    103148\n",
      "   macro avg       0.65      0.34      0.34    103148\n",
      "weighted avg       0.89      0.92      0.88    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   81     6  3111]\n",
      " [   10    28  4943]\n",
      " [   27    45 94897]]\n",
      "Accuracy: 0.9210648776515299\n"
     ]
    }
   ],
   "source": [
    "#initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_RF_train, y_RF_train)\n",
    "\n",
    "# determine the predictions without any balancing techniques first to confirm if it performs well on original data\n",
    "y_RF_pred = rf_model.predict(X_RF_test)\n",
    "\n",
    "#evaluate results\n",
    "RF_report = classification_report(y_RF_test, y_RF_pred)\n",
    "RF_confusion_matrix = confusion_matrix(y_RF_test, y_RF_pred)\n",
    "RF_accuracy = accuracy_score(y_RF_test, y_RF_pred)\n",
    "\n",
    "#print the results\n",
    "print(\"Classification Report:\\n\", RF_report)\n",
    "print(\"Confusion Matrix:\\n\", RF_confusion_matrix)\n",
    "print(\"Accuracy:\", RF_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b8f10f",
   "metadata": {},
   "source": [
    "Our results are skewed still with Random Forest due to the imbalanced dataset. I will again resample the data to see if I can improve the results for the negative and neutral cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c4a6d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=90, n_estimators=80, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=90, n_estimators=80, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=90, n_estimators=80, random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to oversample, I am going to try another method called random oversampler [11][12]\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# initiate the oversampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "#create the oversampled data\n",
    "X_RF_resampled, y_RF_resampled = oversampler.fit_resample(X_RF_train, y_RF_train)\n",
    "\n",
    "# now we need to split the data for Random Forest\n",
    "X_RF_resampled, X_RF_test_resampled, y_RF_resampled, y_RF_test_resampled = train_test_split(X_RF_resampled, y_RF_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "#initialize and train the Random Forest model\n",
    "rf_model_resampled = RandomForestClassifier(n_estimators=80, max_depth=90, random_state=42)\n",
    "rf_model_resampled.fit(X_RF_resampled, y_RF_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ae5bce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94     75933\n",
      "     neutral       0.91      0.91      0.91     76009\n",
      "    positive       0.88      0.92      0.90     76382\n",
      "\n",
      "    accuracy                           0.92    228324\n",
      "   macro avg       0.92      0.92      0.92    228324\n",
      "weighted avg       0.92      0.92      0.92    228324\n",
      "\n",
      "Confusion Matrix:\n",
      " [[69543  2213  4177]\n",
      " [ 1283 69318  5408]\n",
      " [ 1768  4465 70149]]\n",
      "Accuracy: 0.9154096809796605\n"
     ]
    }
   ],
   "source": [
    "# determine the predictions without any balancing techniques first to confirm if it performs well on original data\n",
    "y_RF_pred_resampled = rf_model_resampled.predict(X_RF_test_resampled)\n",
    "\n",
    "#evaluate results\n",
    "RF_report_resampled = classification_report(y_RF_test_resampled, y_RF_pred_resampled)\n",
    "RF_confusion_matrix_resampled = confusion_matrix(y_RF_test_resampled, y_RF_pred_resampled)\n",
    "RF_accuracy_resampled = accuracy_score(y_RF_test_resampled, y_RF_pred_resampled)\n",
    "\n",
    "#print results\n",
    "print(\"Classification Report:\\n\", RF_report_resampled)\n",
    "print(\"Confusion Matrix:\\n\", RF_confusion_matrix_resampled)\n",
    "print(\"Accuracy:\", RF_accuracy_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ade819",
   "metadata": {},
   "source": [
    "Next, we will look at the case with no POS tagging, so that we can see the impact on POS tagging for RF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84c355d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no POS tags version\n",
    "#  next I will work on the no pos tagged version - turn it into strings with the tags\n",
    "reviews_no_pos_tagging_RF['Total_Review_handled'] = reviews_no_pos_tagging_RF['Total_Review_handled'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# vectorize the data with TF-IDF [13]\n",
    "RF_vectorizer_noPOS = TfidfVectorizer() \n",
    "X_RF_noPOS = RF_vectorizer_noPOS.fit_transform(reviews_no_pos_tagging_RF['Total_Review_handled'])\n",
    "y_RF_noPOS = reviews_no_pos_tagging_RF['Reviewer_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75947715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to split the data for Random Forest\n",
    "X_RF_noPOS_train, X_RF_noPOS_test, y_RF_noPOS_train, y_RF_noPOS_test = train_test_split(X_RF_noPOS, y_RF_noPOS, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f83aebbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.03      0.05      3198\n",
      "     neutral       0.37      0.01      0.01      4981\n",
      "    positive       0.92      1.00      0.96     94969\n",
      "\n",
      "    accuracy                           0.92    103148\n",
      "   macro avg       0.65      0.34      0.34    103148\n",
      "weighted avg       0.89      0.92      0.89    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   87     4  3107]\n",
      " [   15    29  4937]\n",
      " [   32    46 94891]]\n",
      "Accuracy: 0.9210745724589909\n"
     ]
    }
   ],
   "source": [
    "#initialize and train the Random Forest model\n",
    "rf_model_noPOS = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_noPOS.fit(X_RF_noPOS_train, y_RF_noPOS_train)\n",
    "\n",
    "# determine the predictions without any balancing techniques first to confirm if it performs well on original data\n",
    "y_RF_noPOS_pred = rf_model_noPOS.predict(X_RF_noPOS_test)\n",
    "\n",
    "#evaluate results\n",
    "RF_report_noPOS = classification_report(y_RF_noPOS_test, y_RF_noPOS_pred)\n",
    "RF_confusion_matrix_noPOS = confusion_matrix(y_RF_noPOS_test, y_RF_noPOS_pred)\n",
    "RF_accuracy_noPOS = accuracy_score(y_RF_noPOS_test, y_RF_noPOS_pred)\n",
    "\n",
    "#print results\n",
    "print(\"Classification Report:\\n\", RF_report_noPOS)\n",
    "print(\"Confusion Matrix:\\n\", RF_confusion_matrix_noPOS)\n",
    "print(\"Accuracy:\", RF_accuracy_noPOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6626ab5",
   "metadata": {},
   "source": [
    "The outcome of no POS tagging was similar to with POS tags. However, the imbalanced data set is not working very well on the RF model. I will try resampling this as well to see if I can improve the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82abec4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=90, n_estimators=80, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=90, n_estimators=80, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=90, n_estimators=80, random_state=42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initiate the new oversampler for no POS tags\n",
    "oversampler_noPOS = RandomOverSampler(random_state=42)\n",
    "\n",
    "#create the oversampled data\n",
    "X_RF_resampled_noPOS, y_RF_resampled_noPOS = oversampler_noPOS.fit_resample(X_RF_noPOS_train, y_RF_noPOS_train)\n",
    "\n",
    "# now we need to split the data for Random Forest\n",
    "X_RF_resampled_noPOS, X_RF_test_resampled_noPOS, y_RF_resampled_noPOS, y_RF_test_resampled_noPOS = train_test_split(X_RF_resampled_noPOS, y_RF_resampled_noPOS, test_size=0.2, random_state=42)\n",
    "\n",
    "#initialize and train the Random Forest model\n",
    "rf_model_resampled_noPOS = RandomForestClassifier(n_estimators=80, max_depth=90, random_state=42)\n",
    "rf_model_resampled_noPOS.fit(X_RF_resampled_noPOS, y_RF_resampled_noPOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c11634ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95     75933\n",
      "     neutral       0.93      0.94      0.93     76009\n",
      "    positive       0.92      0.93      0.92     76382\n",
      "\n",
      "    accuracy                           0.94    228324\n",
      "   macro avg       0.94      0.94      0.94    228324\n",
      "weighted avg       0.94      0.94      0.94    228324\n",
      "\n",
      "Confusion Matrix:\n",
      " [[71564  1467  2902]\n",
      " [ 1276 71081  3652]\n",
      " [ 1783  3641 70958]]\n",
      "Accuracy: 0.9355258317128291\n"
     ]
    }
   ],
   "source": [
    "# determine the predictions without any balancing techniques first to confirm if it performs well on original data\n",
    "y_RF_pred_resampled_noPOS = rf_model_resampled_noPOS.predict(X_RF_test_resampled_noPOS)\n",
    "\n",
    "#evaluate results\n",
    "RF_report_resampled_noPOS = classification_report(y_RF_test_resampled_noPOS, y_RF_pred_resampled_noPOS)\n",
    "RF_confusion_matrix_resampled_noPOS = confusion_matrix(y_RF_test_resampled_noPOS, y_RF_pred_resampled_noPOS)\n",
    "RF_accuracy_resampled_noPOS = accuracy_score(y_RF_test_resampled_noPOS, y_RF_pred_resampled_noPOS)\n",
    "\n",
    "#print results\n",
    "print(\"Classification Report:\\n\", RF_report_resampled_noPOS)\n",
    "print(\"Confusion Matrix:\\n\", RF_confusion_matrix_resampled_noPOS)\n",
    "print(\"Accuracy:\", RF_accuracy_resampled_noPOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c0826f",
   "metadata": {},
   "source": [
    "## Part 7: Exploring Recurrent Neural Networks (RNN) Outcomes for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ad15f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the dataframes are still in order\n",
    "# preprocessed_reviews_pos_tagging_final\n",
    "# preprocessed_reviews_no_pos_tagging_final\n",
    "\n",
    "reviews_pos_tagging_RNN = preprocessed_reviews_pos_tagging_final.copy()\n",
    "reviews_no_pos_tagging_RNN = preprocessed_reviews_no_pos_tagging_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74b3716f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.13.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.24.2)\n",
      "Requirement already satisfied: setuptools in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (67.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: keras in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (2.13.1)\n"
     ]
    }
   ],
   "source": [
    "# for this type of model I will use TensorFlow and Keras \n",
    "\n",
    "#install the deep learning framework Tensor Flow and library Keras [14][15]\n",
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a0ae4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to use a Recurrent Neural Network (RNN), we need to do a bit more processing on the data to format it the way it is needed for input\n",
    "# This includes, seperating the words and the POS tags, adding padding to get the length consistent, and\n",
    "# creating embeddings for the data, then splitting into test and train datasets for the model. \n",
    "\n",
    "#first I will import all the libraries needed for this model - I will use different tokenizers than previously\n",
    "#to show capabilities with different technologies\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Bidirectional, LSTM, GRU, Dense #[16][17]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "#with an RNN the scores can not be text - they need to be numbers - will encode these now\n",
    "label_encoder_RNN = LabelEncoder()\n",
    "encoded_scores_RNN = label_encoder_RNN.fit_transform(reviews_pos_tagging_RNN[\"Reviewer_Score\"])\n",
    "\n",
    "# get the text and POS data\n",
    "review_RNN = reviews_pos_tagging_RNN[\"POS_Tag\"]\n",
    "\n",
    "# prepare the text and POS data for RNN usage\n",
    "tokenizer_RNN = Tokenizer()\n",
    "tokenizer_RNN.fit_on_texts([\" \".join([rev for rev, _ in seq]) for seq in review_RNN])\n",
    "sequences_RNN = tokenizer_RNN.texts_to_sequences([\" \".join([rev for rev, _ in seq]) for seq in review_RNN])\n",
    "review_prepped_RNN = pad_sequences(sequences_RNN, maxlen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1a6536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the test and train datasets\n",
    "X_train_RNN, X_test_RNN, y_train_RNN, y_test_RNN = train_test_split(review_prepped_RNN, encoded_scores_RNN, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# I will oversample the data as the minority class is not being recognized well\n",
    "# this was shown by training the model without any additional fine tuning and just the regular preprocessing. \n",
    "# smote_RNN = SMOTE(random_state=42)\n",
    "# X_train_RNN_resampled, y_train_RNN_resampled = smote_RNN.fit_resample(X_train_RNN, y_train_RNN)\n",
    "\n",
    "#adjust the class weights - it ended up overfitting the data so I will not use this technique [18]\n",
    "# Compute class weights for balancing the dataset - this will increase the weight for the minority classes\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_RNN), y=y_train_RNN)\n",
    "# Convert class weights to a dictionary for use in the model\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "# next we will manually apply class weights to the training data\n",
    "sample_weights = np.array([class_weights_dict[y] for y in y_train_RNN])\n",
    "\n",
    "\n",
    "#now that I have prepared the data, I can initiate the model\n",
    "model_RNN = Sequential()\n",
    "model_RNN.add(Embedding(input_dim=len(tokenizer_RNN.word_index) + 1, output_dim=128, input_length=10))\n",
    "model_RNN.add(Bidirectional(LSTM(128)))\n",
    "model_RNN.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model with the updated class weights\n",
    "model_RNN.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    "    weighted_metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c65bc517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5158/5158 [==============================] - 109s 21ms/step - loss: 0.8290 - accuracy: 0.7266 - weighted_accuracy: 0.5931 - val_loss: 0.8141 - val_accuracy: 0.7259 - val_weighted_accuracy: 0.6066\n",
      "Epoch 2/5\n",
      "5158/5158 [==============================] - 110s 21ms/step - loss: 0.7297 - accuracy: 0.7631 - weighted_accuracy: 0.6624 - val_loss: 0.8236 - val_accuracy: 0.7513 - val_weighted_accuracy: 0.6073\n",
      "Epoch 3/5\n",
      "5158/5158 [==============================] - 110s 21ms/step - loss: 0.6414 - accuracy: 0.7848 - weighted_accuracy: 0.7185 - val_loss: 0.8951 - val_accuracy: 0.7717 - val_weighted_accuracy: 0.5919\n",
      "Epoch 4/5\n",
      "5158/5158 [==============================] - 109s 21ms/step - loss: 0.5428 - accuracy: 0.8059 - weighted_accuracy: 0.7706 - val_loss: 1.0084 - val_accuracy: 0.7388 - val_weighted_accuracy: 0.5890\n",
      "Epoch 5/5\n",
      "5158/5158 [==============================] - 110s 21ms/step - loss: 0.4460 - accuracy: 0.8261 - weighted_accuracy: 0.8181 - val_loss: 1.1969 - val_accuracy: 0.7708 - val_weighted_accuracy: 0.5764\n",
      "3224/3224 [==============================] - 7s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#now I will train the model and make predictions\n",
    "model_RNN.fit(X_train_RNN, y_train_RNN, epochs=5, batch_size=64, validation_split=0.2, sample_weight=sample_weights)\n",
    "pred_RNN = model_RNN.predict(X_test_RNN)\n",
    "\n",
    "# convert back to positive, negative, or neutral\n",
    "pred_RNN_converted_back = label_encoder_RNN.inverse_transform(pred_RNN.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f5d4c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.53      0.28      3198\n",
      "           1       0.13      0.43      0.20      4981\n",
      "           2       0.98      0.80      0.88     94969\n",
      "\n",
      "    accuracy                           0.77    103148\n",
      "   macro avg       0.43      0.58      0.45    103148\n",
      "weighted avg       0.91      0.77      0.83    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1679  1056   463]\n",
      " [ 1455  2142  1384]\n",
      " [ 5721 13694 75554]]\n",
      "Accuracy: 0.7695253422267033\n"
     ]
    }
   ],
   "source": [
    "#classification metrics didnt work out as we are getting probabilities of each classification from the model\n",
    "#to fix this, we will convert it to the predicted outcome using numpy [19]\n",
    "pred_RNN_converted = np.argmax(pred_RNN, axis=1)\n",
    "\n",
    "#evaluate results from the RNN\n",
    "RNN_report_POS = classification_report(y_test_RNN, pred_RNN_converted)\n",
    "RNN_confusion_matrix_POS = confusion_matrix(y_test_RNN, pred_RNN_converted)\n",
    "RNN_accuracy_POS = accuracy_score(y_test_RNN, pred_RNN_converted)\n",
    "\n",
    "#print the results\n",
    "print(\"Classification Report:\\n\", RNN_report_POS)\n",
    "print(\"Confusion Matrix:\\n\", RNN_confusion_matrix_POS)\n",
    "print(\"Accuracy:\", RNN_accuracy_POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6044e0ed",
   "metadata": {},
   "source": [
    "Using POS tags in the preprocessed data, we get an accuracy of 91.9%. This is good, but the Random Forest model still outperformed the RNN with this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca627cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, I will use the RNN model for the no_POS tag scenario. \n",
    "#with an RNN the scores can not be text - they need to be numbers - will encode these now\n",
    "label_encoder_RNN_no_POS = LabelEncoder()\n",
    "encoded_scores_RNN_no_POS = label_encoder_RNN_no_POS.fit_transform(reviews_no_pos_tagging_RNN[\"Reviewer_Score\"])\n",
    "\n",
    "# get the review text data\n",
    "review_RNN_no_POS = reviews_no_pos_tagging_RNN[\"Total_Review_handled\"]\n",
    "\n",
    "# prepare the review text data for RNN usage\n",
    "tokenizer_RNN_noPOS = Tokenizer()\n",
    "tokenizer_RNN_noPOS.fit_on_texts(review_RNN_no_POS)\n",
    "review_prepped_RNN_noPOS = tokenizer_RNN_noPOS.texts_to_sequences(review_RNN_no_POS)\n",
    "\n",
    "# pad the text with a set length - used 10 previously so will use it again\n",
    "review_prepped_RNN_noPOS_padded = pad_sequences(review_prepped_RNN_noPOS, maxlen=10)\n",
    "\n",
    "#split the data into train and test sets\n",
    "X_train_RNN_noPOS, X_test_RNN_noPOS, y_train_RNN_noPOS, y_test_RNN_noPOS = train_test_split(review_prepped_RNN_noPOS_padded, encoded_scores_RNN_no_POS, test_size=0.2, random_state=42)\n",
    "\n",
    "# I will oversample the data as the minority class is not being recognized well\n",
    "# this was shown by training the model without any additional fine tuning and just the regular preprocessing. \n",
    "# smote_RNN_noPOS = SMOTE(random_state=42)\n",
    "# X_train_RNN_resampled_noPOS, y_train_RNN_resampled_noPOS = smote_RNN_noPOS.fit_resample(X_train_RNN_noPOS, y_train_RNN_noPOS)\n",
    "\n",
    "#adjust the class weights\n",
    "# Compute class weights for balancing the dataset - this will increase the weight for the minority classes\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_RNN_noPOS), y=y_train_RNN_noPOS)\n",
    "# Convert class weights to a dictionary for use in the model\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "# next we will manually apply class weights to the training data\n",
    "sample_weights = np.array([class_weights_dict[y] for y in y_train_RNN_noPOS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7565a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next I will train the new RNN model for noPOS\n",
    "#initiate\n",
    "model_RNN_noPOS = Sequential()\n",
    "model_RNN_noPOS.add(Embedding(input_dim=len(tokenizer_RNN_noPOS.word_index) + 1, output_dim=128, input_length=10))\n",
    "model_RNN_noPOS.add(Bidirectional(LSTM(128)))\n",
    "model_RNN_noPOS.add(Dense(3, activation='softmax'))  # 3 classes for \"positive,\" \"negative,\" and \"neutral\"\n",
    "\n",
    "# Compile the model with the updated class weights\n",
    "model_RNN_noPOS.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    "    weighted_metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9808bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5158/5158 [==============================] - 110s 21ms/step - loss: 0.8294 - accuracy: 0.7313 - weighted_accuracy: 0.5980 - val_loss: 0.8137 - val_accuracy: 0.7233 - val_weighted_accuracy: 0.6079\n",
      "Epoch 2/5\n",
      "5158/5158 [==============================] - 108s 21ms/step - loss: 0.7302 - accuracy: 0.7642 - weighted_accuracy: 0.6630 - val_loss: 0.8322 - val_accuracy: 0.7707 - val_weighted_accuracy: 0.6067\n",
      "Epoch 3/5\n",
      "5158/5158 [==============================] - 109s 21ms/step - loss: 0.6403 - accuracy: 0.7868 - weighted_accuracy: 0.7193 - val_loss: 0.8924 - val_accuracy: 0.7430 - val_weighted_accuracy: 0.5976\n",
      "Epoch 4/5\n",
      "5158/5158 [==============================] - 109s 21ms/step - loss: 0.5388 - accuracy: 0.8086 - weighted_accuracy: 0.7732 - val_loss: 1.0328 - val_accuracy: 0.7515 - val_weighted_accuracy: 0.5876\n",
      "Epoch 5/5\n",
      "5158/5158 [==============================] - 109s 21ms/step - loss: 0.4396 - accuracy: 0.8296 - weighted_accuracy: 0.8191 - val_loss: 1.1830 - val_accuracy: 0.7806 - val_weighted_accuracy: 0.5742\n",
      "3224/3224 [==============================] - 7s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#now I will train the model and make predictions\n",
    "model_RNN_noPOS.fit(X_train_RNN_noPOS, y_train_RNN_noPOS, epochs=5, batch_size=64, validation_split=0.2, sample_weight=sample_weights)\n",
    "pred_RNN_noPOS = model_RNN_noPOS.predict(X_test_RNN_noPOS)\n",
    "\n",
    "# convert back to positive, negative, or neutral\n",
    "pred_RNN_noPOS_converted_back = label_encoder_RNN_no_POS.inverse_transform(pred_RNN_noPOS.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af2c1b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.53      0.27      3198\n",
      "           1       0.13      0.41      0.20      4981\n",
      "           2       0.98      0.81      0.88     94969\n",
      "\n",
      "    accuracy                           0.78    103148\n",
      "   macro avg       0.43      0.58      0.45    103148\n",
      "weighted avg       0.91      0.78      0.83    103148\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1693  1036   469]\n",
      " [ 1556  2018  1407]\n",
      " [ 6234 11940 76795]]\n",
      "Accuracy: 0.7804901694652344\n"
     ]
    }
   ],
   "source": [
    "#classification metrics didnt work out as we are getting probabilities of each classification from the model\n",
    "#to fix this, we will convert it to the predicted outcome using numpy\n",
    "pred_RNN_noPOS_converted = np.argmax(pred_RNN_noPOS, axis=1)\n",
    "\n",
    "#evaluate results from the RNN\n",
    "RNN_report_noPOS = classification_report(y_test_RNN_noPOS, pred_RNN_noPOS_converted)\n",
    "RNN_confusion_matrix_noPOS = confusion_matrix(y_test_RNN_noPOS, pred_RNN_noPOS_converted)\n",
    "RNN_accuracy_noPOS = accuracy_score(y_test_RNN_noPOS, pred_RNN_noPOS_converted)\n",
    "\n",
    "#print the results\n",
    "print(\"Classification Report:\\n\", RNN_report_noPOS)\n",
    "print(\"Confusion Matrix:\\n\", RNN_confusion_matrix_noPOS)\n",
    "print(\"Accuracy:\", RNN_accuracy_noPOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c681368",
   "metadata": {},
   "source": [
    "While the POS tagged data performed better, the results were still slightly less than the Random Forest model. While they are very similar, it seems the Random Forest model with no POS tagging in the preprocessed data performed the best out of all three models tested (Multinomial Naive Bayes, Random Forest, and a Recurrent Neural Network (RNN). It is possible that with further fine tuning some of these models can be improved even further, however, I will proceed with using the best model found through this exploratory exercise for the development of the sentiment analysis tool for Short-Term Rental reviews. \n",
    "\n",
    "The summary of all the results is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25dafa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Results:\n",
      "\n",
      "Classification Report Multinomial Naive Bayes - POS Tags:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.20      0.65      0.30      3198\n",
      "     neutral       0.17      0.30      0.22      4981\n",
      "    positive       0.97      0.86      0.91     94969\n",
      "\n",
      "    accuracy                           0.83    103148\n",
      "   macro avg       0.45      0.60      0.48    103148\n",
      "weighted avg       0.91      0.83      0.86    103148\n",
      "\n",
      "Confusion Matrix Multinomial Naive Bayes - POS Tags:\n",
      " [[ 2065   615   518]\n",
      " [ 1855  1476  1650]\n",
      " [ 6654  6452 81863]]\n",
      "Accuracy Multinomial Naive Bayes - POS Tags:\n",
      " 0.8279753364098189\n",
      "\n",
      "\n",
      "\n",
      "Classification Report Multinomial Naive Bayes - no POS Tags:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.20      0.63      0.30      3198\n",
      "     neutral       0.17      0.33      0.23      4981\n",
      "    positive       0.98      0.86      0.91     94969\n",
      "\n",
      "    accuracy                           0.82    103148\n",
      "   macro avg       0.45      0.61      0.48    103148\n",
      "weighted avg       0.91      0.82      0.86    103148\n",
      "\n",
      "Confusion Matrix Multinomial Naive Bayes - no POS Tags:\n",
      " [[ 2014   694   490]\n",
      " [ 1773  1654  1554]\n",
      " [ 6440  7275 81254]]\n",
      "Accuracy Multinomial Naive Bayes - no POS Tags:\n",
      " 0.8233024392135572\n",
      "\n",
      "\n",
      "\n",
      "Random Forest Results:\n",
      "\n",
      "Classification Report Random Forest - POS Tags:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94     75933\n",
      "     neutral       0.91      0.91      0.91     76009\n",
      "    positive       0.88      0.92      0.90     76382\n",
      "\n",
      "    accuracy                           0.92    228324\n",
      "   macro avg       0.92      0.92      0.92    228324\n",
      "weighted avg       0.92      0.92      0.92    228324\n",
      "\n",
      "Confusion Matrix Random Forest - POS Tags:\n",
      " [[69543  2213  4177]\n",
      " [ 1283 69318  5408]\n",
      " [ 1768  4465 70149]]\n",
      "Accuracy Random Forest - POS Tags:\n",
      " 0.9154096809796605\n",
      "\n",
      "\n",
      "\n",
      "Classification Report Random Forest - no POS Tags:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95     75933\n",
      "     neutral       0.93      0.94      0.93     76009\n",
      "    positive       0.92      0.93      0.92     76382\n",
      "\n",
      "    accuracy                           0.94    228324\n",
      "   macro avg       0.94      0.94      0.94    228324\n",
      "weighted avg       0.94      0.94      0.94    228324\n",
      "\n",
      "Confusion Matrix Random Forest - no POS Tags:\n",
      " [[71564  1467  2902]\n",
      " [ 1276 71081  3652]\n",
      " [ 1783  3641 70958]]\n",
      "Accuracy Random Forest - no POS Tags:\n",
      " 0.9355258317128291\n",
      "\n",
      "\n",
      "\n",
      "Recurrent Neural Network RNN Results:\n",
      "\n",
      "Classification Report Recurrent Neural Network RNN - POS Tags:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.53      0.28      3198\n",
      "           1       0.13      0.43      0.20      4981\n",
      "           2       0.98      0.80      0.88     94969\n",
      "\n",
      "    accuracy                           0.77    103148\n",
      "   macro avg       0.43      0.58      0.45    103148\n",
      "weighted avg       0.91      0.77      0.83    103148\n",
      "\n",
      "Confusion Matrix Recurrent Neural Network RNN - POS Tags:\n",
      " [[ 1679  1056   463]\n",
      " [ 1455  2142  1384]\n",
      " [ 5721 13694 75554]]\n",
      "Accuracy Recurrent Neural Network RNN - POS Tags:\n",
      " 0.7695253422267033\n",
      "\n",
      "\n",
      "\n",
      "Classification Report Recurrent Neural Network RNN - no POS Tags:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.53      0.27      3198\n",
      "           1       0.13      0.41      0.20      4981\n",
      "           2       0.98      0.81      0.88     94969\n",
      "\n",
      "    accuracy                           0.78    103148\n",
      "   macro avg       0.43      0.58      0.45    103148\n",
      "weighted avg       0.91      0.78      0.83    103148\n",
      "\n",
      "Confusion Matrix Recurrent Neural Network RNN - no POS Tags:\n",
      " [[ 1693  1036   469]\n",
      " [ 1556  2018  1407]\n",
      " [ 6234 11940 76795]]\n",
      "Accuracy Recurrent Neural Network RNN - no POS Tags:\n",
      " 0.7804901694652344\n"
     ]
    }
   ],
   "source": [
    "print(\"Multinomial Naive Bayes Results:\\n\")\n",
    "\n",
    "print(\"Classification Report Multinomial Naive Bayes - POS Tags:\\n\", MNB_postag_report_optimized_smoothing_oversampled)\n",
    "print(\"Confusion Matrix Multinomial Naive Bayes - POS Tags:\\n\", MNB_postag_confusion_matrix_optimized_smoothing_oversampled)\n",
    "print(\"Accuracy Multinomial Naive Bayes - POS Tags:\\n\", MNB_postag_accuracy_optimized_smoothing_oversampled)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"Classification Report Multinomial Naive Bayes - no POS Tags:\\n\", MNB_report_optimized_smoothing)\n",
    "print(\"Confusion Matrix Multinomial Naive Bayes - no POS Tags:\\n\", MNB_confusion_matrix_optimized_smoothing)\n",
    "print(\"Accuracy Multinomial Naive Bayes - no POS Tags:\\n\", MNB_accuracy_optimized_smoothing)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"Random Forest Results:\\n\")\n",
    "\n",
    "print(\"Classification Report Random Forest - POS Tags:\\n\", RF_report_resampled)\n",
    "print(\"Confusion Matrix Random Forest - POS Tags:\\n\", RF_confusion_matrix_resampled)\n",
    "print(\"Accuracy Random Forest - POS Tags:\\n\", RF_accuracy_resampled)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"Classification Report Random Forest - no POS Tags:\\n\", RF_report_resampled_noPOS)\n",
    "print(\"Confusion Matrix Random Forest - no POS Tags:\\n\", RF_confusion_matrix_resampled_noPOS)\n",
    "print(\"Accuracy Random Forest - no POS Tags:\\n\", RF_accuracy_resampled_noPOS)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"Recurrent Neural Network RNN Results:\\n\")\n",
    "\n",
    "print(\"Classification Report Recurrent Neural Network RNN - POS Tags:\\n\", RNN_report_POS)\n",
    "print(\"Confusion Matrix Recurrent Neural Network RNN - POS Tags:\\n\", RNN_confusion_matrix_POS)\n",
    "print(\"Accuracy Recurrent Neural Network RNN - POS Tags:\\n\", RNN_accuracy_POS)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"Classification Report Recurrent Neural Network RNN - no POS Tags:\\n\", RNN_report_noPOS)\n",
    "print(\"Confusion Matrix Recurrent Neural Network RNN - no POS Tags:\\n\", RNN_confusion_matrix_noPOS)\n",
    "print(\"Accuracy Recurrent Neural Network RNN - no POS Tags:\\n\", RNN_accuracy_noPOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cddb167",
   "metadata": {},
   "source": [
    "As can be seen in the summary, my above statement is confirmed: The best results were using Random Forest without the POS tags in the dataset. This will be the model I use for sentiment analysis with Short-Term Rental Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4d2533",
   "metadata": {},
   "source": [
    "## Part 8: Scraping Reviews to Get New Data From a Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02a74f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: selenium in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (4.12.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/coreyreid/anaconda3/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "#ensure libraries are installed for scraping needs [20][21]\n",
    "!pip install beautifulsoup4\n",
    "!pip install --upgrade selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f27a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a0333ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, I need to specify the driver path for the web driver for Selenium to work\n",
    "#set up selenium webdriver [21]\n",
    "service = Service('/Users/coreyreid/Documents/Final Project/Final Project - Implementation & Evaluation/chromedriver')\n",
    "options = webdriver.ChromeOptions()\n",
    "#options.add_argument('--headless') #to make it headless and not run the chrome instance\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "#example website to use for the scraping\n",
    "url = \"https://www.mainecottagekeepers.com/2-beautiful-water-view-properties-in-1-for-extended-families-orp5b4a2abx\"\n",
    "driver.get(url)\n",
    "\n",
    "# delay as needed\n",
    "time.sleep(10)  \n",
    "\n",
    "# Switch to the iframe containing the reviews - need to switch the focus into the iframe\n",
    "iframe = driver.find_element(By.CSS_SELECTOR, 'div.ownerrez-widget[data-widgetid=\"dc0c1ee92566447e81ba5e68a8a2ac1a\"] iframe')\n",
    "driver.switch_to.frame(iframe)\n",
    "\n",
    "# delay as needed\n",
    "time.sleep(10)  \n",
    "\n",
    "# Extract the HTML content\n",
    "html = driver.page_source\n",
    "\n",
    "# now, I will scrape the website to expose the review content\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "review_elements = soup.find_all('div', class_='review-item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb697403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The title of the review is: \n",
      "The review content is: A big thank you from us to be able to stay in this wonderful place in order to be with our family during the Lobstah fest.  We drove from Florida to see our Massachusetts family as we gathered in Maine to welcome our Grandson from the ship that anchored in Rockland for the Festival.  We loved being able to see him as he did us.  We felt at home in this Airbnb as we gathered at the fire pit and the deck table for meals. We did several meals at the Dip Net too.  Great food and very close to house.This house is very well equipped, clean, and is an old farmhouse with a lot of Character.We did host an Airbnb on the Cape at one time and know that Shawn-Elise deserves a 5 star rating to become a super host if she is not already.Would we come again?  You Bet.Sharyn\n",
      "---------------------------------\n",
      "The title of the review is: \n",
      "The review content is: Great stay. Just didn’t understand why they took 500 for a security deposit\n",
      "---------------------------------\n",
      "The title of the review is: \n",
      "The review content is: The place is absolutely beautiful and there was plenty of room for all 10 f us to sleep. The houses are just a short drive from a bunch of cool spots. Highly recommend!\n",
      "---------------------------------\n",
      "The title of the review is: A peace of heaven with 10 family members\n",
      "The review content is: We enjoyed the peace and quit of this lovely 2 home farm house.My family of 10  celebrated a wonderful 1 night get together.  For myBrother-in-law 60th birthday dinner and we flew in from all over .We all enjoyed the large outdoor eating area .And then in the evening we made s’mores at the fire pit and just watched the beautiful  Stars. we all had a private area to go to get away if we needed .the beds were  very comfortable So if you want to enjoy everyone under one roof…Book this ASAP because it  will be a wonderful place to make family or friends memories Sincerely Audrey & Douglas and family\n",
      "---------------------------------\n",
      "The title of the review is: \n",
      "The review content is: It was a very charming Home\n",
      "---------------------------------\n",
      "The title of the review is: Large, well located summer rental\n",
      "The review content is: Our 3 families enjoyed our 5 nights on this well located property. The kids had their own ‘lofted apartment’ and enjoyed their independence. The house is located near Drift In Beach and Clark Island and Port Clyde Harbor.The beds were all wonderfully comfortable and everyone slept well. This property is right on RT. 131, which is the main thoroughfare for traffic going to Port Vlyde Harbor. It can be a bit noisy at night, but each time was provided with a fan which blocked the noise well. I would definitely recommend this rental for large groups and the hosts were always available for questions.\n",
      "---------------------------------\n",
      "The title of the review is: Large, well located summer rental\n",
      "The review content is: Our 3 families enjoyed our 5 nights on this well located property. The kids had their own ‘lofted apartment’ and enjoyed their independence. The house is located near Drift In Beach and Clark Island and Port Clyde Harbor.The beds were all wonderfully comfortable and everyone slept well. This property is right on RT. 131, which is the main thoroughfare for traffic going to Port Vlyde Harbor. It can be a bit noisy at night, but each time was provided with a fan which blocked the noise well. I would definitely recommend this rental for large groups and the hosts were always available for questions.\n",
      "---------------------------------\n",
      "The title of the review is: \n",
      "The review content is: We had a wonderful time, the house was very clean and the grass was freshly mowed. We really enjoyed our stay and all their recommendations for local activities!\n",
      "---------------------------------\n",
      "The title of the review is: \n",
      "The review content is: The house and loft were clean and staying there was comfortable.\n",
      "---------------------------------\n",
      "The title of the review is: \n",
      "The review content is: Excellent hosts\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "#now that we have isolated the html element that matters, we will want to go through all the reviews\n",
    "#and collect just the relevant text\n",
    "#initialize\n",
    "real_reviews = []\n",
    "\n",
    "#loop through the review elements\n",
    "for review in review_elements:\n",
    "    # Scrape the review title text\n",
    "    review_title = review.find(\"span\", class_=\"review-item-title\").strong\n",
    "    # Scrape the review body text\n",
    "    review_body = review.find(\"div\", class_=\"has-read-more\").text.strip()\n",
    "    #check that a review exists\n",
    "    if review_title and review_body:\n",
    "        #get review title text \n",
    "        review_title_text = review_title.text.strip()\n",
    "        #get review body text\n",
    "        review_body_text = review_body\n",
    "        # put the data in a dataframe\n",
    "                # Append the scraped data as a dictionary to the 'data' list\n",
    "        real_reviews.append(\n",
    "            review_body_text\n",
    "        )\n",
    "        #print the details through the loop\n",
    "        print(\"The title of the review is:\", review_title_text)\n",
    "        print(\"The review content is:\", review_body_text)\n",
    "        print(\"---------------------------------\")\n",
    "    else:\n",
    "        #error handling\n",
    "        print(\"There is no review title or text.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73f5edf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A big thank you from us to be able to stay in this wonderful place in order to be with our family during the Lobstah fest.\\xa0 We drove from Florida to see our Massachusetts family as we gathered in Maine to welcome our Grandson from the ship that anchored in Rockland for the Festival.\\xa0 We loved being able to see him as he did us.\\xa0 We felt at home in this Airbnb as we gathered at the fire pit and the deck table for meals. We did several meals at the Dip Net too.\\xa0 Great food and very close to house.This house is very well equipped, clean, and is an old farmhouse with a lot of Character.We did host an Airbnb on the Cape at one time and know that Shawn-Elise deserves a 5 star rating to become a super host if she is not already.Would we come again?\\xa0 You Bet.Sharyn',\n",
       " 'Great stay. Just didn’t understand why they took 500 for a security deposit',\n",
       " 'The place is absolutely beautiful and there was plenty of room for all 10 f us to sleep. The houses are just a short drive from a bunch of cool spots. Highly recommend!',\n",
       " 'We enjoyed the peace and quit of this lovely 2 home farm house.My family of 10\\xa0 celebrated a wonderful 1 night get together.\\xa0 For myBrother-in-law 60th birthday dinner and we flew in from all over .We all enjoyed the large outdoor eating area .And then in the evening we made s’mores at the fire pit and just watched the beautiful\\xa0 Stars. we all had a private area to go to get away if we needed .the beds were\\xa0 very comfortable So if you want to enjoy everyone under one roof…Book this ASAP because it\\xa0 will be a wonderful place to make family or friends memories Sincerely Audrey & Douglas and family',\n",
       " 'It was a very charming Home',\n",
       " 'Our 3 families enjoyed our 5 nights on this well located property. The kids had their own ‘lofted apartment’ and enjoyed their independence. The house is located near Drift In Beach and Clark Island and Port Clyde Harbor.The beds were all wonderfully comfortable and everyone slept well. This property is right on RT. 131, which is the main thoroughfare for traffic going to Port Vlyde Harbor. It can be a bit noisy at night, but each time was provided with a fan which blocked the noise well. I would definitely recommend this rental for large groups and the hosts were always available for questions.',\n",
       " 'Our 3 families enjoyed our 5 nights on this well located property. The kids had their own ‘lofted apartment’ and enjoyed their independence. The house is located near Drift In Beach and Clark Island and Port Clyde Harbor.The beds were all wonderfully comfortable and everyone slept well. This property is right on RT. 131, which is the main thoroughfare for traffic going to Port Vlyde Harbor. It can be a bit noisy at night, but each time was provided with a fan which blocked the noise well. I would definitely recommend this rental for large groups and the hosts were always available for questions.',\n",
       " 'We had a wonderful time, the house was very clean and the grass was freshly mowed. We really enjoyed our stay and all their recommendations for local activities!',\n",
       " 'The house and loft were clean and staying there was comfortable.',\n",
       " 'Excellent hosts']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the way the data is structured by looking at the output\n",
    "real_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5888e427",
   "metadata": {},
   "source": [
    "## Part 9: Testing on Real Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb65b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to scale the preprocessing to be able to be used with new reviews, I need to generalize the \n",
    "# preprocessing function - I will do that now for the one with no POS tagging\n",
    "\n",
    "def preprocess_no_pos(review):\n",
    "    \n",
    "    #remove special characters and ensure lowercase\n",
    "    def preprocess_remove_special(review):\n",
    "        review_handled = re.sub(r'[^a-zA-Z\\s]', '', review)\n",
    "        review_lower = review_handled.lower()\n",
    "        return review_lower\n",
    "\n",
    "    #tokenize\n",
    "    def preprocess_tokenize(review):\n",
    "        bag_of_words = word_tokenize(review)\n",
    "        return bag_of_words\n",
    "\n",
    "    #remove stopwords\n",
    "    def preprocess_stopwords(review):\n",
    "        words = stopwords.words('english')\n",
    "        set_stop_words = set(words)\n",
    "        removed_stopwords_words = []\n",
    "        for word in review:\n",
    "            if word not in set_stop_words:\n",
    "                removed_stopwords_words.append(word)\n",
    "        return removed_stopwords_words\n",
    "\n",
    "    #lemmatize\n",
    "    def preprocess_lemmatize(review):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized_review = [lemmatizer.lemmatize(word) for word in review ]\n",
    "        return lemmatized_review\n",
    "\n",
    "    # Apply the preprocessing steps\n",
    "    review = preprocess_remove_special(review)\n",
    "    review = preprocess_tokenize(review)\n",
    "    review = preprocess_stopwords(review)\n",
    "    review = preprocess_lemmatize(review)\n",
    "\n",
    "    # Join the tokens back into a single string\n",
    "    preprocessed_review = ' '.join(review)\n",
    "\n",
    "    #return the preprocessed reviews\n",
    "    return preprocessed_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "283808fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, I will preprocess using this function and looping through all the reviews\n",
    "real_reviews_processed = [preprocess_no_pos(review) for review in real_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cdf1f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with this data, I now need to transform it to be used in the model\n",
    "X_new_reviews = vectorizer_noPOS.transform(real_reviews_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c365f425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the sentiment of the reviews\n",
    "real_review_predictions = multi_naive_bayes_optimized_smoothing_noPOS.predict(X_new_reviews)\n",
    "\n",
    "real_review_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3d225040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A big thank you from us to be able to stay in this wonderful place in order to be with our family during the Lobstah fest.\\xa0 We drove from Florida to see our Massachusetts family as we gathered in Maine to welcome our Grandson from the ship that anchored in Rockland for the Festival.\\xa0 We loved being able to see him as he did us.\\xa0 We felt at home in this Airbnb as we gathered at the fire pit and the deck table for meals. We did several meals at the Dip Net too.\\xa0 Great food and very close to house.This house is very well equipped, clean, and is an old farmhouse with a lot of Character.We did host an Airbnb on the Cape at one time and know that Shawn-Elise deserves a 5 star rating to become a super host if she is not already.Would we come again?\\xa0 You Bet.Sharyn',\n",
       " 'Great stay. Just didn’t understand why they took 500 for a security deposit',\n",
       " 'The place is absolutely beautiful and there was plenty of room for all 10 f us to sleep. The houses are just a short drive from a bunch of cool spots. Highly recommend!',\n",
       " 'We enjoyed the peace and quit of this lovely 2 home farm house.My family of 10\\xa0 celebrated a wonderful 1 night get together.\\xa0 For myBrother-in-law 60th birthday dinner and we flew in from all over .We all enjoyed the large outdoor eating area .And then in the evening we made s’mores at the fire pit and just watched the beautiful\\xa0 Stars. we all had a private area to go to get away if we needed .the beds were\\xa0 very comfortable So if you want to enjoy everyone under one roof…Book this ASAP because it\\xa0 will be a wonderful place to make family or friends memories Sincerely Audrey & Douglas and family',\n",
       " 'It was a very charming Home',\n",
       " 'Our 3 families enjoyed our 5 nights on this well located property. The kids had their own ‘lofted apartment’ and enjoyed their independence. The house is located near Drift In Beach and Clark Island and Port Clyde Harbor.The beds were all wonderfully comfortable and everyone slept well. This property is right on RT. 131, which is the main thoroughfare for traffic going to Port Vlyde Harbor. It can be a bit noisy at night, but each time was provided with a fan which blocked the noise well. I would definitely recommend this rental for large groups and the hosts were always available for questions.',\n",
       " 'Our 3 families enjoyed our 5 nights on this well located property. The kids had their own ‘lofted apartment’ and enjoyed their independence. The house is located near Drift In Beach and Clark Island and Port Clyde Harbor.The beds were all wonderfully comfortable and everyone slept well. This property is right on RT. 131, which is the main thoroughfare for traffic going to Port Vlyde Harbor. It can be a bit noisy at night, but each time was provided with a fan which blocked the noise well. I would definitely recommend this rental for large groups and the hosts were always available for questions.',\n",
       " 'We had a wonderful time, the house was very clean and the grass was freshly mowed. We really enjoyed our stay and all their recommendations for local activities!',\n",
       " 'The house and loft were clean and staying there was comfortable.',\n",
       " 'Excellent hosts',\n",
       " 'Awful',\n",
       " 'It was a bad rental unit and was very ugly. The ammenities were all broken.',\n",
       " 'I will never return to this or recommend it to anyone - it was a horrible rental and it ruined my holiday.']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turns out they are all positive, which when you look above you can see is the case - this will happen \n",
    "# from time to time. I will manually add data to the reviews data to put in a few negative reviews for further \n",
    "# testing - this will confirm the model is working properly\n",
    "\n",
    "updated_real_reviews = real_reviews.copy()\n",
    "\n",
    "updated_real_reviews.extend(['Awful', 'It was a bad rental unit and was very ugly. The ammenities were all broken.', 'I will never return to this or recommend it to anyone - it was a horrible rental and it ruined my holiday.'])\n",
    "\n",
    "updated_real_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e65dc714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'negative', 'negative'], dtype='<U8')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next, I will test this set with Multinomial Naive Bayes with no POS tags\n",
    "# to start I will preprocess the data using this function and looping through all the reviews\n",
    "updated_real_reviews_processed = [preprocess_no_pos(review) for review in updated_real_reviews]\n",
    "\n",
    "# with this data, I now need to transform it to be used in the model\n",
    "X_updated_real_reviews = vectorizer_noPOS.transform(updated_real_reviews_processed)\n",
    "\n",
    "# predict the sentiment of the reviews - we will use the no POS tagging version as it performed slightly better\n",
    "#than the POS tagging scenario\n",
    "updated_real_reviews_predictions = multi_naive_bayes_optimized_smoothing_noPOS.predict(X_updated_real_reviews)\n",
    "\n",
    "#show the results\n",
    "updated_real_reviews_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "51ce481c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'negative', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the RF model - it was seen that the no POS tagging scenario always performed a bit better than with tags.\n",
    "# we will test the model on real data - the data is already processed above\n",
    "\n",
    "# predict the sentiment of the reviews\n",
    "updated_real_reviews_predictions = rf_model_resampled_noPOS.predict(X_updated_real_reviews)\n",
    "\n",
    "#show the results\n",
    "updated_real_reviews_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5eab739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive', 'positive', 'positive', 'neutral',\n",
       "       'negative', 'negative', 'positive', 'neutral', 'neutral'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#last I will test the RNN model with the real review data\n",
    "# to do this, we will need to process the data a bit more to get it into it's final model training state.\n",
    "# we will use the no POS tagging version as it always seemed to perform a bit better, even if the difference was\n",
    "# very small between no POS tags and POS tagged data\n",
    "\n",
    "# prepare the review text data for RNN usage\n",
    "tokenizer_RNN_noPOS_test = Tokenizer()\n",
    "tokenizer_RNN_noPOS_test.fit_on_texts(real_reviews_processed)\n",
    "review_prepped_RNN_noPOS_test = tokenizer_RNN_noPOS_test.texts_to_sequences(real_reviews_processed)\n",
    "\n",
    "# pad the text with a set length - used 10 previously so will use it again\n",
    "review_prepped_RNN_noPOS_padded = pad_sequences(review_prepped_RNN_noPOS_test, maxlen=10)\n",
    "\n",
    "real_pred_RNN_noPOS_test = model_RNN_noPOS.predict(review_prepped_RNN_noPOS_padded)\n",
    "\n",
    "# convert back to positive, negative, or neutral\n",
    "real_pred_RNN_noPOS_converted_back_test = label_encoder_RNN_no_POS.inverse_transform(real_pred_RNN_noPOS_test.argmax(axis=1))\n",
    "\n",
    "# get the predictions\n",
    "real_pred_RNN_noPOS_converted_back_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79dbd0a",
   "metadata": {},
   "source": [
    "Upon reviewing the 3 different models on real life data, it was determined that the best results on real data come from the Multinomial Naive Bayes model. I will use this in the continuation of the minimum viable product development. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f94968",
   "metadata": {},
   "source": [
    "## Part 10: Product Development "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ac93f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary GUI libraries\n",
    "#I will use message box from Tkinter to build the GUI and the Tkinter library in general [22]\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import joblib\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "81c5a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first I need to define a function that will run on the button click. \n",
    "# this will include the preprocessing, vectorization, and model execution for the sentiment analysis\n",
    "\n",
    "# function to determine the preprocessed state for the reviews\n",
    "def determine_preprocess(review):\n",
    "    # Create a list of reviews, for any \";\" will seperate the list so input needs to seperate reviews by \";\"\n",
    "    reviews_list = review.split(\";\")\n",
    "    #initialize the results list to be used to append the results\n",
    "    reviews_list_processed = []\n",
    "    \n",
    "    #loop through the reviews and analyze individually\n",
    "    for review in reviews_list:\n",
    "        # Preprocess each review individually\n",
    "        processed_review = preprocess_no_pos(review)    \n",
    "        #transform the review with our vectorizer\n",
    "        reviews_list_vectorized = RF_vectorizer_noPOS.transform([processed_review])\n",
    "        # predict the sentiment of the reviews\n",
    "        reviews_list_predictions = rf_model_resampled_noPOS.predict(reviews_list_vectorized)\n",
    "        #append the results\n",
    "        reviews_list_processed.append((review, reviews_list_predictions[0])) \n",
    "    #return the results\n",
    "    return reviews_list_processed\n",
    "\n",
    "# create a function for the sentiment analysis\n",
    "def get_sentiment():\n",
    "    #get the entry from the form \n",
    "    user_reviews_list = entry.get()\n",
    "    # if there are reviews, then analyze them \n",
    "    if user_reviews_list:\n",
    "        #determine sentiment\n",
    "        sentiment_out = determine_preprocess(user_reviews_list)\n",
    "        #clear the previous review info to ensure each review is looked at individually\n",
    "        review_text.delete(1.0, tk.END)\n",
    "        \n",
    "        # analyse the review\n",
    "        for review, sentiment in sentiment_out:\n",
    "            # in the text output that is part of the GUI, we will now get the values needed in our presentation of results\n",
    "            # get the review\n",
    "            review_text.insert(tk.END, \"Review:\\n{}\\n\".format(review))\n",
    "            # get the sentiment\n",
    "            review_text.insert(tk.END, \"Sentiment: {}\\n\".format(sentiment))\n",
    "            \n",
    "            #logic for giving recommendations on the handling procedures for the review\n",
    "            #positive\n",
    "            if sentiment == 'positive':\n",
    "                message = \"Message: This is a positive review. You should consider reaching out to learn more about what was so great about the stay and thank them for leaving a good review.\"\n",
    "            #negative\n",
    "            elif sentiment == 'negative':\n",
    "                message = \"Message: This is a negative review. You should consider reaching out to learn more about their bad experience and offer them a 10% discount for their next stay. Also thank them for the feedback.\"\n",
    "            #nuetral or other\n",
    "            else:\n",
    "                message = \"Message: Sentiment is uncertain. You may want to connect with them for more information.\"\n",
    "            \n",
    "            #add the message to the text output for presentation\n",
    "            review_text.insert(tk.END, message + \"\\n\\n\")\n",
    "    #if no reviews input and button clicked\n",
    "    else:\n",
    "        #give an error to the user\n",
    "        messagebox.showerror(\"Error\", \"Please enter a review.\")\n",
    "\n",
    "\n",
    "# initialize the tkinter model\n",
    "root = tk.Tk()\n",
    "#provide a title for the GUI\n",
    "root.title(\"Short-Term Rental Review Sentiment Analysis\")\n",
    "\n",
    "# give the label for the GUI input\n",
    "label = tk.Label(root, text=\"Enter your Short-Term Rental review (seperate multiple reviews with a ';')\")\n",
    "#update the label\n",
    "label.pack()\n",
    "\n",
    "#define the form entry size\n",
    "entry = tk.Entry(root, width=50)\n",
    "#update the entry\n",
    "entry.pack()\n",
    "\n",
    "#define the button and actions from the button click - in this case we will run the get_sentiment function\n",
    "analyze_button = tk.Button(root, text=\"Determine Sentiment\", command=get_sentiment)\n",
    "#update the button\n",
    "analyze_button.pack()\n",
    "\n",
    "# Size the text widget which will be used to display the review analysis output - including the resolution message \n",
    "review_text = tk.Text(root, height=10, width=50)\n",
    "# update the text details\n",
    "review_text.pack()\n",
    "\n",
    "#loop the root GUI to keep the window running\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b06301f",
   "metadata": {},
   "source": [
    "As can be seen when you run the code, a GUI is created that allows the user to input reviews - multiple are seperated with a \";\" - and get outcomes from the sentiment analysis with recommendations on what to do. This proves that a sentiment analysis tool like this could be created, and the minimal viable product is completed. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
